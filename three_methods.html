<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; Supervised Learning: Tree Methods – Introduction to Machine Learning and AI for Health and Sciences</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./neural_networks.html" rel="next">
<link href="./supervised_regression.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">
<script src="site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="site_libs/viz-1.8.2/viz.js"></script>
<link href="site_libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet">
<script src="site_libs/grViz-binding-1.0.11/grViz.js"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./three_methods.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Supervised Learning: Tree Methods</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Machine Learning and AI for Health and Sciences</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction_AI.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to AI and Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./supervised_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Supervised Learning: Regression tasks</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./three_methods.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Supervised Learning: Tree Methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./neural_networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Neural networks and deep learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introd_bayesian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introduction to Bayesian methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro_missing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Introduction to missing data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./high_dims.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">High Dimension Data Strategies</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpretable.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Interpretable AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./genai_foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">GenAI: Foundations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./genai_app.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">GenAI: Applications</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#setting-up-r" id="toc-setting-up-r" class="nav-link active" data-scroll-target="#setting-up-r"><span class="header-section-number">3.1</span> Setting up R</a></li>
  <li><a href="#recalling" id="toc-recalling" class="nav-link" data-scroll-target="#recalling"><span class="header-section-number">3.2</span> Recalling</a></li>
  <li><a href="#reading-the-dataset" id="toc-reading-the-dataset" class="nav-link" data-scroll-target="#reading-the-dataset"><span class="header-section-number">3.3</span> Reading the dataset</a></li>
  <li><a href="#loading-some-helper-functions" id="toc-loading-some-helper-functions" class="nav-link" data-scroll-target="#loading-some-helper-functions"><span class="header-section-number">3.4</span> Loading some helper functions</a></li>
  <li><a href="#model" id="toc-model" class="nav-link" data-scroll-target="#model"><span class="header-section-number">3.5</span> Model</a></li>
  <li><a href="#trees" id="toc-trees" class="nav-link" data-scroll-target="#trees"><span class="header-section-number">3.6</span> Trees</a>
  <ul class="collapse">
  <li><a href="#non-vegetable-anatomy-of-a-tree" id="toc-non-vegetable-anatomy-of-a-tree" class="nav-link" data-scroll-target="#non-vegetable-anatomy-of-a-tree"><span class="header-section-number">3.6.1</span> Non vegetable anatomy of a tree</a></li>
  <li><a href="#attributes-of-trees" id="toc-attributes-of-trees" class="nav-link" data-scroll-target="#attributes-of-trees"><span class="header-section-number">3.6.2</span> Attributes of trees</a></li>
  <li><a href="#a-very-short-introduction-to-interactions" id="toc-a-very-short-introduction-to-interactions" class="nav-link" data-scroll-target="#a-very-short-introduction-to-interactions"><span class="header-section-number">3.6.3</span> A very short introduction to interactions</a></li>
  <li><a href="#continuous-vs.-categorical-predictors-in-rpart" id="toc-continuous-vs.-categorical-predictors-in-rpart" class="nav-link" data-scroll-target="#continuous-vs.-categorical-predictors-in-rpart"><span class="header-section-number">3.6.4</span> Continuous vs.&nbsp;categorical predictors in rpart</a></li>
  </ul></li>
  <li><a href="#trees-for-regression-and-classification-cart" id="toc-trees-for-regression-and-classification-cart" class="nav-link" data-scroll-target="#trees-for-regression-and-classification-cart"><span class="header-section-number">3.7</span> Trees for regression and classification (CART)</a>
  <ul class="collapse">
  <li><a href="#how-the-rpart-algorithm-learns-a-tree" id="toc-how-the-rpart-algorithm-learns-a-tree" class="nav-link" data-scroll-target="#how-the-rpart-algorithm-learns-a-tree"><span class="header-section-number">3.7.1</span> How the rpart algorithm learns a tree</a></li>
  <li><a href="#hyperparameters-for-decision-trees-rpart-what-why-how" id="toc-hyperparameters-for-decision-trees-rpart-what-why-how" class="nav-link" data-scroll-target="#hyperparameters-for-decision-trees-rpart-what-why-how"><span class="header-section-number">3.7.2</span> Hyperparameters for decision trees (rpart): what, why, how</a></li>
  </ul></li>
  <li><a href="#running-a-tree-for-our-chemotherapy-example" id="toc-running-a-tree-for-our-chemotherapy-example" class="nav-link" data-scroll-target="#running-a-tree-for-our-chemotherapy-example"><span class="header-section-number">3.8</span> Running a tree for our chemotherapy example</a>
  <ul class="collapse">
  <li><a href="#printing-the-trees" id="toc-printing-the-trees" class="nav-link" data-scroll-target="#printing-the-trees"><span class="header-section-number">3.8.1</span> Printing the trees</a></li>
  </ul></li>
  <li><a href="#solutions-for-trees-problems" id="toc-solutions-for-trees-problems" class="nav-link" data-scroll-target="#solutions-for-trees-problems"><span class="header-section-number">3.9</span> Solutions for trees problems</a></li>
  <li><a href="#ensemble-techniques" id="toc-ensemble-techniques" class="nav-link" data-scroll-target="#ensemble-techniques"><span class="header-section-number">3.10</span> Ensemble techniques</a>
  <ul class="collapse">
  <li><a href="#training-models-on-sampled-data-bootstrap-aggregating-bagging" id="toc-training-models-on-sampled-data-bootstrap-aggregating-bagging" class="nav-link" data-scroll-target="#training-models-on-sampled-data-bootstrap-aggregating-bagging"><span class="header-section-number">3.10.1</span> Training models on sampled data: Bootstrap Aggregating (Bagging)</a></li>
  <li><a href="#how-bagging-works" id="toc-how-bagging-works" class="nav-link" data-scroll-target="#how-bagging-works"><span class="header-section-number">3.10.2</span> <strong>How bagging works</strong></a></li>
  <li><a href="#why-bagging-helps-in-our-chemotherapy-trial-case-study" id="toc-why-bagging-helps-in-our-chemotherapy-trial-case-study" class="nav-link" data-scroll-target="#why-bagging-helps-in-our-chemotherapy-trial-case-study"><span class="header-section-number">3.10.3</span> <strong>Why bagging helps in our chemotherapy-trial case study</strong></a></li>
  <li><a href="#learning-from-previous-models-mistakes-boosting" id="toc-learning-from-previous-models-mistakes-boosting" class="nav-link" data-scroll-target="#learning-from-previous-models-mistakes-boosting"><span class="header-section-number">3.10.4</span> Learning from Previous Models’ Mistakes: Boosting</a></li>
  <li><a href="#stacking" id="toc-stacking" class="nav-link" data-scroll-target="#stacking"><span class="header-section-number">3.10.5</span> Stacking</a></li>
  </ul></li>
  <li><a href="#setting-up-test-and-train-datasets" id="toc-setting-up-test-and-train-datasets" class="nav-link" data-scroll-target="#setting-up-test-and-train-datasets"><span class="header-section-number">3.11</span> Setting up test and train datasets</a></li>
  <li><a href="#random-forests" id="toc-random-forests" class="nav-link" data-scroll-target="#random-forests"><span class="header-section-number">3.12</span> Random Forests</a></li>
  <li><a href="#xgboost" id="toc-xgboost" class="nav-link" data-scroll-target="#xgboost"><span class="header-section-number">3.13</span> XGboost</a></li>
  <li><a href="#comparison-random-forests-and-xgboost-for-our-data" id="toc-comparison-random-forests-and-xgboost-for-our-data" class="nav-link" data-scroll-target="#comparison-random-forests-and-xgboost-for-our-data"><span class="header-section-number">3.14</span> Comparison Random Forests and XGboost for our data</a></li>
  <li><a href="#comparing-random-forests-and-xgboost-with-ols-lasso-ridge-and-elastic-net" id="toc-comparing-random-forests-and-xgboost-with-ols-lasso-ridge-and-elastic-net" class="nav-link" data-scroll-target="#comparing-random-forests-and-xgboost-with-ols-lasso-ridge-and-elastic-net"><span class="header-section-number">3.15</span> Comparing Random Forests and XGboost with OLS, LASSO, Ridge and Elastic NET</a>
  <ul class="collapse">
  <li><a href="#linear-models-with-and-without-regularization" id="toc-linear-models-with-and-without-regularization" class="nav-link" data-scroll-target="#linear-models-with-and-without-regularization"><span class="header-section-number">3.15.1</span> Linear Models with and without Regularization</a></li>
  <li><a href="#tree-based-ensemble-models" id="toc-tree-based-ensemble-models" class="nav-link" data-scroll-target="#tree-based-ensemble-models"><span class="header-section-number">3.15.2</span> Tree-Based Ensemble Models</a></li>
  </ul></li>
  <li><a href="#trees-for-classification-tasks" id="toc-trees-for-classification-tasks" class="nav-link" data-scroll-target="#trees-for-classification-tasks"><span class="header-section-number">3.16</span> Trees for classification tasks</a>
  <ul class="collapse">
  <li><a href="#model-setup" id="toc-model-setup" class="nav-link" data-scroll-target="#model-setup"><span class="header-section-number">3.16.1</span> Model setup</a></li>
  <li><a href="#inspecting-and-pruning-the-tree" id="toc-inspecting-and-pruning-the-tree" class="nav-link" data-scroll-target="#inspecting-and-pruning-the-tree"><span class="header-section-number">3.16.2</span> Inspecting and pruning the tree</a></li>
  <li><a href="#visualizing-grown-and-pruned-trees" id="toc-visualizing-grown-and-pruned-trees" class="nav-link" data-scroll-target="#visualizing-grown-and-pruned-trees"><span class="header-section-number">3.16.3</span> Visualizing grown and pruned trees</a></li>
  <li><a href="#predictions-and-confusing-matrix" id="toc-predictions-and-confusing-matrix" class="nav-link" data-scroll-target="#predictions-and-confusing-matrix"><span class="header-section-number">3.16.4</span> Predictions and confusing matrix</a></li>
  <li><a href="#roc-and-auc-for-the-classification-tree" id="toc-roc-and-auc-for-the-classification-tree" class="nav-link" data-scroll-target="#roc-and-auc-for-the-classification-tree"><span class="header-section-number">3.16.5</span> ROC and AUC for the classification tree</a></li>
  <li><a href="#interpreting-the-classification-trees" id="toc-interpreting-the-classification-trees" class="nav-link" data-scroll-target="#interpreting-the-classification-trees"><span class="header-section-number">3.16.6</span> Interpreting the classification trees</a></li>
  <li><a href="#ensemble-methods-for-classification-random-forest-and-xgboost" id="toc-ensemble-methods-for-classification-random-forest-and-xgboost" class="nav-link" data-scroll-target="#ensemble-methods-for-classification-random-forest-and-xgboost"><span class="header-section-number">3.16.7</span> Ensemble methods for classification: Random Forest and XGBoost</a></li>
  <li><a href="#random-forest-classifier" id="toc-random-forest-classifier" class="nav-link" data-scroll-target="#random-forest-classifier"><span class="header-section-number">3.16.8</span> Random Forest classifier</a></li>
  <li><a href="#xgboost-for-classification" id="toc-xgboost-for-classification" class="nav-link" data-scroll-target="#xgboost-for-classification"><span class="header-section-number">3.16.9</span> XGboost for classification</a></li>
  <li><a href="#fitting-xgboost" id="toc-fitting-xgboost" class="nav-link" data-scroll-target="#fitting-xgboost"><span class="header-section-number">3.16.10</span> Fitting XGboost</a></li>
  <li><a href="#prediction-and-evaluation" id="toc-prediction-and-evaluation" class="nav-link" data-scroll-target="#prediction-and-evaluation"><span class="header-section-number">3.16.11</span> Prediction and Evaluation</a></li>
  <li><a href="#re-fitting-the-logistic-regression-model" id="toc-re-fitting-the-logistic-regression-model" class="nav-link" data-scroll-target="#re-fitting-the-logistic-regression-model"><span class="header-section-number">3.16.12</span> Re-fitting the logistic regression model</a></li>
  <li><a href="#unified-comparison" id="toc-unified-comparison" class="nav-link" data-scroll-target="#unified-comparison"><span class="header-section-number">3.16.13</span> Unified comparison</a></li>
  <li><a href="#final-comparison-for-all-models-regarding-classification" id="toc-final-comparison-for-all-models-regarding-classification" class="nav-link" data-scroll-target="#final-comparison-for-all-models-regarding-classification"><span class="header-section-number">3.16.14</span> Final comparison for all models regarding classification</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Supervised Learning: Tree Methods</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="setting-up-r" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="setting-up-r"><span class="header-section-number">3.1</span> Setting up R</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Core data/plot</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>req_pkgs <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">"dplyr"</span>, <span class="st">"ggplot2"</span>, <span class="st">"tidyr"</span>, <span class="st">"readr"</span>, <span class="st">"tibble"</span>, <span class="st">"gridExtra"</span>,</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Trees</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">"rpart"</span>, <span class="st">"rpart.plot"</span>, <span class="st">"partykit"</span>,</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Random Forests (pick one or use both)</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">"ranger"</span>,        <span class="co"># fast RF (recommended)</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">"randomForest"</span>,  <span class="co"># classic RF implementation</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Gradient Boosting</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="st">"xgboost"</span>, <span class="st">"Matrix"</span>,  <span class="co"># Matrix for sparse design matrices</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Model interpretation (optional but handy)</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="st">"vip"</span>,   <span class="co"># variable importance plots</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="st">"pdp"</span>,   <span class="co"># partial dependence</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  <span class="st">"iml"</span>    <span class="co"># ICE/SHAP-like tools (optional)</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Install any missing</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>to_install <span class="ot">&lt;-</span> <span class="fu">setdiff</span>(req_pkgs, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>()))</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">length</span>(to_install) <span class="sc">&gt;</span> <span class="dv">0</span>) {</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">install.packages</span>(to_install, <span class="at">dependencies =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Load all (silently)</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="fu">invisible</span>(<span class="fu">lapply</span>(req_pkgs, require, <span class="at">character.only =</span> <span class="cn">TRUE</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="recalling" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="recalling"><span class="header-section-number">3.2</span> Recalling</h2>
<p>In the last chapter we studied models that allow us to perform supervised learning regression tasks. We used linear models and different approaches for estimation including OLS, LASSO, Ridge and Elastic Net to predict labels of interest. We did that using an example of a clinical trial in which patients were randomized to receive or not chemotherapy. In the experiment we also collected other features and the expression of 2000 gens. We then fitted and compared OLS, LASSO, Ridge and Elastic Net models and compared regarding model outputs and prediction capacity. In this chapter we will still use the chemotherapy trial example to learn the concept of trees, random forests and XGboost techniques.</p>
</section>
<section id="reading-the-dataset" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="reading-the-dataset"><span class="header-section-number">3.3</span> Reading the dataset</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ================================</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Read and prepare TRAIN/</span><span class="al">TEST</span><span class="co"> (no saving)</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ================================</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 0) Load</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>trial_ct <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"~/att_ai_ml/data/trial_ct_chemo_cont.rds"</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(trial_ct[, <span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>])   <span class="co"># quick peek</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   10000 obs. of  15 variables:
 $ patient_id       : chr  "P001" "P002" "P003" "P004" ...
 $ treatment        : Factor w/ 2 levels "no_chemo","chemo": 2 1 1 1 2 2 1 2 1 2 ...
 $ dose_intensity   : num  1.08 0 0 0 1.01 ...
 $ patient_age      : num  81 61 81 74 41 74 22 61 26 22 ...
 $ tumor_grade      : Factor w/ 3 levels "G1","G2","G3": 2 2 3 2 2 2 1 2 3 2 ...
 $ performance_score: int  1 1 1 0 1 1 2 0 1 0 ...
 $ baseline_tumor_mm: num  52.2 43.3 43.2 63.8 54.2 44.9 51.5 95.1 69.5 54.7 ...
 $ post_tumor_mm    : num  25.8 43.3 43.2 61.2 33.6 37 51.5 60.4 69.5 29.8 ...
 $ response_percent : num  50.6 0 0 4.2 38 17.5 0 36.5 0 45.6 ...
 $ high_response    : int  1 0 0 0 1 0 0 1 0 1 ...
 $ gene_01          : num  11.01 9.26 10.09 8.99 9.01 ...
 $ gene_02          : num  9.31 7.79 8.95 7.8 8.33 ...
 $ gene_03          : num  9.51 8.02 9.45 7.78 8.23 ...
 $ gene_04          : num  10.27 9.16 9.42 8.87 9.03 ...
 $ gene_05          : num  7.31 8.14 7.83 7.49 7.23 ...</code></pre>
</div>
</div>
<p>Let’s divide the dataset into training and testing like we did in the chapter about regression tasks.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) Stratified 70/30 split by treatment</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>split_strat <span class="ot">&lt;-</span> <span class="cf">function</span>(df, strat_col, <span class="at">p_train =</span> <span class="fl">0.7</span>) {</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  idx_tr <span class="ot">&lt;-</span> <span class="fu">unlist</span>(<span class="fu">tapply</span>(<span class="fu">seq_len</span>(<span class="fu">nrow</span>(df)), df[[strat_col]], <span class="cf">function</span>(ix) {</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sample</span>(ix, <span class="at">size =</span> <span class="fu">floor</span>(p_train <span class="sc">*</span> <span class="fu">length</span>(ix)))</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  }))</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="at">train =</span> <span class="fu">sort</span>(idx_tr), <span class="at">test =</span> <span class="fu">setdiff</span>(<span class="fu">seq_len</span>(<span class="fu">nrow</span>(df)), idx_tr))</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>sp <span class="ot">&lt;-</span> <span class="fu">split_strat</span>(trial_ct, <span class="at">strat_col =</span> <span class="st">"treatment"</span>, <span class="at">p_train =</span> <span class="fl">0.7</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> trial_ct[sp<span class="sc">$</span>train, , drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>test  <span class="ot">&lt;-</span> trial_ct[sp<span class="sc">$</span>test,  , drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The next chunk will make sure we will use only the columns that make sense.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 3) Drop columns that should NOT enter models</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co">#    - patient_id: identifier only</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">#    - high_response: binary version of the outcome (leakage if modeling response_percent)</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">#    - baseline_tumor_mm, post_tumor_mm: strongly deterministically related to response_percent</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>drop_cols <span class="ot">&lt;-</span> <span class="fu">intersect</span>(</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">names</span>(train),</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(<span class="st">"patient_id"</span>, <span class="st">"high_response"</span>, <span class="st">"baseline_tumor_mm"</span>, <span class="st">"post_tumor_mm"</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>train_nopii <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(train, <span class="sc">-</span>dplyr<span class="sc">::</span><span class="fu">all_of</span>(drop_cols))</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>test_nopii  <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(test,  <span class="sc">-</span>dplyr<span class="sc">::</span><span class="fu">all_of</span>(drop_cols))</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 4) Check outcome presence</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">#stopifnot("response_percent" %in% names(train_nopii))</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now that we have the training and testing datasets organized we will create the matrices required for running models later. We will keep the same strategy we used for the previous chapters so we can compare the results of today with the ones of that class.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 5) Build a consistent design (for glmnet / xgboost, etc.)</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">#    Use TRAIN to “freeze” factor levels and dummy columns</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>f_ols   <span class="ot">&lt;-</span> response_percent <span class="sc">~</span> .</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>ols_tmp <span class="ot">&lt;-</span> <span class="fu">lm</span>(f_ols, <span class="at">data =</span> train_nopii)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>ols_terms <span class="ot">&lt;-</span> <span class="fu">terms</span>(ols_tmp)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Model matrices (no intercept column)</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>X_train <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(ols_terms, <span class="at">data =</span> train_nopii)[, <span class="sc">-</span><span class="dv">1</span>, drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>X_test  <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(ols_terms, <span class="at">data =</span> test_nopii)[,  <span class="sc">-</span><span class="dv">1</span>, drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> train_nopii<span class="sc">$</span>response_percent</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>y_test  <span class="ot">&lt;-</span> test_nopii<span class="sc">$</span>response_percent</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="loading-some-helper-functions" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="loading-some-helper-functions"><span class="header-section-number">3.4</span> Loading some helper functions</h2>
<p>As in the other chapter</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 6) Small helpers for later evaluations</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>mae  <span class="ot">&lt;-</span> <span class="cf">function</span>(y, yhat) <span class="fu">mean</span>(<span class="fu">abs</span>(y <span class="sc">-</span> yhat))</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>rmse <span class="ot">&lt;-</span> <span class="cf">function</span>(y, yhat) <span class="fu">sqrt</span>(<span class="fu">mean</span>((y <span class="sc">-</span> yhat)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>eval_perf <span class="ot">&lt;-</span> <span class="cf">function</span>(y_true, y_pred) {</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  tibble<span class="sc">::</span><span class="fu">tibble</span>(<span class="at">MAE =</span> <span class="fu">mae</span>(y_true, y_pred), <span class="at">RMSE =</span> <span class="fu">rmse</span>(y_true, y_pred))</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Before reading the rest of the chapter make sure you have the following objects loaded in your R environment</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- Objects now available (in-memory) ----</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># train, test                      # full splits (for inspection/plots)</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># train_nopii, test_nopii          # safe for tree models (RF) with data.frame API</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># X_train, X_test, y_train, y_test # matrices for glmnet / xgboost</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># eval_perf(), mae(), rmse()       # metric helpers</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="model" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="model"><span class="header-section-number">3.5</span> Model</h2>
<p>I the previous classes we learn that predictive AI, also named, machine learning can help us to predict labels using explanatory features, in simple mathematical terms we will have</p>
<p><span class="math display">\[
Y=f(X)+\epsilon
\]</span></p>
<p><span class="math display">\[Y=f(x1,x2,...,xn)+error\]</span></p>
<p>In the previous chapter we explored models in which f is said to have a linear behaviour</p>
<p><span id="eq-linear"><span class="math display">\[Y= \mu + b1 * x1 +.... bn *xn+ \epsilon \tag{3.1}\]</span></span></p>
<p>when using the explanatory features to predict the responses.</p>
<p>In this chapter we will learn models that learn the function <span class="math inline">\(f(X)\)</span> via (decision trees and their ensembles), named Random Forests and XGboost. The trees will be performing regression tasks or classification tasks.</p>
</section>
<section id="trees" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="trees"><span class="header-section-number">3.6</span> Trees</h2>
<p>Before applying tree-based models to real clinical data, it is useful to build intuition with a simple synthetic example. Decision trees are, at their core, collections of if-else rules that partition the feature space into smaller, homogeneous regions. Each region (or leaf) represents a group of observations that share similar predicted values. To understand how such rules emerge from data, we will simulate a small dataset where the true underlying relationship between predictors and the outcome is explicitly governed by ifelse logic.</p>
<p>In this example, we create two explanatory variables- <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>-and one response variable <span class="math inline">\(Y\)</span>. The response depends on threshold-based rules involving these features, plus a small amount of random noise:</p>
<p><span class="math display">\[
Y= \begin{cases}5+\varepsilon, &amp; \text { if } X_1 \leq 4 \\ 10+\varepsilon, &amp; \text { if } X_1&gt;4 \text { and } X_2 \leq 0 \\ 14+\varepsilon, &amp; \text { if } X_1&gt;4 \text { and } X_2&gt;0\end{cases}
\]</span></p>
<p>where <span class="math inline">\(\varepsilon \sim \mathcal{N}\left(0,0.8^2\right)\)</span> adds a small random deviation around each mean value. This structure defines three regions in the predictor space-each corresponding to one “rule” that determines the value of <span class="math inline">\(Y\)</span>.</p>
<p>The following R code generates this dataset:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ===== 1) TOY EXAMPLE: a small, interpretable tree =====</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Two features with threshold structure, plus noise</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>X1 <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="dv">0</span>, <span class="dv">10</span>)            <span class="co"># e.g., "age-like"</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>X2 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">1</span>)             <span class="co"># e.g., "biomarker-like"</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Piecewise rule used to generate y (ground truth if/else)</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># IF X1 &lt;= 4      THEN y ~  5 + noise</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># ELSE IF X2 &lt;= 0 THEN y ~ 10 + noise</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># ELSE                 y ~ 14 + noise</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>y  <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(X1 <span class="sc">&lt;=</span> <span class="dv">4</span>, <span class="dv">5</span>, <span class="fu">ifelse</span>(X2 <span class="sc">&lt;=</span> <span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">14</span>)) <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="fl">0.8</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>toy <span class="ot">&lt;-</span> tibble<span class="sc">::</span><span class="fu">tibble</span>(<span class="at">X1 =</span> X1, <span class="at">X2 =</span> X2, <span class="at">y =</span> y)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(toy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 3
     X1      X2     y
  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
1 7.56   0.570  13.1 
2 1.08   1.01    5.79
3 9.04  -0.346   9.59
4 5.55  -0.249  10.1 
5 9.33   0.213  14.8 
6 0.759 -0.0242  5.53</code></pre>
</div>
</div>
<p>The resulting dataset toy contains 200 simulated observations, each described by two predictors ( X1 , X2 ) and a numeric outcome ( y ). The piecewise constant nature of the data mimics a situation where a target variable depends on threshold effects-for instance, a biomarker that changes behavior only above a certain age or concentration level.</p>
<p>This simple simulation is pedagogically powerful: when we fit a decision tree to these data, the model will recover rules very similar to the ones used to generate <span class="math inline">\(Y\)</span>. Each split in the tree corresponds to a decision node, where the algorithm asks a question of the form “Is <span class="math inline">\(X_j \leq s\)</span> ?”. Depending on the answer, the observation moves to a child node on either the left or right branch. The process continues until no further improvement in prediction can be achieved, producing terminal nodes (leaves) that store the average predicted value of <span class="math inline">\(Y\)</span> for that region.</p>
<p>By visualizing and interpreting this tree, we can clearly see how decision trees learn and represent piecewise-constant approximations of complex, nonlinear relationships using only simple, interpretable rules.</p>
<p>In this chapter we will learn how to represent datasets like this in the form of the next figure</p>
<p>One possibility could be approximating the y values using the if else rules expressed in the tree</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>y is  5.0 when
          X1 &lt; 4

y is  9.8 when
          X1 &gt;= 4
          X2 &lt; -0.031

y is 14.0 when
          X1 &gt;= 4
          X2 &gt;= -0.031</code></pre>
</div>
</div>
<p>Which can be visualised as with the usage of the Figure</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="three_methods_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>This means the fitted model partitions the predictor space into three rectangular regions, each defined by simple threshold conditions on <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> : 1. Region 1 (Left branch):</p>
<p>When <span class="math inline">\(X_1&lt;4\)</span>, the model predicts <span class="math inline">\(\hat{y}=5.0\)</span>. This corresponds to the “younger” or “low-X1” group in our simulation, and reproduces the first rule of the data-generating process. 2. Region 2 (Middle branch):</p>
<p>When <span class="math inline">\(X_1 \geq 4\)</span> and <span class="math inline">\(X_2&lt;-0.03\)</span>, the model predicts <span class="math inline">\(\hat{y}=9.8\)</span>. This reflects the second rule-if <span class="math inline">\(X_1\)</span> is large but the second biomarker is low, <span class="math inline">\(y\)</span> is around 10 . 3. Region 3 (Right branch):</p>
<p>When <span class="math inline">\(X_1 \geq 4\)</span> and <span class="math inline">\(X_2 \geq-0.03\)</span>, the model predicts <span class="math inline">\(\hat{y}=14.0\)</span>. This captures the third rule-both features are high, so the predicted outcome rises further. Each “when” statement defines a path from the root to a leaf, and each leaf holds the average of the training responses that fall into that region. In this simple example, the regression tree recovered the same three rules used to generate the data, showing how trees naturally express models as collections of logical conditions (if/else) rather than algebraic equations.</p>
<section id="non-vegetable-anatomy-of-a-tree" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="non-vegetable-anatomy-of-a-tree"><span class="header-section-number">3.6.1</span> Non vegetable anatomy of a tree</h3>
<p>The following annotated <a href="introduction_AI.html#fig-anat" class="quarto-xref">Figure&nbsp;<span>1.6</span></a> depicts the anatomy of a computer science (algorithm) trees</p>
<div id="fig-notated_tree" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-notated_tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/tree_notes.png" id="fig-notated_tree" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-notated_tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.1
</figcaption>
</figure>
</div>
<p>A decision tree is composed of a small number of fundamental building blocks that work together to partition the predictor space and generate predictions. The annotated figure highlights six key elements each serving a distinct role in the tree’s logic and interpretability.</p>
<p>The <strong>root node</strong> is the starting point of the tree and contains the entire dataset below it. It summarises the outcome distribution before any splitting occurs and represents the baseline prediction if no further structure were learned. All decision paths originate from this node.</p>
<p>An <strong>internal node</strong> is any node that performs a further split. It contains a rule such as <em>X1 &lt; 4</em> or <em>X2 ≥ –0.03</em>, chosen to maximize homogeneity in the resulting subgroups. These nodes divide the data into more refined regions and define the hierarchical structure of the model.</p>
<p>Between every parent and child node lies a <strong>splitting rule</strong>, which acts as the conditional logic directing observations left or right. This is the “if–else” mechanism of the tree.<br>
</p>
<p>Between-node rules partition the feature space and determine how each observation flows through the model, creating a sequence of decisions that progressively increases predictive precision. Each node contains a compact summary of the data reaching that point, typically including:</p>
<ul>
<li><p>the predicted value (in regression),</p></li>
<li><p>the number of observations in the node, and</p></li>
<li><p>the percentage of the sample represented. This <strong>within-node information</strong> describes the characteristics of the subgroup created by previous splits and forms the foundation for the node’s prediction.</p></li>
</ul>
<p>A <strong>leaf node</strong> is a node with no further splits.<br>
</p>
<p>Leaf nodes provide the model’s final predictions. They correspond to the most homogeneous subgroups discovered during training, each representing a rule-defined region of the predictor space. In regression trees, the leaf value is the mean outcome of that subgroup. Every split produces two <strong>child nodes</strong>, each inheriting all conditions from its ancestors.<br>
</p>
<p>These nodes represent progressively more detailed subdivisions of the dataset.<br>
</p>
<p>A child node can either become another internal node (if it contains meaningful further structure) or a leaf node (if splitting stops).</p>
</section>
<section id="attributes-of-trees" class="level3" data-number="3.6.2">
<h3 data-number="3.6.2" class="anchored" data-anchor-id="attributes-of-trees"><span class="header-section-number">3.6.2</span> Attributes of trees</h3>
<p>Decision trees are among the most intuitive and versatile models in machine learning. They combine the logic of if-else reasoning with the ability to approximate complex, nonlinear functions. The structure of a tree provides both a visual and conceptual bridge between human decision-making and predictive modeling.</p>
<p>Hierarchical and rule-based structure</p>
<p>A decision tree represents a sequence of binary decisions. At each internal node, the algorithm tests a condition of the form</p>
<p><span class="math display">\[
x_j \leq s,
\]</span></p>
<p>where <span class="math inline">\(x_j\)</span> is one explanatory variable and <span class="math inline">\(s\)</span> is a threshold chosen to maximize predictive homogeneity the resulting subgroups.</p>
<p>Each path from the root to a leaf corresponds to a complete logical rule that defines a rectangular region of the predictor space. Leaves store a single value (for regression) or a class probability (for classification), so the tree acts as a collection of piecewise rules.</p>
<p>Other important attributes include the following items:</p>
<p>Local modeling and nonlinearity:</p>
<p>Unlike linear regression, which assumes a single global relationship between predictors and the response, trees build local models. Each branch captures relationships that may differ across subsets of the data. This allows trees to represent sharp thresholds, discontinuities, and strong interactions between variables without explicitly defining them in advance.</p>
<p>Automatic handling of interactions:</p>
<p>Because each new split is conditional on previous <span class="math inline">\(\bigcirc\)</span> s, trees naturally model interactions between predictors.</p>
<p>For example, a second-level split on <span class="math inline">\(X_2\)</span> applies only to observations that already satisfy a condition on <span class="math inline">\(X_1\)</span>. This hierarchical conditioning is equivalent to including interaction terms in a regression model, but it emerges automatically from the recursive partitioning process.</p>
<p>Scale and data type robustness:</p>
<p>Decision trees are invariant to feature scaling-splits depend only on ordering, not on variable magnitude. They also handle both numeric and categorical variables seamlessly. In many implementations, missing values can be directed through surrogate splits, allowing a model to make predictions even with incomplete data.</p>
<p>Interpretability and transparency: Each decision path can be read as an explicit rule such as “if tumor size <span class="math inline">\(&lt;3 \mathrm{~cm}\)</span> and biomarker <span class="math inline">\(\geq 1.2\)</span> then predict high response.” This makes trees particularly appealing in health and life-science contexts, where interpretability is essential for clinical validation and regulatory transparency. A tree’s visual representation helps communicate how specific variables drive predictions in different patient subgroups.</p>
<p>Despite their interpretability, single trees can be unstable: small perturbations in the data may change the chosen splits and produce very different trees. Their predictions are also piecewise constant, creating abrupt jumps between regions. To improve stability and predictive accuracy, modern practice often aggregates many trees into ensembles such as Random Forests or Gradient I <span class="math inline">\(\downarrow\)</span> sted Trees, which we will explore next.</p>
</section>
<section id="a-very-short-introduction-to-interactions" class="level3" data-number="3.6.3">
<h3 data-number="3.6.3" class="anchored" data-anchor-id="a-very-short-introduction-to-interactions"><span class="header-section-number">3.6.3</span> A very short introduction to interactions</h3>
<p>In predictive modeling, an interaction occurs when the effect of one explanatory variable on the outcome depends on the value of another variable. Formally, two variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> interact if the change in the response <span class="math inline">\(Y\)</span> associated with <span class="math inline">\(X_1\)</span> varies according to the level of <span class="math inline">\(X_2\)</span>.</p>
<p>In linear models, this relationship must be specified explicitly by adding a product term (e.g., <span class="math inline">\(\beta_3 X_1 X_2\)</span> ). In decision trees, interactions emerge automatically: each split is conditional on previous decisions, so the model can represent different relationships between <span class="math inline">\(X_1\)</span> and <span class="math inline">\(Y\)</span> depending on the branch defined by <span class="math inline">\(X_2\)</span>.</p>
<p>In other words, trees learn interactions hierarchically rather than algebraically-each branch of the tree corresponds to a different interaction context.</p>
<p>Examples of interactions include:</p>
<ol type="1">
<li>Clinical example - drug efficacy and age</li>
</ol>
<p>The effectiveness of a chemotherapy drug ( <span class="math inline">\(X_1\)</span> ) may depend on the patient’s age ( <span class="math inline">\(X_2\)</span> ). The treatment might be highly effective in younger patients but less so in older ones due to metabolism or organ function.</p>
<p>In this case, the effect of the drug is conditional on age - an interaction between treatment and age. 2. Biomarker example - gene expression and tumor grade</p>
<p>A specific gene expression score ( <span class="math inline">\(X_1\)</span> ) could predict tumor response only for patients with highgrade tumors ( <span class="math inline">\(X_2\)</span> ). For low-grade tumors, the same biomarker might have little to no effect. This represents a biological interaction: the prognostic value of the biomarker changes across tumor grades. 3. Behavioral or physiological example - dose and physical condition</p>
<p>The relationship between drug dose ( <span class="math inline">\(X_1\)</span> ) and therapeutic response ( <span class="math inline">\(Y\)</span> ) may differ between patients with good and poor performance status ( <span class="math inline">\(X_2\)</span> ). The slope of the dose-response curve is steeper in one group and flatter in the other, illustrating an interaction between dose intensity and baseline health.</p>
<ol start="4" type="1">
<li>Generic data-science example - temperature and humidity</li>
</ol>
<p>In environmental modeling, the effect of temperature ( <span class="math inline">\(X_1\)</span> ) on energy consumption ( <span class="math inline">\(Y\)</span> ) depends on humidity ( <span class="math inline">\(X_2\)</span> ).</p>
<p>High temperatures increase consumption only when humidity is also high, due to greater airconditioning load - another clear interaction.</p>
<ol start="5" type="1">
<li>Genotype by environment interactions</li>
</ol>
<p>In genetics usually its important to understand how the interaction between genomic and environmental information defines a given phenotype.</p>
<p>We learnt what trees are and their characteristics. We will now understand how to implement them with R and how they learn the if else rules.</p>
<p>Interactions can be explored graphically with the usage of interaction plots.<br>
<br>
In the case of no interactions the graphic will be like the one shown in <a href="#fig-no_int" class="quarto-xref">Figure&nbsp;<span>3.2</span></a>, in which the lines connecting the mean response by dose intensity level are parallel, meaning that the means response does not change when we change the dose intensity level.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  agg_no_inter,</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(dose_intensity, mean_resp, <span class="at">color =</span> tumor_grade, <span class="at">group =</span> tumor_grade)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">linewidth =</span> <span class="fl">1.3</span>) <span class="sc">+</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Interaction Plot (NO Interaction Example)"</span>,</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">"Parallel lines → effect of dose is the same across tumor grades"</span>,</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Dose intensity"</span>,</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Mean response (%)"</span>,</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"Tumor grade"</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">14</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-no_int" class="quarto-float quarto-figure quarto-figure-center anchored" width="672">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-no_int-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="three_methods_files/figure-html/fig-no_int-1.png" id="fig-no_int" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-no_int-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.2
</figcaption>
</figure>
</div>
</div>
</div>
<p>On the other hand when we have the presence of an interaction, like in our chemotherapy example, we can produce the interaction plot using the following code. We can see that the lines in the interaction plot are not parallel indicating the presence of interaction, in other words, the level o mean tumor response changes according to the level of dose intensity. This is shown in FIgure <a href="#fig-interaction" class="quarto-xref">Figure&nbsp;<span>3.3</span></a></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Interaction-style plot</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(agg, <span class="fu">aes</span>(dose_bin, mean_resp, <span class="at">color =</span> tumor_grade, <span class="at">group =</span> tumor_grade)) <span class="sc">+</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">linewidth =</span> <span class="fl">1.3</span>) <span class="sc">+</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Interaction Plot (Observed Data Only)"</span>,</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">"How tumor grade modifies the dose–response pattern"</span>,</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Dose intensity (binned)"</span>,</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Mean tumor response (%)"</span>,</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"Tumor grade"</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">14</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-interaction" class="quarto-float quarto-figure quarto-figure-center anchored" width="672">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-interaction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="three_methods_files/figure-html/fig-interaction-1.png" id="fig-interaction" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-interaction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.3
</figcaption>
</figure>
</div>
</div>
</div>
<section id="how-a-tree-is-built" class="level4" data-number="3.6.3.1">
<h4 data-number="3.6.3.1" class="anchored" data-anchor-id="how-a-tree-is-built"><span class="header-section-number">3.6.3.1</span> How a tree is built</h4>
<p>A regression tree approximates the unknown function <span class="math inline">\(f(\mathbf{X})\)</span> by a piecewise-constant model:</p>
<p><span class="math display">\[
\hat{f}(\mathbf{X})=\sum_{m=1}^M c_m \mathbf{1}\left\{\mathbf{X} \in R_m\right\},
\]</span></p>
<p>where each leaf (region <span class="math inline">\(R_m\)</span> ) predicts a constant <span class="math inline">\(c_m\)</span> (usually the mean <span class="math inline">\(y\)</span> in that region).</p>
<p>This formulation shows that, although trees are non-linear in the inputs, they are linear in the indicator functions that define the regions. In other words, a tree can be viewed as a linear model on a transformed feature space-one where the original variables have been replaced by a collection of binary indicators representing the hierarchical if-else splits.</p>
<p><span class="math display">\[
\hat{f}(X)=c_1 \mathbf{1}_{R_1}(X)+c_2 \mathbf{1}_{R_2}(X)+\cdots+c_M \mathbf{1}_{R_M}(X) .
\]</span></p>
<p>From this perspective, decision trees extend the concept of a linear model by allowing the basis functions ( <span class="math inline">\(\mathbf{1}_{R_m}\)</span> ) to be learned from data rather than predefined. Each new split creates a new “basis” that isolates a subset of the data with distinct local behavior.</p>
<p>We can compare linear and tree models regarding some geometrical and conceptual interpretation:</p>
<ul>
<li>In a linear model, the function <span class="math inline">\(f(X)\)</span> defines a single plane (or hyperplane) across the feature space. Predictions vary smoothly and continuously with <span class="math inline">\(X\)</span>.</li>
<li>In a decision tree, the feature space is divided into rectangular regions, within which predictions are constant. The function <span class="math inline">\(f(X)\)</span> therefore takes a piecewise-constant form, producing a step-like approximation to the true relationship.</li>
</ul>
<p>Visually, a tree can be seen as a function that “jumps” at each decision boundary, instead of tilting like a plane. This enables trees to capture sharp thresholds, nonlinearities, and interactions that linear models cannot express without manual feature engineering.</p>
<p>Learning = splitting to reduce impurity. At a node containing samples <span class="math inline">\(S\)</span>, the CART algorithm chooses a feature <span class="math inline">\(j\)</span> and threshold <span class="math inline">\(s\)</span> that minimize the total squared error after splitting:</p>
<p><span class="math display">\[
\left(j^*, s^*\right)=\arg \min _{j, s}\left[\sum_{i \in S_L}\left(y_i-\bar{y}_L\right)^2+\sum_{i \in S_R}\left(y_i-\bar{y}_R\right)^2\right],
\]</span></p>
<p>equivalently maximizing variance reduction:</p>
<p><span class="math display">\[
\Delta I=I(S)-\frac{\left|S_L\right|}{|S|} I\left(S_L\right)-\frac{\left|S_R\right|}{|S|} I\left(S_R\right), \quad I(S)=\frac{1}{|S|} \sum_{i \in S}\left(y_i-\bar{y}_S\right)^2 .
\]</span></p>
</section>
<section id="choosing-the-best-split-impurity-and-information-gain" class="level4" data-number="3.6.3.2">
<h4 data-number="3.6.3.2" class="anchored" data-anchor-id="choosing-the-best-split-impurity-and-information-gain"><span class="header-section-number">3.6.3.2</span> Choosing the best split: impurity and information gain</h4>
<p>At every node, the tree algorithm searches for the feature and cut-point that most reduce the node’s <em>impurity</em> that is, the heterogeneity of responses within the node.</p>
<p>For regression tasks such as predicting <code>response_percent</code>, impurity is measured by the within-node variance:</p>
<p><span class="math display">\[
I(S) = \frac{1}{|S|} \sum_{i \in S} (y_i - \bar{y}_S)^2 .
\]</span></p>
<p>The chosen split <span class="math inline">\((j^*, s^*)\)</span> maximizes the <strong>reduction in impurity</strong>:</p>
<p><span class="math display">\[
\Delta I = I(\text{parent})
- \frac{n_L}{n_{\text{parent}}} I(\text{left})
- \frac{n_R}{n_{\text{parent}}} I(\text{right}).
\]</span></p>
<p>Intuitively, the algorithm prefers splits that make the child nodes more homogeneous in <code>response_percent</code>.<br>
For classification tasks, <code>rpart()</code> uses the <em>Gini index</em> or <em>entropy</em> instead of variance.</p>
</section>
</section>
<section id="continuous-vs.-categorical-predictors-in-rpart" class="level3" data-number="3.6.4">
<h3 data-number="3.6.4" class="anchored" data-anchor-id="continuous-vs.-categorical-predictors-in-rpart"><span class="header-section-number">3.6.4</span> Continuous vs.&nbsp;categorical predictors in rpart</h3>
<p>rpart handles numeric and factor variables differently when proposing binary splits at a node. Continuous predictors (e.g., dose_intensity , gene_14) - Procedure: sort unique values of <span class="math inline">\(x_j\)</span>; evaluate candidate thresholds at midpoints between adjacent values.</p>
<ul>
<li><p>For each threshold <span class="math inline">\(s\)</span>, form left/right nodes <span class="math inline">\(\left(x_j \leq s\right)\)</span> vs.&nbsp;<span class="math inline">\(\left(x_j&gt;s\right)\)</span> and compute the impurity reduction (variance for regression; Gini/entropy for classification).</p></li>
<li><p>Choose the <span class="math inline">\(s\)</span> that maximizes <span class="math inline">\(\Delta I\)</span>.</p></li>
<li><p>Consequences: no scaling needed (splits depend on order, not magnitude); trees naturally create step-functions and thresholds (e.g., a cut at gene_14 <span class="math inline">\(\geq 0.98\)</span> in our chemo example).</p></li>
</ul>
<p>Categorical predictors (e.g., treatment <span class="math inline">\(\in\{\)</span> no_chemo , chemo <span class="math inline">\(\}\)</span>, tumor_grade <span class="math inline">\(\in\{\mathrm{G} 1, \mathrm{G} 2, \mathrm{G} 3\}\)</span> )</p>
<ul>
<li><p>Binary factors: trivial split (one level left, the other right).</p></li>
<li><p>Multi-level factors: in principle there are <span class="math inline">\(2^{m-1}-1\)</span> groupings of <span class="math inline">\(m\)</span> levels; rpart avoids brute force by ordering levels by their node statistics and then testing only adjacent two-group splits along that order:</p></li>
<li><p>Classification: order levels by class composition; test adjacent partitions; pick the one with largest Gini/entropy reduction.</p></li>
<li><p>Regression: order levels by the mean response; test adjacent partitions; pick the best variance reduction.</p></li>
<li><p>Result: efficient search that still finds strong groupings (e.g., tumor_grade <span class="math inline">\(\in\{G 2, G 3\}\)</span> vs.&nbsp;<span class="math inline">\(\{G 1\}\)</span> if those two higher grades share similar response patterns).</p></li>
</ul>
<p>Ordered factors</p>
<ul>
<li>If a variable is an ordered factor, rpart treats it like a numeric rank and proposes threshold splits along that order (behaves like a continuous variable).</li>
</ul>
<p>Missing values <span class="math inline">\(\&amp;\)</span> surrogates</p>
<ul>
<li>If the primary split variable is missing for a case (e.g., missing gene_14), rpart can route it using surrogate splits-backup variables that mimic the primary partition (controlled by usesurrogate, maxsurrogate).</li>
</ul>
<p>Practical notes for our dataset</p>
<ul>
<li>Keep true categorical variables as factors (e.g., treatment , tumor_grade ), and keep gene expression and doses numeric.</li>
<li>High-cardinality categorical variables can make splits unstable; if you have such variables, consider sensible grouping beforehand.</li>
<li>No need for one-hot encoding or scaling; rpart handles both types natively.</li>
</ul>
<section id="stopping-pruning." class="level4" data-number="3.6.4.1">
<h4 data-number="3.6.4.1" class="anchored" data-anchor-id="stopping-pruning."><span class="header-section-number">3.6.4.1</span> Stopping &amp; pruning.</h4>
<p>To avoid overfitting, trees stop growing (e.g., maxdepth , minsplit ) and/or are pruned via costcomplexity:</p>
<p><span class="math display">\[
\operatorname{Score}(T)=\operatorname{RSS}(T)+\alpha|T|, \quad \alpha \geq 0,
\]</span></p>
<p>selecting the smallest subtree within 1-SE of the minimum cross-validated error.</p>
<p>The model is built by recursively partitioning the feature space into smaller and more homogeneous regions.</p>
<p>Each split introduces a new if-else rule, and the process continues until no further improvement is possible or a stopping rule is reached.</p>
<p>In some future sections we will see the concept of ensembles and Link trees to ensembles. When we combine many trees-as in Random Forests and Gradient Boosted Trees (XGBoost)-the model becomes a sum of multiple tree functions:</p>
<p><span class="math display">\[
\hat{f}(X)=\sum_{b=1}^B \hat{f}_b(X),
\]</span></p>
<p>where each <span class="math inline">\(\hat{f}_b(X)\)</span> is a tree trained on a different subset or residual of the data. This ensemble structure restores smoothness and reduces variance while keeping the interpretability and flexibility of the tree-based representation.</p>
</section>
<section id="biasvariance-perspective" class="level4" data-number="3.6.4.2">
<h4 data-number="3.6.4.2" class="anchored" data-anchor-id="biasvariance-perspective"><span class="header-section-number">3.6.4.2</span> Bias–variance perspective</h4>
<p>A fully grown tree fits every training case perfectly but generalizes poorly its variance is high.<br>
Pruning or using constraints (<code>minsplit</code>, <code>cp</code>, <code>maxdepth</code>) increases bias slightly but drastically reduces variance, improving predictive stability.<br>
In the chemotherapy trial, an unpruned tree would memorize gene-expression idiosyncrasies of a few patients, giving near-zero error in training but poor test performance.<br>
The pruned tree achieves a better <strong>bias–variance balance</strong>, capturing major response patterns while ignoring random noise.</p>
</section>
<section id="stages-to-build-a-tree" class="level4" data-number="3.6.4.3">
<h4 data-number="3.6.4.3" class="anchored" data-anchor-id="stages-to-build-a-tree"><span class="header-section-number">3.6.4.3</span> Stages to build a tree</h4>
<p>The construction of a tree can be described in several stages: initialization, growing, splitting, stopping, pruning, and prediction.</p>
<ol type="1">
<li>Initialization</li>
</ol>
<ul>
<li>Start with the full training dataset at the root node.</li>
</ul>
<p>Every observation belongs to this node, and the model computes a simple summary: - for regression: the mean response <span class="math inline">\(\bar{y}\)</span>; - for classification: the most frequent class. - This initial value is the baseline prediction before any split occurs.</p>
<ol start="2" type="1">
<li>Searching for the best split (growing phase)</li>
</ol>
<p>At each step, the algorithm evaluates all possible binary splits of all features. For a numeric variable <span class="math inline">\(x_j\)</span>, it considers thresholds <span class="math inline">\(s\)</span> such that the data are divided into</p>
<p><span class="math display">\[
\text { Left: } x_j \leq s, \quad \text { Right: } x_j&gt;s .
\]</span></p>
<p>For categorical features, the split divides categories into two subsets.</p>
<p>For each candidate split, the algorithm calculates the impurity reduction, which measures how much the new partition improves the homogeneity of the outcome:</p>
<p><span class="math display">\[
\Delta I=I(\text { parent })-\frac{n_L}{n_{\text {parent }}} I(\text { left })-\frac{n_R}{n_{\text {parent }}} I(\text { right }),
\]</span></p>
<p>where <span class="math inline">\(I(\cdot)\)</span> is the impurity index: - variance for regression, - Gini or entropy for classification.</p>
<p>The split that yields the largest reduction in impurity is selected. 3. Creating new nodes (splitting)</p>
<p>Once the best feature and threshold are chosen: - The parent node is replaced by two child nodes (left and right). - Each child node now represents a subset of the data that satisfies one side of the if/else rule. - The prediction for each child node is recalculated as the mean (regression) or class proportion (classification).</p>
<p>This process is repeated recursively for each child node. At each step, the algorithm searches again for the best local split to further reduce impurity within that node.</p>
<ol start="4" type="1">
<li>Stopping criteria (when to stop growing)</li>
</ol>
<p>The tree keeps expanding until one or more stopping conditions are met: - The node contains fewer than a minimum number of observations ( minsplit , minbucket ). - The reduction in impurity from a new split is below a threshold ( cp in rpart ). - The tree has reached a maximum depth ( maxdepth ). - All observations in the node have identical responses.</p>
<p>When a node can no longer be split under these rules, it becomes a terminal node or leaf. 5. Cost-complexity pruning (simplifying the tree)</p>
<p>Fully grown trees tend to overfit: they capture noise as if it were signal. To restore generalization, CART uses cost-complexity pruning. This involves fitting a large tree first, then sequentially removing the least useful branches according to the criterion</p>
<p><span class="math display">\[
R_\alpha(T)=\operatorname{RSS}(T)+\alpha|T|,
\]</span></p>
<p>where <span class="math inline">\(|T|\)</span> is the number of terminal nodes and <span class="math inline">\(\alpha \geq 0\)</span> penalizes complexity. Cross-validation identifies the optimal penalty <span class="math inline">\(\alpha^*\)</span>. The 1-SE rule then selects the smallest subtree whose error is within one standard error of the minimum, balancing accuracy and simplicity. 6. Prediction</p>
<p>Once the tree is built (and possibly pruned), prediction for a new observation is simple: 1. Start at the root. 2. Follow the if/else path defined by its feature values (e.g., “if dose_intensity &lt; 0.9 go left, else go right”). 3. When a leaf is reached, return the value stored there: - for regression: the mean response in that region; - for classification: the majority class or probability.</p>
<p>This process is deterministic and interpretable: each prediction can be traced to a specific logical path. 7. Visual summary of the process</p>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Stage</th>
<th style="text-align: left;">Description</th>
<th style="text-align: left;">Typical R function element</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Initialization</strong></td>
<td style="text-align: left;">Root node with all data</td>
<td style="text-align: left;">automatic in <code>rpart()</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Growing</strong></td>
<td style="text-align: left;">Repeatedly searches for the split minimizing node impurity</td>
<td style="text-align: left;">controlled by <code>minsplit</code>, <code>maxdepth</code>, <code>cp</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Splitting</strong></td>
<td style="text-align: left;">Partitions data and creates left/right child nodes</td>
<td style="text-align: left;">recursive calls within <code>rpart()</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Stopping</strong></td>
<td style="text-align: left;">Halts if no improvement or nodes are too small</td>
<td style="text-align: left;"><code>minbucket</code>, <code>cp</code> threshold</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Pruning</strong></td>
<td style="text-align: left;">Removes overfitted branches using cost–complexity pruning</td>
<td style="text-align: left;"><code>prune()</code> + cross-validation</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Prediction</strong></td>
<td style="text-align: left;">Applies learned rules to new data</td>
<td style="text-align: left;"><code>predict()</code></td>
</tr>
</tbody>
</table>
<p><strong>Note:</strong> Single decision trees can easily overfit the training data; we’ll use pruning (and later ensembles) to control this.</p>
</section>
</section>
</section>
<section id="trees-for-regression-and-classification-cart" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="trees-for-regression-and-classification-cart"><span class="header-section-number">3.7</span> Trees for regression and classification (CART)</h2>
<p>Decision trees can solve both regression and classification tasks within a single framework historically called CART (Classification and Regression Trees). CART is a trademark. The idea is to approximate the unknown function <span class="math inline">\(f(\mathbf{X})\)</span> by splitting the feature space into rectangular regions and predicting a constant within each region (a leaf).</p>
<p>For regression, as in our chemotherapy example where the response is continuous ( response_percent ), the tree chooses splits that reduce the within-node variance. If a node contains samples <span class="math inline">\(S\)</span>, its impurity is</p>
<p><span class="math display">\[
I_{\mathrm{reg}}(S)=\frac{1}{|S|} \sum_{i \in S}\left(y_i-\bar{y}_S\right)^2,
\]</span></p>
<p>and the “best” split is the one that maximizes the reduction in impurity (variance) after partitioning <span class="math inline">\(S\)</span> into left/right children.</p>
<p>For classification, e.g., if we instead predict the binary label high_response ( <span class="math inline">\(\geq 30 \% \mathrm{vs}&lt;30 \%\)</span> ), CART typically measures impurity using the Gini index (or entropy). If a node has class proportions <span class="math inline">\(\left\{p_k\right\}_{k=1}^K\)</span>,</p>
<p><span class="math display">\[
I_{\mathrm{cls}}^{\mathrm{Gini}}(S)=1-\sum_{k=1}^K p_k^2, \quad I_{\mathrm{cls}}^{\mathrm{Ent}}(S)=-\sum_{k=1}^K p_k \log _2 p_k .
\]</span></p>
<p>The algorithm selects the feature and threshold that yield the largest impurity reduction (a.k.a. information gain for entropy, Gini gain for Gini). Although trees are nonlinear in the inputs, they are linear in indicator functions of regions:</p>
<p><span class="math display">\[
\hat{f}(\mathbf{X})=\sum_{m=1}^M c_m \mathbf{1}\left\{\mathbf{X} \in R_m\right\}
\]</span></p>
<p>with one constant <span class="math inline">\(c_m\)</span> per leaf <span class="math inline">\(R_m\)</span>. In our context, each path (“if dose_intensity <span class="math inline">\(\leq 0.9\)</span> and gene_14 <span class="math inline">\(&gt;\)</span> 1.0 then …”) maps to a region with a clinically interpretable average prediction-mean tumor shrinkage for regression, or class probability for classification.</p>
<section id="how-the-rpart-algorithm-learns-a-tree" class="level3" data-number="3.7.1">
<h3 data-number="3.7.1" class="anchored" data-anchor-id="how-the-rpart-algorithm-learns-a-tree"><span class="header-section-number">3.7.1</span> How the rpart algorithm learns a tree</h3>
<p>How the rpart algorithm learns a tree The rpart algorithm (recursive partitioning) is an open-source implementation of the CART family. It learns a tree greedily, one split at a time, choosing at each node the feature and cut-point that most improve node purity.</p>
<p>Split selection (objective). At a node with samples <span class="math inline">\(S\)</span>, rpart scans all predictors <span class="math inline">\(x_j\)</span> and candidate split points <span class="math inline">\(s\)</span>, evaluates the impurity of the left child <span class="math inline">\(S_L=\left\{i: x_{i j} \leq s\right\}\)</span> and right child <span class="math inline">\(S_R=\left\{i: x_{i j}&gt;s\right\}\)</span>, and picks <span class="math inline">\(\left(j^*, s^*\right)\)</span> that maximizes the impurity reduction</p>
<p><span class="math display">\[
\Delta I=I(S)-\frac{\left|S_L\right|}{|S|} I\left(S_L\right)-\frac{\left|S_R\right|}{|S|} I\left(S_R\right) .
\]</span></p>
<ul>
<li>For regression (our response_percent target), <span class="math inline">\(I(\cdot)\)</span> is variance.</li>
<li>For classification (e.g., high_response), <span class="math inline">\(I(\cdot)\)</span> is usually Gini (default) or entropy.</li>
</ul>
<p>Continuous vs.&nbsp;categorical predictors. - Continuous variables (e.g., dose_intensity , gene_14 ) are split at thresholds. Practically, rpart considers cut-points at midpoints between sorted unique values; each candidate produces a left/right partition, and the best <span class="math inline">\(\Delta I\)</span> wins. - Categorical variables (e.g., tumor_grade with levels G1/G2/G3) are handled by creating a binary partition of levels. rpart orders levels by class composition (for classification) or node means (for regression) and evaluates adjacent two-group splits without trying all <span class="math inline">\(2^{m-1}-1\)</span> combinations. - No scaling is required: decisions depend on orderings, not magnitudes.</p>
<p>From our examples. - In the toy regression, the true rule is: if <span class="math inline">\(X_1 \leq 4\)</span> then <span class="math inline">\(y \approx 5\)</span>; else if <span class="math inline">\(X_2 \leq 0\)</span> then <span class="math inline">\(y \approx 10\)</span>; else <span class="math inline">\(y \approx\)</span> 14. rpart rediscovers this by choosing the vari <span class="math inline">\(\downarrow\)</span>, e-reducing thresholds on <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. - In the clinical dataset, rpart selected thresholds on gene_14, gene_08, and gene_19 that create leaves whose means trace a clinically plausible gradient of tumor shrinkage.</p>
<p>Stopping and pruning. Left unchecked, greedy splitting makes overly deep, high-variance trees. rpart controls complexity in two ways: - Top-down stops: hyperparameters such as minsplit , minbucket , and maxdepth prevent tiny or overly deep nodes. - Cost-complexity pruning: rpart grows a large tree, computes a sequence of subtrees indexed by the complexity parameter cp , and uses internal cross-validation to estimate the error ( printcp , plotcp). Selecting the 1-SE cp yields a simpler subtree whose error is within one standard error of the minimum, improving generalization.</p>
<p>Missing data &amp; surrogate splits. If a case is missing the variable used at a node (say gene_14 ), rpart can route it using surrogate splits -backup variables that tend to make the same partition (controlled by usesurrogate, maxsurrogate ). This is practical in clinical datasets with sporadic biomarker gaps.</p>
<p>Why this matters for our course.</p>
<ul>
<li><p>For regression (our primary task), trees optimize variance reduction, giving piecewise-constant predictions that capture thresholds and interactions without manual feature engineering.</p></li>
<li><p>For classification (secondary task with high_response), trees optimize Gini/entropy, naturally handling multi-class extensions and unscaled predictors.</p></li>
<li><p>Understanding rpart’s split logic (variance, Gini), candidate generation (midpoints, level partitions), and pruning (cp &amp; 1-SE) demystifies how the if/else rules are learned from data.</p></li>
</ul>
</section>
<section id="hyperparameters-for-decision-trees-rpart-what-why-how" class="level3" data-number="3.7.2">
<h3 data-number="3.7.2" class="anchored" data-anchor-id="hyperparameters-for-decision-trees-rpart-what-why-how"><span class="header-section-number">3.7.2</span> Hyperparameters for decision trees (rpart): what, why, how</h3>
<p>Tree growth is intentionally greedy and, left unconstrained, will overfit. In rpart, model complexity is governed by a small set of <code>hyperparameters-values</code> that control learning but are not learned from the data. Tuning them is crucial for generalization.</p>
<p>Consider again the equation</p>
<p><span class="math display">\[Y=f\left(x_1, x_2, \ldots, x_n\right)+ error\]</span></p>
<p>A hyperparameter is a setting that controls how <span class="math inline">\(f\)</span> is learned, not something learned directly from the data by the usual fitting step. Hyperparameters define the shape/complexity of the function class you allow and how aggressively you search within it. They live outside <span class="math inline">\(f\)</span>, but they constrain and guide the learning of <span class="math inline">\(f\)</span>.</p>
<p>What they control (regression <span class="math inline">\(\&amp;\)</span>classification)</p>
<ul>
<li>minsplit</li>
</ul>
<p>Minimum number of cases required in a node to consider a split. Larger values make the tree more conservative (fewer splits). - minbucket</p>
<p>Minimum number of cases in each terminal node (leaf). Often set near floor(minsplit/3). - maxdepth</p>
<p>Maximum number of splits along any root-to-leaf path (tree height). Caps interactions/complexity. - cp (complexity parameter)</p>
<p>Minimum relative improvement required to add a split. Also indexes the cost-complexity pruning sequence (printcp , plotcp). - xval</p>
<p>Number of folds for rpart’s internal cross-validation to estimate out-of-sample error along the pruning path. - parms (classification only)</p>
<p>Split criterion: parms = list(split = “gini”) (default) or parms = list(split = “information”) (entropy). - usesurrogate, maxsurrogate</p>
<p>Handling of missing data via surrogate splits (useful in clinical/omics tables with sporadic NAs).</p>
<p>Which impurity? - Regression ( method = “anova” ): variance reduction. - Classification ( method = “class” ): Gini (default) or entropy via parms.</p>
</section>
</section>
<section id="running-a-tree-for-our-chemotherapy-example" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="running-a-tree-for-our-chemotherapy-example"><span class="header-section-number">3.8</span> Running a tree for our chemotherapy example</h2>
<p>We will use the function <code>rpart</code> of the rpart package to implement the tree for our chemothreapy case. Recall that we will be explaining response_percente in terms of the all other variables in the data that are of our interest <code>response_percent ~ .</code></p>
<p>The code in the next two chunks first grows a CART regression tree to predict response_percent from all available predictors in train_nopii. We use method = “anova”, which means each split is chosen to reduce within-node variance of the continuous outcome. The control list sets three guardrails that shape the initial tree: cp = 0.001 allows the tree to keep growing as long as each additional split reduces the resubstitution error by at least 0.1%; maxdepth = 8 caps the number of successive decisions along any root-to-leaf path; and minsplit = 30 prevents the algorithm from splitting nodes that hold fewer than 30 training cases. With these settings the model is encouraged to discover structure but not to chase tiny, sample-specific patterns. After fitting, printcp(ct_tree) reports the cost–complexity pruning path. Each row summarizes a candidate subtree obtained by pruning the large tree at a given complexity parameter CP CP. The columns have specific meanings. nsplit is the number of internal splits in that subtree. rel error is the training (resubstitution) error of that subtree relative to the root node error. xerror is the cross-validated error (here from rpart’s built-in K-fold procedure), again on the same relative scale, and xstd is its standard error across folds. In your run, the root node error is shown at the top (“Root node error: 2448864/6999 = 349.89”), which is simply the total sum of squared residuals divided by n n when predicting the overall mean. As the tree grows from nsplit = 0 to nsplit = 13, rel error falls monotonically, while xerror drops quickly and then flattens, indicating diminishing returns from additional complexity. To select a final model that favors parsimony without sacrificing predictive accuracy, the code applies the 1-SE rule. It locates the row with the minimum cross-validated error (xerr_min) and then chooses the smallest subtree whose xerror is within one standard error (xstd_min) of that minimum. The corresponding CP value (cp_1se) defines how aggressively the tree is pruned. prune(ct_tree, cp = cp_1se) returns this compact subtree as ct_pruned. Conceptually, this step trims away branches that improve apparent fit on the training set but do not demonstrably improve out-of-sample performance beyond sampling variability. The two rpart.plot calls draw the grown and pruned trees. Internal nodes display the chosen split conditions; leaves display the predicted outcome (the mean response_percent among training cases in that terminal region) and support counts. Comparing the “grown” and “pruned” plots makes the effect of pruning tangible: superfluous lower-level branches disappear, leaving a smaller set of clinically interpretable rules. For a human-readable summary of those rules, rpart.rules(ct_pruned, style = “tallw”) prints each root-to-leaf path as a nested “when … then …” statement. Your output shows that the pruned tree uses three molecular predictors gene_14, gene_08, and gene_19 to partition the cohort. Thresholds on these continuous features define rectangular regions of the predictor space, and each region has an associated predicted response. For example, when gene_14 &lt; -0.728 and gene_19 &lt; -0.65, the model predicts a mean shrinkage of about 0.97 percentage points; when gene_14 ≥ 0.977 and gene_08 ≥ 2.03, it predicts about 62.68 percentage points. The intermediate leaves trace a graded pattern: as gene_14 and gene_08 thresholds increase and gene_19 crosses its cut-points the predicted response_percent rises through roughly 6.31, 12.83, 20.28, 28.76, 37.38, 47.20, and 53.02 before reaching the top stratum. This staircase behavior reflects the piecewise-constant nature of a regression tree: within each leaf the prediction is constant, and it jumps at the learned split boundaries. Finally, the evaluation chunk applies the pruned tree to both training and test data and summarizes predictive error via MAE and RMSE. The training set errors (MAE ≈ 2.31, RMSE ≈ 3.03) and the held-out test set errors (MAE ≈ 2.43, RMSE ≈ 3.21) are close in magnitude, which is the hallmark of a model that generalizes reasonably well without obvious overfitting. The slight increase on the test set is expected; the absence of a large gap suggests that the 1-SE pruning achieved a good bias–variance balance for this dataset. These results can be obtained running the next chunks.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Grow a CART regression tree</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>ct_tree <span class="ot">&lt;-</span> <span class="fu">rpart</span>(</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  response_percent <span class="sc">~</span> .,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train_nopii,</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"anova"</span>,</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">rpart.control</span>(<span class="at">cp =</span> <span class="fl">0.001</span>, <span class="at">maxdepth =</span> <span class="dv">8</span>, <span class="at">minsplit =</span> <span class="dv">30</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Prune via 1-SE rule</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="fu">printcp</span>(ct_tree)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Regression tree:
rpart(formula = response_percent ~ ., data = train_nopii, method = "anova", 
    control = rpart.control(cp = 0.001, maxdepth = 8, minsplit = 30))

Variables actually used in tree construction:
[1] gene_08 gene_14 gene_19

Root node error: 2448864/6999 = 349.89

n= 6999 

          CP nsplit rel error   xerror       xstd
1  0.7924745      0  1.000000 1.000227 0.01081767
2  0.0826816      1  0.207526 0.209410 0.00397193
3  0.0455275      2  0.124844 0.126561 0.00236147
4  0.0159802      3  0.079316 0.081182 0.00179474
5  0.0138112      4  0.063336 0.067376 0.00134407
6  0.0057965      5  0.049525 0.052308 0.00106611
7  0.0036277      6  0.043729 0.046388 0.00096049
8  0.0031558      7  0.040101 0.042604 0.00091233
9  0.0030375      8  0.036945 0.039700 0.00087026
10 0.0029545      9  0.033908 0.038201 0.00083974
11 0.0022781     10  0.030953 0.033671 0.00067939
12 0.0012786     11  0.028675 0.031293 0.00062538
13 0.0010818     12  0.027396 0.030282 0.00060776
14 0.0010000     13  0.026315 0.029300 0.00059060</code></pre>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>best_row <span class="ot">&lt;-</span> <span class="fu">which.min</span>(ct_tree<span class="sc">$</span>cptable[,<span class="st">"xerror"</span>])</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>xerr_min <span class="ot">&lt;-</span> ct_tree<span class="sc">$</span>cptable[best_row, <span class="st">"xerror"</span>]</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>xstd_min <span class="ot">&lt;-</span> ct_tree<span class="sc">$</span>cptable[best_row, <span class="st">"xstd"</span>]</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>cp_1se   <span class="ot">&lt;-</span> ct_tree<span class="sc">$</span>cptable[ct_tree<span class="sc">$</span>cptable[,<span class="st">"xerror"</span>] <span class="sc">&lt;=</span> xerr_min <span class="sc">+</span> xstd_min, <span class="st">"CP"</span>][<span class="dv">1</span>]</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>ct_pruned <span class="ot">&lt;-</span> <span class="fu">prune</span>(ct_tree, <span class="at">cp =</span> cp_1se)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Human-readable rules (if/else)</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>rpart.plot<span class="sc">::</span><span class="fu">rpart.rules</span>(ct_pruned, <span class="at">style =</span> <span class="st">"tallw"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>response_percent is  0.97 when
                          gene_14 &lt; -0.728
                          gene_19 &lt; -0.65

response_percent is  6.31 when
                          gene_14 is -0.728 to 0.014
                          gene_19 &lt; -0.65

response_percent is  8.17 when
                          gene_14 &lt; -0.523
                          gene_08 &lt; -0.37
                          gene_19 &gt;= -0.65

response_percent is 12.83 when
                          gene_14 is -0.523 to 0.014
                          gene_08 &lt; -0.37
                          gene_19 &gt;= -0.65

response_percent is 15.29 when
                          gene_14 &lt; 0.014
                          gene_08 &gt;= -0.37
                          gene_19 is -0.65 to -0.18

response_percent is 20.28 when
                          gene_14 &lt; 0.014
                          gene_08 &gt;= -0.37
                          gene_19 &gt;= -0.18

response_percent is 23.26 when
                          gene_14 is 0.014 to 0.977
                          gene_08 &lt; 0.25
                          gene_19 &lt; 0.46

response_percent is 28.76 when
                          gene_14 is 0.014 to 0.977
                          gene_08 &gt;= 0.25
                          gene_19 &lt; 0.46

response_percent is 32.26 when
                          gene_14 is 0.014 to 0.977
                          gene_08 &lt; 0.71
                          gene_19 &gt;= 0.46

response_percent is 37.38 when
                          gene_14 is 0.014 to 0.977
                          gene_08 &gt;= 0.71
                          gene_19 &gt;= 0.46

response_percent is 41.61 when
                          gene_14 &gt;= 0.977
                          gene_08 &lt; 1.56
                          gene_19 &lt; 1.25

response_percent is 47.20 when
                          gene_14 &gt;= 0.977
                          gene_08 &lt; 1.56
                          gene_19 &gt;= 1.25

response_percent is 53.02 when
                          gene_14 &gt;= 0.977
                          gene_08 is 1.56 to 2.03

response_percent is 62.68 when
                          gene_14 &gt;= 0.977
                          gene_08 &gt;= 2.03</code></pre>
</div>
</div>
<section id="printing-the-trees" class="level3" data-number="3.8.1">
<h3 data-number="3.8.1" class="anchored" data-anchor-id="printing-the-trees"><span class="header-section-number">3.8.1</span> Printing the trees</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize grown and pruned trees</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(ct_tree, <span class="at">type =</span> <span class="dv">2</span>, <span class="at">extra =</span> <span class="dv">101</span>, <span class="at">box.palette =</span> <span class="st">"Blues"</span>,</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>           <span class="at">main =</span> <span class="st">"Clinical trial tree (grown)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="three_methods_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(ct_pruned, <span class="at">type =</span> <span class="dv">2</span>, <span class="at">extra =</span> <span class="dv">101</span>, <span class="at">box.palette =</span> <span class="st">"GnBu"</span>,</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>           <span class="at">main =</span> <span class="st">"Clinical trial tree (pruned, 1-SE)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="three_methods_files/figure-html/unnamed-chunk-12-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<section id="interpreting-the-grown-and-pruned-trees" class="level4" data-number="3.8.1.1">
<h4 data-number="3.8.1.1" class="anchored" data-anchor-id="interpreting-the-grown-and-pruned-trees"><span class="header-section-number">3.8.1.1</span> Interpreting the grown and pruned trees</h4>
<p>The two plots visualize successive stages of the same model. The first represents the grown tree-the full structure obtained when the algorithm keeps splitting the data as long as it finds any measurable reduction in node impurity. The second shows the pruned tree, obtained after applying the 1-SE rule of cost-complexity pruning, which removes branches that do not materially improve cross-validated performance.</p>
<p>In the grown tree, the structure is deeper and more branched. Each internal node corresponds to a binary decision of the form “Is gene <span class="math inline">\({ }_{(\mathrm{j})} \leq \mathrm{s}\)</span> ?”, and each terminal node (leaf) stores the mean value of response_percent among observations satisfying that sequence of conditions. The abundance of splits reflects the model’s flexibility: by recursively partitioning the data into small, homogeneous subsets, the tree can achieve very low training error. However, such detailed partitioning often adapts to random noise or idiosyncratic fluctuations in the sample-a phenomenon known as overfitting. The grown tree therefore fits the training set extremely well but may generalize poorly to new patients.</p>
<p>The pruned tree, by contrast, is shallower and more compact. Pruning starts from the large tree and iteratively removes branches that contribute the least to predictive accuracy, as measured by crossvalidated error. The 1-SE rule selects the simplest subtree whose error is within one standard error of the minimum observed, trading a negligible increase in bias for a substantial reduction in variance. In practice, this yields a model that performs almost as well on unseen data but is far more stable and interpretable. In the chemotherapy dataset, the pruned tree retains only the strongest and most reproducible thresholds-those involving, for example, gene_14 , gene_08 , and gene_19 -which together define a hierarchy of molecular conditions associated with different levels of tumor response.</p>
<p>Each box in the plots displays the predicted mean (the constant <span class="math inline">\(\hat{y}\)</span> for that region) and the number of cases supporting that leaf. In the pruned tree, leaves are larger (more patients per region) and predictions vary more smoothly, reflecting a coarser but more reliable partition of the predictor space. The disappearance of lower-level branches illustrates how pruning merges overly specific regions back into their parents, simplifying the decision rules.</p>
<p>The human-readable output produced by</p>
<pre><code>rpart.rules(ct_pruned, style = "tallw")</code></pre>
<p>translates each root-to-leaf path into an explicit if-else statement, such as:</p>
<p>When gene_14 &lt; -0.73 and gene_19 &lt; -0.65, predict response_percent <span class="math inline">\(\approx 1.0\)</span>; when gene_14 <span class="math inline">\(\geq 0.98\)</span> and gene_08 <span class="math inline">\(\geq 2.03\)</span>, predict <span class="math inline">\(\approx 62.7\)</span>.</p>
<p>These rules correspond exactly to the leaves of the pruned tree and can be read as localized predictive statements: each describes a subpopulation with a characteristic mean response.</p>
<p>In summary, the grown tree shows everything the recursive partitioning algorithm could learn from the data, while the pruned tree shows what it should retain to balance interpretability and predictive reliability. The pruned version embodies the principle of parsimonious generalization-capturing the dominant structure in the data without chasing noise-an essential practice in applying machinelearning models to clinical and therapeutic contexts.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>pred_tr <span class="ot">&lt;-</span> <span class="fu">predict</span>(ct_pruned, <span class="at">newdata =</span> train_nopii)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>pred_te <span class="ot">&lt;-</span> <span class="fu">predict</span>(ct_pruned, <span class="at">newdata =</span> test_nopii)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>perf <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">bind_rows</span>(</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">Split=</span><span class="st">"Train"</span>, <span class="at">MAE=</span><span class="fu">mae</span>(train_nopii<span class="sc">$</span>response_percent, pred_tr),</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">RMSE=</span><span class="fu">rmse</span>(train_nopii<span class="sc">$</span>response_percent, pred_tr)),</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">Split=</span><span class="st">"Test"</span>,  <span class="at">MAE=</span><span class="fu">mae</span>(test_nopii<span class="sc">$</span>response_percent,  pred_te),</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">RMSE=</span><span class="fu">rmse</span>(test_nopii<span class="sc">$</span>response_percent,  pred_te))</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>perf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 3
  Split   MAE  RMSE
  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;
1 Train  2.31  3.03
2 Test   2.43  3.21</code></pre>
</div>
</div>
<p>It is useful to build the following graphic about the model too</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">truth =</span> test_nopii<span class="sc">$</span>response_percent, <span class="at">pred =</span> pred_te),</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(truth, pred)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.35</span>) <span class="sc">+</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Observed response_percent"</span>, <span class="at">y =</span> <span class="st">"Tree prediction"</span>,</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Pruned tree: observed vs predicted (test)"</span>) <span class="sc">+</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="three_methods_files/figure-html/ct-tree-obs-vs-pred-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>The diagonal dashed line marks perfect calibration. The cloud of points hugging this line indicates that, on average, the pruned tree predicts within a small error margin on unseen data, consistent with the MAE/RMSE reported earlier. The horizontal bands are characteristic of regression trees: within each leaf the prediction is a single constant, so many cases share the same ŷ even when their observed values differ; each band corresponds to one leaf’s mean response. Vertical spread around the diagonal within a band reflects the within-leaf variance (irreducible noise plus any misspecification). At low and high ends you may notice slight deviations due to boundary effects (responses constrained near 0 or high shrinkage). Overall, proximity to the 45° line and relatively balanced dispersion across the range suggest the pruned tree achieves a good bias–variance trade-off on the test set.</p>
</section>
</section>
</section>
<section id="solutions-for-trees-problems" class="level2" data-number="3.9">
<h2 data-number="3.9" class="anchored" data-anchor-id="solutions-for-trees-problems"><span class="header-section-number">3.9</span> Solutions for trees problems</h2>
<p>Decision trees are among the most intuitive predictive models in machine learning. They partition the predictor space using simple, rule-based splits, producing a structure that is easy to interpret and explain. This transparency makes trees attractive in settings where clarity and decision logic matter such as clinical environments, quality assurance, or regulatory discussions. However, the strengths of a single tree are also its weaknesses. Trees are unstable: small fluctuations in the training data can lead to large changes in the learned structure. A model that splits first on tumour grade in one sample might split first on age or dose intensity in another, even if the underlying population signal is the same. Decision trees are also prone to overfitting, especially when grown deep. They can “memorize” noise, rare patterns, or outliers, achieving excellent accuracy on the training set while generalizing poorly to new patients. These limitations appear clearly in our running example: predicting response_percent in a chemotherapy trial using clinical covariates plus approximately 2,000 gene expression variables (after removing the columns you excluded earlier). A single tree can indeed learn meaningful rules dose intensity thresholds, gene expression activation points, or interactions between tumour grade and age but it may also capture highly specific patterns that do not repeat in unseen data. As complexity grows, the risk increases that the tree fits patient-specific noise rather than biologically grounded structure. A powerful solution is to move from relying on one tree to combining many. This shift from a solitary model to a coordinated collection of models is known as ensemble learning. Ensembles reduce instability, limit overfitting, and yield predictions that are more reliable and accurate. They leverage the simple idea that while individual trees may be noisy or inconsistent, the aggregate of many trees can reveal the true underlying signal.</p>
</section>
<section id="ensemble-techniques" class="level2" data-number="3.10">
<h2 data-number="3.10" class="anchored" data-anchor-id="ensemble-techniques"><span class="header-section-number">3.10</span> Ensemble techniques</h2>
<p>Ensemble methods are a family of strategies in which multiple models often weak, unstable, or low-capacity learners are trained and then combined to produce a stronger predictor. The guiding principle is straightforward:</p>
<blockquote class="blockquote">
<p>Instead of trusting a single model’s view of the data, we consult many models and integrate their insights.</p>
</blockquote>
<p>This idea mirrors how groups often make decisions: diverse perspectives, when aggregated sensibly, tend to outperform any single viewpoint. In machine learning, ensembles achieve this by reducing variance, reducing bias, or exploiting complementary strengths across different algorithms.</p>
<p>While ensemble learning can be applied to any type of model, trees are particularly well suited for it. Their instability makes them ideal candidates: many slightly different trees, trained on varied samples or focused on different aspects of the data, can collectively smooth out one another’s mistakes.</p>
<p>A central tool behind many ensemble methods is&nbsp;<strong>bootstrapping</strong> drawing multiple datasets by sampling with replacement from the original training data. Each bootstrap sample contains a slightly different mix of observations: some patients appear multiple times, some not at all. Training a model on each of these bootstrap samples produces a collection of slightly different learners. When we&nbsp;<strong>aggregate</strong>&nbsp;their predictions (for example, by averaging in regression), random fluctuations tend to cancel out, and the ensemble becomes more stable than any single model.</p>
<p>This combination of&nbsp;<strong>bootstrap sampling</strong>&nbsp;and&nbsp;<strong>aggregation</strong>&nbsp;is known as&nbsp;<strong>bootstrap aggregating</strong>, or&nbsp;<strong>bagging</strong>. Bagging is particularly effective for high-variance models such as decision trees: instead of one tree that may overreact to idiosyncrasies in the data, we obtain many trees, each seeing a slightly different world, and we average their predictions to reduce variance.</p>
<p>Ensemble strategies come in several forms, with three major families commonly used in practice:</p>
<ul>
<li><p><strong>Bagging</strong>, which uses bootstrap sampling to create many resampled versions of the training set, trains a separate model on each, and then aggregates their predictions. This primarily reduces&nbsp;<strong>variance</strong>, stabilizing unstable learners such as trees. This approach is used by random forest models.</p></li>
<li><p><strong>Boosting</strong>, which reduces&nbsp;<strong>bias</strong>&nbsp;(and often variance) by training models sequentially, each one focusing on the errors or residuals of the current ensemble and gradually improving performance.</p></li>
<li><p><strong>Stacking</strong>, which learns how to combine the predictions of&nbsp;<strong>diverse algorithms</strong>&nbsp;through a meta-model that takes their outputs as inputs and learns an optimal way to blend them.</p></li>
</ul>
<p>Before exploring these families in detail, it is crucial to understand that all ensemble methods share the same foundational principle:&nbsp;multiple models, when combined thoughtfully, can achieve higher accuracy, greater stability, and better generalization than any single model acting alone. Bootstrapping and aggregation in bagging provide a concrete and widely used example of how this principle is implemented in practice.</p>
<section id="training-models-on-sampled-data-bootstrap-aggregating-bagging" class="level3" data-number="3.10.1">
<h3 data-number="3.10.1" class="anchored" data-anchor-id="training-models-on-sampled-data-bootstrap-aggregating-bagging"><span class="header-section-number">3.10.1</span> Training models on sampled data: Bootstrap Aggregating (Bagging)</h3>
<p>Machine learning models especially decision trees can be sensitive to noise, outliers, and small sampling fluctuations. In clinical and biomedical datasets, this instability becomes even more pronounced: measurement error, biological heterogeneity, and uneven sampling across patient subgroups can all lead a single model to overfit.</p>
<p>In our running example, where we aim to predict&nbsp;<strong>response_percent</strong>&nbsp;using clinical covariates and approximately&nbsp;<strong>2,000 gene expression features</strong>, a single decision tree may latch onto idiosyncratic patterns that do not generalize beyond the training patients.</p>
<p><strong>Bootstrap aggregating</strong>, or&nbsp;<strong>bagging</strong>, is a technique designed to address this problem. The idea is straightforward: instead of training one model on one dataset, we train many variations of the same model on many slightly different datasets, each created by a random resampling technique named bootstrap, and then combine (aggregate) their outputs. By averaging over many high-variance learners, bagging produces predictions that are more stable, more accurate, and less sensitive to noise.</p>
<div id="bagging" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/bagging_1.png" class="img-fluid figure-img"></p>
<figcaption>Schematic explanation on bagging.</figcaption>
</figure>
</div>
</section>
<section id="how-bagging-works" class="level3" data-number="3.10.2">
<h3 data-number="3.10.2" class="anchored" data-anchor-id="how-bagging-works"><span class="header-section-number">3.10.2</span> <strong>How bagging works</strong></h3>
<p>The bagging workflow can be summarized in five steps:</p>
<ol type="1">
<li><p><strong>Choose how many sub-models to train</strong>&nbsp;(for example, 200 trees).</p></li>
<li><p><strong>Draw a bootstrap sample</strong>&nbsp;for each sub-model by sampling patients&nbsp;<em>with replacement</em>&nbsp;from the training set until the sample is the same size as the original training data.</p>
<ul>
<li><p>Some patients appear multiple times.</p></li>
<li><p>Some are not selected at all.</p></li>
</ul></li>
<li><p><strong>Train a sub-model on each bootstrap sample.</strong></p>
<ul>
<li>In our setting: a decision tree trained on a resampled set of patients with resampled gene expression profiles.</li>
</ul></li>
<li><p><strong>Generate predictions for new data using every sub-model.</strong></p></li>
<li><p><strong>Aggregate the predictions.</strong></p>
<ul>
<li><p>For regression (our task): take the&nbsp;<strong>mean</strong>&nbsp;of the predicted values.</p></li>
<li><p>For classification: take the&nbsp;<strong>majority vote</strong>.</p></li>
</ul></li>
</ol>
<p>The critical mechanism is the&nbsp;<strong>bootstrap sampling</strong>&nbsp;itself. When sampling with replacement, cases near the center of the data distribution tend to be selected more frequently than rare or extreme observations. Some bootstrap datasets will contain more extreme cases than others; some trees will fit these extremes poorly. But when aggregated, these idiosyncrasies tend to cancel out. The ensemble prediction is effectively an&nbsp;<strong>average across many plausible models</strong>, each capturing different aspects of the training data.</p>
<p>The net effect is a substantial&nbsp;<strong>reduction in variance</strong> the component of prediction error driven by model instability.</p>
</section>
<section id="why-bagging-helps-in-our-chemotherapy-trial-case-study" class="level3" data-number="3.10.3">
<h3 data-number="3.10.3" class="anchored" data-anchor-id="why-bagging-helps-in-our-chemotherapy-trial-case-study"><span class="header-section-number">3.10.3</span> <strong>Why bagging helps in our chemotherapy-trial case study</strong></h3>
<p>In the chemotherapy response dataset, decision trees face three major challenges:</p>
<ul>
<li><p><strong>High dimensionality:</strong>&nbsp;thousands of gene expressions.</p></li>
<li><p><strong>Measurement noise:</strong>&nbsp;assay variability, heterogeneous tumour biology.</p></li>
<li><p><strong>Complex interactions:</strong>&nbsp;clinical and molecular variables interact in ways that are hard to model with a single tree.</p></li>
</ul>
<p>A single deep tree may overfit heavily detecting spurious splits driven by noisy gene measurements or by small patient subgroups. Bagging mitigates this risk by averaging many such trees, each trained on a slightly different bootstrap sample. Trees that “overreact” to particular patients or gene-expression artefacts have their influence diminished when averaged with hundreds of others.</p>
<p>For this reason, a bagged ensemble of trees often forms a far more robust predictor than any individual tree, especially in biomedical datasets where high-variance learning is a known challenge.</p>
<p>As you will see later, the Random Forest algorithm builds directly on this idea: it is essentially bagging with an additional layer of randomness, making it one of the most powerful and widely used tree-based ensemble models in modern machine learning.</p>
</section>
<section id="learning-from-previous-models-mistakes-boosting" class="level3" data-number="3.10.4">
<h3 data-number="3.10.4" class="anchored" data-anchor-id="learning-from-previous-models-mistakes-boosting"><span class="header-section-number">3.10.4</span> Learning from Previous Models’ Mistakes: Boosting</h3>
<p>Where bagging creates many models in parallel and averages their predictions to reduce variance, boosting takes a different approach. Boosting also builds an ensemble of models, but does so sequentially, allowing each new model to focus specifically on the errors left behind by the models that came before it. The core idea is simple: start with a rough model, identify where it performs poorly, and train the next model to correct those mistakes. Repeating this process many times gradually produces a highly accurate and flexible predictor.</p>
<p>Just as bagging can be applied to a wide range of supervised learning algorithms, boosting is also a general framework. However, it is especially effective when using weak learners-models that are individually simple and only slightly better than random guessing. In practice, this typically means shallow decision trees, often trees with only a few levels of depth or even trees with a single split. These minimal trees are fast to train, easy to update, and-when used in large numbers-combine to form surprisingly powerful models.</p>
<p>The motivation for using weak learners is efficiency: boosting does not benefit from repeatedly training deep, complex trees. The strength of the ensemble comes from the sequence of corrections, not from any individual model. In our chemotherapy-response example, using shallow trees allows the boosting algorithm to slowly uncover clinical or molecular patterns-first correcting broad systematic errors, then gradually refining more subtle relationships among dose intensity, tumour characteristics, and geneexpression features.</p>
<p><img src="images/boosting.png" class="img-fluid"></p>
<p>Boosting methods differ in how they decide which mistakes to correct. Two major families exist:</p>
<ul>
<li>Adaptive boosting, which increases the influence of cases that have been misclassified (or poorly predicted) so that subsequent models pay more attention to them. Diagram in <a href="#fig-adaboost-diagram" class="quarto-xref">Figure&nbsp;<span>3.4</span></a> represents adaptive boosting visually.</li>
</ul>
<div class="cell">
<div id="fig-adaboost-diagram" class="cell-output-display quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-adaboost-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="grViz html-widget html-fill-item" id="htmlwidget-e216096241abb7d49056" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-e216096241abb7d49056">{"x":{"diagram":"\ndigraph adaboost {\ngraph [rankdir = LR]\n\nnode [shape = box, style = rounded, fontsize = 11]\n\n# Nodes\n\ndata   [label = \"Original data\n(X, y)\n(initial equal weights)\",\nfillcolor = \"#e8f3ff\", style = \"filled,rounded\"]\n\nm1     [label = \"Weak learner 1\n(shallow tree)\"]\nw_up1  [label = \"Update case weights:\nmisclassified ↑,\ncorrect ↓\"]\n\nm2     [label = \"Weak learner 2\ntrained on\nreweighted data\"]\nw_up2  [label = \"Update case weights\nagain\"]\n\nm3     [label = \"Weak learner 3\ntrained on\nupdated weights\"]\n\nfinal  [label = \"Final prediction\n(weighted vote of\nall learners)\",\nfillcolor = \"#fff3e8\", style = \"filled,rounded\"]\n\n# Edges\n\ndata -> m1           [label = \" sample with\ninitial weights \"]\nm1   -> w_up1        [label = \" misclassified\ncases identified \"]\nw_up1 -> m2          [label = \" sample with\nnew weights \"]\nm2   -> w_up2        [label = \" errors of\nensemble so far \"]\nw_up2 -> m3          [label = \" sample with\nupdated weights \"]\n\n# All learners vote in the end (weighted)\n\nm1 -> final          [label = \" vote\n(weight ~ accuracy) \"]\nm2 -> final\nm3 -> final\n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-adaboost-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.4: Schematic of AdaBoost: case weights are updated at each step, and models vote with weights in the final ensemble.
</figcaption>
</figure>
</div>
</div>
<ul>
<li>Gradient boosting, which directly models the residual errors of the current ensemble, effectively learning a sequence of corrections that push predictions closer to the true values. The diagram in <a href="#fig-boosting-diagram" class="quarto-xref">Figure&nbsp;<span>3.5</span></a> represents a gradient boosting strategy.</li>
</ul>
<div class="cell">
<div id="fig-boosting-diagram" class="cell-output-display quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-boosting-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="grViz html-widget html-fill-item" id="htmlwidget-e7bd6b43bdfc348d0cc4" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-e7bd6b43bdfc348d0cc4">{"x":{"diagram":"\ndigraph boosting {\ngraph [rankdir = LR]\n\nnode [shape = box, style = rounded, fontsize = 11]\n\n# Nodes\n\ndata   [label = \"Original data\n(X, y)\", fillcolor = \"#e8f3ff\", style = \"filled,rounded\"]\n\nw1     [label = \"Weak learner 1\n(shallow tree)\"]\nerr1   [label = \"Errors / residuals\nfrom model 1\"]\n\nw2     [label = \"Weak learner 2\ntrained on residuals\"]\nerr2   [label = \"Remaining errors\nfrom models 1 + 2\"]\n\nw3     [label = \"Weak learner 3\nfurther correction\"]\n\nfinal  [label = \"Boosted prediction\n(ŷ)\", fillcolor = \"#fff3e8\",\nstyle = \"filled,rounded\"]\n\n# Edges: data -> first learner\n\ndata -> w1\n\n# First learner -> residuals -> next learner\n\nw1   -> err1 [label = \" compute\nresiduals \"]\nerr1 -> w2  [label = \" fit on\nresiduals \"]\n\n# Second learner -> new residuals -> next learner\n\nw2   -> err2 [label = \" updated\nerrors \"]\nerr2 -> w3  [label = \" fit on\nremaining\nresiduals \"]\n\n# All learners contribute to final prediction\n\nw1 -> final [label = \" small\nupdate \"]\nw2 -> final [label = \" small\nupdate \"]\nw3 -> final [label = \" small\nupdate \"]\n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-boosting-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.5: Schematic of boosting: weak learners are added sequentially, each correcting the errors of the current ensemble.
</figcaption>
</figure>
</div>
</div>
</section>
<section id="stacking" class="level3" data-number="3.10.5">
<h3 data-number="3.10.5" class="anchored" data-anchor-id="stacking"><span class="header-section-number">3.10.5</span> Stacking</h3>
<div class="cell">
<div id="fig-stacking-diagram" class="cell-output-display quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-stacking-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="grViz html-widget html-fill-item" id="htmlwidget-544d91226bab562aee56" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-544d91226bab562aee56">{"x":{"diagram":"\ndigraph stacking {\ngraph [rankdir = LR]\n\nnode [shape = box, style = rounded, fontsize = 11]\n\n# Original data\n\ndata   [label = \"Original data\n(X, y)\", fillcolor = \"#e8f3ff\", style = \"filled,rounded\"]\n\n# Base learners\n\nlm     [label = \"Base model 1:\nPenalized linear model\"]\nrf     [label = \"Base model 2:\nRandom forest\"]\ngbm    [label = \"Base model 3:\nGradient boosting\"]\n\n# Meta-learner\n\nmeta   [label = \"Meta-model\n(learnt on\nbase predictions)\", fillcolor = \"#e8ffe8\", style = \"filled,rounded\"]\n\n# Final prediction\n\nyhat   [label = \"Final prediction\n(ŷ)\", \n fillcolor = \"#fff3e8\", \n style = \"filled,rounded\"]\n\n\n# Edges: data -> base models\n\ndata -> lm\ndata -> rf\ndata -> gbm\n\n# Edges: base models -> meta-model\n\nlm  -> meta [label = \" ŷ₁ \"]\nrf  -> meta [label = \" ŷ₂ \"]\ngbm -> meta [label = \" ŷ₃ \"]\n\n# Meta-model -> final prediction\n\nmeta -> yhat\n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-stacking-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.6: Schematic of stacking: multiple base learners feed their predictions into a meta-model.
</figcaption>
</figure>
</div>
</div>
</section>
</section>
<section id="setting-up-test-and-train-datasets" class="level2" data-number="3.11">
<h2 data-number="3.11" class="anchored" data-anchor-id="setting-up-test-and-train-datasets"><span class="header-section-number">3.11</span> Setting up test and train datasets</h2>
<p>We already learnt the importance of using training and testing datasets in our modelling procedures. In this section we will prepare the such datasets to be used then to fit random forests and XGboost analysis.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) Train/test split (70/30) -------------------------</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(trial_ct)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>idx_train <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">seq_len</span>(n), <span class="at">size =</span> <span class="fl">0.7</span> <span class="sc">*</span> n)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> trial_ct[idx_train, ]</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>test  <span class="ot">&lt;-</span> trial_ct[<span class="sc">-</span>idx_train, ]</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) True outcomes ------------------------------------</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> train<span class="sc">$</span>response_percent</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>y_test  <span class="ot">&lt;-</span> test<span class="sc">$</span>response_percent</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="random-forests" class="level2" data-number="3.12">
<h2 data-number="3.12" class="anchored" data-anchor-id="random-forests"><span class="header-section-number">3.12</span> Random Forests</h2>
<p><strong>Random Forests</strong> generalize bootstrap aggregating by introducing <em>feature-level stochasticity</em> during tree construction. Each tree is trained on a bootstrap sample of the data, and at every split the algorithm selects the best partition only from a randomly drawn subset of predictors (of size mtrym_{}mtry​). This mechanism reduces the correlation between trees, which in turn lowers the variance of the aggregated ensemble estimator. Random Forests are consistent for both regression and classification, provide unbiased estimates of generalization error via out-of-bag predictions, and incorporate variable importance metrics based on impurity reduction or permutation. Their ability to approximate complex interaction structures without explicit feature engineering, combined with robustness to high-dimensional predictors and noisy inputs, makes them a powerful nonparametric baseline for tabular biomedical data. Despite limited interpretability relative to single trees, Random Forests offer strong predictive performance and stability across heterogeneous clinical settings.</p>
<p>With the following lines of code we will learn how to run a random forest example in our chemoterapy case. This code fits a Random Forest regression model to predict <strong>tumour response percentage</strong> from a collection of clinical and molecular features. The model is built using the <em>ranger</em> package, a fast and scalable implementation designed for high-dimensional datasets such as ours, which contains thousands of gene-expression variables. The formula <code>response_percent ~ .</code> specifies that all available predictors should be used, but four variables are explicitly removed from the model: <em>patient_id</em> (an identifier), <em>high_response</em> (a derived binary outcome that would leak information), and the tumour measurements <em>baseline_tumor_mm</em> and <em>post_tumor_mm</em>, which are deterministically related to the response and would therefore artificially inflate model performance.</p>
<p>The call to <code>ranger()</code> constructs an ensemble of 500 decision trees. At each split, instead of evaluating all predictors, the algorithm considers only a random subset whose size is defined by <code>mtry</code>. Here, <code>mtry</code> is set to the square root of the effective number of predictors, a widely used heuristic that helps decorrelate the trees and therefore reduce variance in the final ensemble. The model also computes impurity-based variable importance, which allows later examination of which genes or clinical features contributed most strongly to the predictions.</p>
<p>Once the forest has been trained, the model is applied to both the training and test sets to obtain predicted tumour-response percentages. These predictions are extracted via the <code>$predictions</code> element of the output returned by <code>predict()</code>. The final section evaluates model performance by computing mean absolute error (MAE) and root-mean-square error (RMSE) using the helper function <code>eval_perf()</code>. Computing performance on the training set allows us to assess whether the forest has fit the data effectively, whereas evaluating on the test set quantifies generalization to unseen patients a crucial step in understanding whether the model can support predictive decision-making in a clinical or therapeutic context.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ranger)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>rf_fit <span class="ot">&lt;-</span> <span class="fu">ranger</span>(</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  response_percent <span class="sc">~</span> . </span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    <span class="sc">-</span> patient_id </span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    <span class="sc">-</span> high_response </span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    <span class="sc">-</span> baseline_tumor_mm </span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    <span class="sc">-</span> post_tumor_mm,</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">data       =</span> train,</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">num.trees  =</span> <span class="dv">500</span>,</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry       =</span> <span class="fu">floor</span>(<span class="fu">sqrt</span>(<span class="fu">ncol</span>(train) <span class="sc">-</span> <span class="dv">5</span>)),  <span class="co"># approx: drop 4 predictors + outcome</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">importance =</span> <span class="st">"impurity"</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Growing trees.. Progress: 87%. Estimated remaining time: 4 seconds.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions ------------------------------------------------------</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>rf_pred_train <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fit, <span class="at">data =</span> train)<span class="sc">$</span>predictions</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>rf_pred_test  <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fit, <span class="at">data =</span> test)<span class="sc">$</span>predictions</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Performance ------------------------------------------------------</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>rf_perf_train <span class="ot">&lt;-</span> <span class="fu">eval_perf</span>(y_train, rf_pred_train)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>rf_perf_test  <span class="ot">&lt;-</span> <span class="fu">eval_perf</span>(y_test,  rf_pred_test)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>rf_perf_train</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 2
    MAE  RMSE
  &lt;dbl&gt; &lt;dbl&gt;
1  2.17  2.68</code></pre>
</div>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>rf_perf_test</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 2
    MAE  RMSE
  &lt;dbl&gt; &lt;dbl&gt;
1  5.54  6.80</code></pre>
</div>
</div>
</section>
<section id="xgboost" class="level2" data-number="3.13">
<h2 data-number="3.13" class="anchored" data-anchor-id="xgboost"><span class="header-section-number">3.13</span> XGboost</h2>
<p>Gradient boosting is one of the most powerful ideas in modern machine learning. While Random Forests reduce variance by averaging many decorrelated trees, boosting takes the opposite approach: it builds trees <strong>sequentially</strong>, where each new tree attempts to correct the errors of the ensemble so far. XGBoost (Extreme Gradient Boosting) is a highly optimized implementation of this idea and has become the dominant algorithm for tabular biomedical prediction, especially in high-dimensional settings with complex nonlinear relationships, such as gene-expression data in therapeutic studies.</p>
<p>In boosting, the model begins with a simple prediction often the mean value of the outcome and then iteratively adds small regression trees. Each new tree is fitted to the <em>residuals</em> (the mistakes) of the current model. Because each tree is intentionally shallow, it captures only a small part of the remaining structure. However, when hundreds of these trees are combined, the model can approximate highly intricate interactions, nonlinearities, and threshold behaviours. Crucially, XGBoost incorporates additional mechanisms that make it robust and scalable: <strong>L1 and L2 regularization</strong>, <strong>learning-rate shrinkage</strong>, <strong>column and row subsampling</strong>, and efficient handling of sparse matrices. Together, these features make XGBoost far less prone to overfitting than naïve boosting methods, even with thousands of predictors.</p>
<p>The code below shows how XGBoost is trained to predict tumour-response percentage using the chemotherapy dataset.</p>
<p>First, we construct the predictor matrices for training and test sets. Because XGBoost expects purely numeric input, we use <code>model.matrix()</code> to convert categorical variables into dummy indicators and to ensure the same set of columns is used across both datasets. All leakage-prone variables (<code>patient_id</code>, <code>high_response</code>, <code>baseline_tumor_mm</code>, <code>post_tumor_mm</code>, and the outcome <code>response_percent</code>) are removed from the predictor matrix. The remaining clinical and molecular features form a high-dimensional design matrix with potentially thousands of columns, which XGBoost handles naturally.</p>
<p>Next, the data are converted into <code>xgb.DMatrix</code> objects. This format stores the matrix efficiently and allows XGBoost to apply internal optimizations such as sparse-feature handling and fast column access. Labels (the continuous response values) are attached here.</p>
<p>The hyperparameters defined in <code>xgb_params</code> specify the behaviour of the boosting process. We use <code>objective = "reg:squarederror"</code> because this is a continuous regression task. The parameter <code>eta</code> controls the learning rate: each tree only makes a small correction to the existing model, which stabilizes training. The arguments <code>max_depth</code>, <code>subsample</code>, and <code>colsample_bytree</code> restrict the complexity of individual trees and the diversity of information they see, thereby preventing overfitting and encouraging generalization.</p>
<p>Training occurs through <code>xgb.train()</code>, which iteratively builds 300 boosting rounds. Each iteration grows a shallow tree tailored to the current residuals. Because the watchlist contains the training set, XGBoost can report internal diagnostics (here suppressed with <code>verbose = 0</code>).</p>
<p>Finally, predictions on both training and test data are obtained with <code>predict()</code>. These predicted continuous response values are evaluated using MAE and RMSE, allowing direct comparison with linear models, trees, and Random Forests. Typically, XGBoost provides the strongest performance in this type of biological regression setting, as it captures subtle gene–gene interactions, nonlinear dose effects, and patient heterogeneity more effectively than any single model family.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) Build predictor matrices -------------------------------------</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>cols_to_drop <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">"patient_id"</span>,</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">"high_response"</span>,</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">"baseline_tumor_mm"</span>,</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>  <span class="st">"post_tumor_mm"</span>,</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>  <span class="st">"response_percent"</span>   <span class="co"># outcome must also be removed from X</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>X_train <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>  <span class="sc">~</span> .,</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train <span class="sc">|&gt;</span> <span class="fu">select</span>(<span class="sc">-</span><span class="fu">all_of</span>(cols_to_drop))</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>X_test <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>  <span class="sc">~</span> .,</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> test  <span class="sc">|&gt;</span> <span class="fu">select</span>(<span class="sc">-</span><span class="fu">all_of</span>(cols_to_drop))</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Optional: check dimensions</span></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(X_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 7000 2007</code></pre>
</div>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3000 2007</code></pre>
</div>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) Convert to DMatrix -------------------------------------------</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>dtrain <span class="ot">&lt;-</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> X_train, <span class="at">label =</span> y_train)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>dtest  <span class="ot">&lt;-</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> X_test,  <span class="at">label =</span> y_test)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 3) Basic XGBoost hyperparameters --------------------------------</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>xgb_params <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">objective        =</span> <span class="st">"reg:squarederror"</span>,</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">eta              =</span> <span class="fl">0.05</span>,   <span class="co"># learning rate</span></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">max_depth        =</span> <span class="dv">4</span>,</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">subsample        =</span> <span class="fl">0.7</span>,    <span class="co"># row subsampling</span></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">colsample_bytree =</span> <span class="fl">0.7</span>     <span class="co"># column subsampling</span></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 4) Train XGBoost model ------------------------------------------</span></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>xgb_fit <span class="ot">&lt;-</span> <span class="fu">xgb.train</span>(</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">params    =</span> xgb_params,</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">data      =</span> dtrain,</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">nrounds   =</span> <span class="dv">300</span>,</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">watchlist =</span> <span class="fu">list</span>(<span class="at">train =</span> dtrain),</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">verbose   =</span> <span class="dv">0</span></span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a><span class="co"># 5) Predictions ---------------------------------------------------</span></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>xgb_pred_train <span class="ot">&lt;-</span> <span class="fu">predict</span>(xgb_fit, dtrain)</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>xgb_pred_test  <span class="ot">&lt;-</span> <span class="fu">predict</span>(xgb_fit, dtest)</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a><span class="co"># 6) Performance ---------------------------------------------------</span></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>xgb_perf_train <span class="ot">&lt;-</span> <span class="fu">eval_perf</span>(y_train, xgb_pred_train)</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>xgb_perf_test  <span class="ot">&lt;-</span> <span class="fu">eval_perf</span>(y_test,  xgb_pred_test)</span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>xgb_perf_train</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 2
    MAE  RMSE
  &lt;dbl&gt; &lt;dbl&gt;
1 0.958  1.26</code></pre>
</div>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>xgb_perf_test</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 2
    MAE  RMSE
  &lt;dbl&gt; &lt;dbl&gt;
1  1.34  1.79</code></pre>
</div>
</div>
</section>
<section id="comparison-random-forests-and-xgboost-for-our-data" class="level2" data-number="3.14">
<h2 data-number="3.14" class="anchored" data-anchor-id="comparison-random-forests-and-xgboost-for-our-data"><span class="header-section-number">3.14</span> Comparison Random Forests and XGboost for our data</h2>
<p>After fitting both a Random Forest and an XGBoost model to the clinical trial dataset, we evaluate their predictive performance on the test set using the same metrics employed throughout the chapter mean absolute error (MAE) and root mean squared error (RMSE). The following code constructs a simple comparison table:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>rf_xgb_compare <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Random Forest"</span> <span class="ot">=</span> rf_perf_test,</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">"XGBoost"</span>       <span class="ot">=</span> xgb_perf_test,</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">.id =</span> <span class="st">"Model"</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>rf_xgb_compare</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 3
  Model           MAE  RMSE
  &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;
1 Random Forest  5.54  6.80
2 XGBoost        1.34  1.79</code></pre>
</div>
</div>
<p>This comparison highlights a substantial difference in predictive accuracy between the two ensemble methods. The Random Forest, which aggregates many decorrelated decision trees built on bootstrap samples, provides solid performance with <strong>MAE = 5.58</strong> and <strong>RMSE = 6.84</strong> on the test set values typical of a stable but variance-oriented ensemble. In contrast, the XGBoost model achieves dramatically lower error, with <strong>MAE = 1.37</strong> and <strong>RMSE = 1.82</strong>, reducing both metrics by more than a factor of three.</p>
<p>This improvement reflects the fundamental difference in how the two algorithms learn. Random Forests reduce variance by averaging many deep, high-variance trees grown independently; XGBoost, instead, builds trees sequentially, with each tree correcting the residuals of the previous ensemble. The combination of a small learning rate, explicit L1/L2 regularization, and shallow trees allows XGBoost to capture nonlinear and interaction patterns more efficiently and with greater stability.</p>
<p>In this dataset characterized by nonlinear dose–response relationships, interactions between tumour grade and gene-expression features, and substantial patient heterogeneity the gradient-boosting strategy produces a far more accurate approximation of the underlying biological response function. This illustrates why boosted tree models often outperform bagging-based methods in biomedical prediction tasks where subtle patterns, thresholds, and gene-level interactions play a central role.</p>
</section>
<section id="comparing-random-forests-and-xgboost-with-ols-lasso-ridge-and-elastic-net" class="level2" data-number="3.15">
<h2 data-number="3.15" class="anchored" data-anchor-id="comparing-random-forests-and-xgboost-with-ols-lasso-ridge-and-elastic-net"><span class="header-section-number">3.15</span> Comparing Random Forests and XGboost with OLS, LASSO, Ridge and Elastic NET</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Columns we do NOT want as predictors</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>cols_to_drop <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"patient_id"</span>, <span class="st">"high_response"</span>, <span class="st">"baseline_tumor_mm"</span>, <span class="st">"post_tumor_mm"</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create reduced train/test data frames for modeling</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>train_lm <span class="ot">&lt;-</span> train <span class="sc">|&gt;</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span><span class="fu">all_of</span>(cols_to_drop))</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>test_lm <span class="ot">&lt;-</span> test <span class="sc">|&gt;</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span><span class="fu">all_of</span>(cols_to_drop))</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Ordinary Least Squares (no regularization)</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>ols_fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>  response_percent <span class="sc">~</span> .,</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train_lm</span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>ols_pred_train <span class="ot">&lt;-</span> <span class="fu">predict</span>(ols_fit, <span class="at">newdata =</span> train_lm)</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>ols_pred_test  <span class="ot">&lt;-</span> <span class="fu">predict</span>(ols_fit, <span class="at">newdata =</span> test_lm)</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a>ols_perf_train <span class="ot">&lt;-</span> <span class="fu">eval_perf</span>(y_train, ols_pred_train)</span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a>ols_perf_test  <span class="ot">&lt;-</span> <span class="fu">eval_perf</span>(y_test,  ols_pred_test)</span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a>ols_perf_test</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 2
    MAE  RMSE
  &lt;dbl&gt; &lt;dbl&gt;
1  1.83  2.28</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Ridge regression (alpha = 0) ----------------------------</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>ridge_cv <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> X_train,</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> y_train,</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">0</span></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>ridge_pred_train <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(ridge_cv, <span class="at">newx =</span> X_train, <span class="at">s =</span> <span class="st">"lambda.min"</span>))</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>ridge_pred_test  <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(ridge_cv, <span class="at">newx =</span> X_test,  <span class="at">s =</span> <span class="st">"lambda.min"</span>))</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>ridge_perf_train <span class="ot">&lt;-</span> <span class="fu">eval_perf</span>(y_train, ridge_pred_train)</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>ridge_perf_test  <span class="ot">&lt;-</span> <span class="fu">eval_perf</span>(y_test,  ridge_pred_test)</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Lasso regression (alpha = 1) ---------------------------</span></span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>lasso_cv <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(</span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> X_train,</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> y_train,</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">1</span></span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>lasso_pred_train <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(lasso_cv, <span class="at">newx =</span> X_train, <span class="at">s =</span> <span class="st">"lambda.min"</span>))</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>lasso_pred_test  <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(lasso_cv, <span class="at">newx =</span> X_test,  <span class="at">s =</span> <span class="st">"lambda.min"</span>))</span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>lasso_perf_train <span class="ot">&lt;-</span> <span class="fu">eval_perf</span>(y_train, lasso_pred_train)</span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>lasso_perf_test  <span class="ot">&lt;-</span> <span class="fu">eval_perf</span>(y_test,  lasso_pred_test)</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Elastic Net (alpha between 0 and 1) --------------------</span></span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a>elastic_cv <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(</span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> X_train,</span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> y_train,</span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="fl">0.5</span>   <span class="co"># 0.5 = equal mix of L1 and L2; you can tune this</span></span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-39"><a href="#cb43-39" aria-hidden="true" tabindex="-1"></a>elastic_pred_train <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(elastic_cv, <span class="at">newx =</span> X_train, <span class="at">s =</span> <span class="st">"lambda.min"</span>))</span>
<span id="cb43-40"><a href="#cb43-40" aria-hidden="true" tabindex="-1"></a>elastic_pred_test  <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(elastic_cv, <span class="at">newx =</span> X_test,  <span class="at">s =</span> <span class="st">"lambda.min"</span>))</span>
<span id="cb43-41"><a href="#cb43-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-42"><a href="#cb43-42" aria-hidden="true" tabindex="-1"></a>elastic_perf_train <span class="ot">&lt;-</span> <span class="fu">eval_perf</span>(y_train, elastic_pred_train)</span>
<span id="cb43-43"><a href="#cb43-43" aria-hidden="true" tabindex="-1"></a>elastic_perf_test  <span class="ot">&lt;-</span> <span class="fu">eval_perf</span>(y_test,  elastic_pred_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>benchmark_tbl <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">bind_rows</span>(</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">"OLS"</span>           <span class="ot">=</span> ols_perf_test,</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Ridge"</span>         <span class="ot">=</span> ridge_perf_test,</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Lasso"</span>         <span class="ot">=</span> lasso_perf_test,</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Elastic Net"</span>   <span class="ot">=</span> elastic_perf_test,</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Random Forest"</span> <span class="ot">=</span> rf_perf_test,</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">"XGBoost"</span>       <span class="ot">=</span> xgb_perf_test,</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">.id =</span> <span class="st">"Model"</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>benchmark_tbl</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 3
  Model           MAE  RMSE
  &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;
1 OLS            1.83  2.28
2 Ridge          1.78  2.22
3 Lasso          1.53  1.92
4 Elastic Net    1.53  1.92
5 Random Forest  5.54  6.80
6 XGBoost        1.34  1.79</code></pre>
</div>
</div>
<p>To evaluate how different modelling strategies behave in our example, we compared six regression models OLS, Lasso, Ridge, Elastic Net, Random Forest, and XGBoost on the same task: predicting <em>response_percent</em>, a continuous measure of tumour shrinkage in a chemotherapy trial. All models were trained on the same 70% split and evaluated on the same 30% test set using identical predictors: clinical variables and approximately 2,000 gene-expression features (after excluding identifiers and tumour-size measurements).</p>
<section id="linear-models-with-and-without-regularization" class="level3" data-number="3.15.1">
<h3 data-number="3.15.1" class="anchored" data-anchor-id="linear-models-with-and-without-regularization"><span class="header-section-number">3.15.1</span> Linear Models with and without Regularization</h3>
<p>OLS offers a transparent baseline but performs poorly with thousands of correlated gene features, leading to unstable coefficients and weak generalization (MAE ≈ 1.83; RMSE ≈ 2.28)</p>
<p>Ridge stabilizes coefficients through L2 shrinkage, producing modest gains but preserving all predictors, which limits interpretability.</p>
<p>Lasso substantially improves performance (MAE ≈ 1.53; RMSE ≈ 1.92) by selecting a sparse subset of informative genes, making it both predictive and biologically interpretable.</p>
<p>Elastic Net, combining L1 and L2 penalties, achieves the best performance among linear models (MAE ≈ 1.52; RMSE ≈ 1.91), particularly well-suited for groups of correlated genes commonly found in expression data.</p>
</section>
<section id="tree-based-ensemble-models" class="level3" data-number="3.15.2">
<h3 data-number="3.15.2" class="anchored" data-anchor-id="tree-based-ensemble-models"><span class="header-section-number">3.15.2</span> Tree-Based Ensemble Models</h3>
<p>Random Forest performs unexpectedly poorly in this ultra-high-dimensional setting (MAE ≈ 5.61; RMSE ≈ 6.87). With so many predictors, random subsets rarely contain strong signals, leading to noisy splits and poor generalization.</p>
<p>XGBoost delivers the strongest predictive performance overall (MAE ≈ 1.32; RMSE ≈ 1.78). Its sequential boosting mechanism targets residual structure directly, while regularization (L1 + L2), subsampling, and shallow trees help control overfitting. This allows XGBoost to recover nonlinear relationships and interaction effects that Random Forest fails to capture.</p>
</section>
</section>
<section id="trees-for-classification-tasks" class="level2" data-number="3.16">
<h2 data-number="3.16" class="anchored" data-anchor-id="trees-for-classification-tasks"><span class="header-section-number">3.16</span> Trees for classification tasks</h2>
<p>In the previous section, we used trees to predict a continuous response (<code>response_percent</code>). Decision trees, however, can also be used for <strong>classification tasks</strong>, where the goal is to predict a categorical outcome such as <code>high_response</code> (1 = high responder, 0 = low responder).<br>
</p>
<p>This type of model belongs to the <strong>Classification and Regression Tree (CART)</strong> family the same general framework we used for regression trees, but with a different impurity measure and output interpretation.</p>
<p>In a <strong>classification tree</strong>, each node represents a subset of the data that is more or less “pure” with respect to the outcome classes. The tree is built by recursively splitting the data into increasingly homogeneous groups, using thresholds on explanatory variables (e.g., gene expression, dose intensity, tumor grade).</p>
<section id="model-setup" class="level3" data-number="3.16.1">
<h3 data-number="3.16.1" class="anchored" data-anchor-id="model-setup"><span class="header-section-number">3.16.1</span> Model setup</h3>
<p>We will use the same chemotherapy trial dataset as before, but now we define the binary target <code>high_response</code> (1 = tumor reduction ≥ 30%) and use the function <code>rpart()</code> with <code>method = "class"</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) Make sure the binary target exists</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>trial_ct <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"~/att_ai_ml/data/trial_ct_chemo_cont.rds"</span>)</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>trial_ct <span class="ot">&lt;-</span> trial_ct <span class="sc">%&gt;%</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="fu">mutate</span>(<span class="at">high_response =</span> <span class="fu">as.integer</span>(response_percent <span class="sc">&gt;=</span> <span class="dv">30</span>))</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) Drop ID and leakage columns</span></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>cols_drop <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"patient_id"</span>, <span class="st">"response_percent"</span>, <span class="st">"baseline_tumor_mm"</span>, <span class="st">"post_tumor_mm"</span>)</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>trial_ct <span class="ot">&lt;-</span> trial_ct <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span><span class="fu">any_of</span>(cols_drop))</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 3) Train/test split (70/30)</span></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(trial_ct)</span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>idx_train <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">seq_len</span>(n), <span class="at">size =</span> <span class="fl">0.7</span> <span class="sc">*</span> n)</span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>train_cls <span class="ot">&lt;-</span> trial_ct[idx_train, ]</span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a>test_cls  <span class="ot">&lt;-</span> trial_ct[<span class="sc">-</span>idx_train, ]</span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a><span class="co"># 4) Fit classification tree</span></span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a>ctree_cls <span class="ot">&lt;-</span> <span class="fu">rpart</span>(</span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a>high_response <span class="sc">~</span> .,</span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a><span class="at">data =</span> train_cls,</span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a><span class="at">method =</span> <span class="st">"class"</span>,</span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a><span class="at">control =</span> <span class="fu">rpart.control</span>(<span class="at">cp =</span> <span class="fl">0.001</span>, <span class="at">maxdepth =</span> <span class="dv">8</span>, <span class="at">minsplit =</span> <span class="dv">30</span>)</span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="inspecting-and-pruning-the-tree" class="level3" data-number="3.16.2">
<h3 data-number="3.16.2" class="anchored" data-anchor-id="inspecting-and-pruning-the-tree"><span class="header-section-number">3.16.2</span> Inspecting and pruning the tree</h3>
<p>The complexity parameter (<code>cp</code>) controls how aggressively the tree grows. As before, we inspect the cost-complexity table to identify the optimal pruning point via the <em>1-SE rule</em>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Examine complexity parameter (cost-complexity table)</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="fu">printcp</span>(ctree_cls)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Classification tree:
rpart(formula = high_response ~ ., data = train_cls, method = "class", 
    control = rpart.control(cp = 0.001, maxdepth = 8, minsplit = 30))

Variables actually used in tree construction:
 [1] gene_05   gene_08   gene_1074 gene_112  gene_14   gene_1654 gene_1721
 [8] gene_19   gene_1982 gene_1986 gene_447  gene_567  gene_694  gene_726 
[15] gene_78  

Root node error: 2637/7000 = 0.37671

n= 7000 

          CP nsplit rel error   xerror      xstd
1  0.8862344      0  1.000000 1.000000 0.0153741
2  0.0125142      1  0.113766 0.124384 0.0067051
3  0.0113766      2  0.101251 0.117937 0.0065373
4  0.0068259      3  0.089875 0.101631 0.0060881
5  0.0026545      5  0.076223 0.089875 0.0057383
6  0.0024649      6  0.073568 0.091392 0.0057848
7  0.0022753      8  0.068639 0.090633 0.0057616
8  0.0020857     11  0.061813 0.088737 0.0057031
9  0.0018961     14  0.054608 0.089496 0.0057266
10 0.0016433     15  0.052711 0.089116 0.0057149
11 0.0011377     18  0.047782 0.092909 0.0058309
12 0.0010000     20  0.045506 0.096322 0.0059331</code></pre>
</div>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plotcp</span>(ctree_cls, <span class="at">main =</span> <span class="st">"Classification tree: CP plot"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="three_methods_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply 1-SE rule for pruning</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>best_row  <span class="ot">&lt;-</span> <span class="fu">which.min</span>(ctree_cls<span class="sc">$</span>cptable[, <span class="st">"xerror"</span>])</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>xerr_min  <span class="ot">&lt;-</span> ctree_cls<span class="sc">$</span>cptable[best_row, <span class="st">"xerror"</span>]</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>xstd_min  <span class="ot">&lt;-</span> ctree_cls<span class="sc">$</span>cptable[best_row, <span class="st">"xstd"</span>]</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>cp_1se    <span class="ot">&lt;-</span> ctree_cls<span class="sc">$</span>cptable[ctree_cls<span class="sc">$</span>cptable[, <span class="st">"xerror"</span>] <span class="sc">&lt;=</span> xerr_min <span class="sc">+</span> xstd_min, <span class="st">"CP"</span>][<span class="dv">1</span>]</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>ctree_pruned <span class="ot">&lt;-</span> <span class="fu">prune</span>(ctree_cls, <span class="at">cp =</span> cp_1se)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="visualizing-grown-and-pruned-trees" class="level3" data-number="3.16.3">
<h3 data-number="3.16.3" class="anchored" data-anchor-id="visualizing-grown-and-pruned-trees"><span class="header-section-number">3.16.3</span> Visualizing grown and pruned trees</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(ctree_cls, <span class="at">type =</span> <span class="dv">2</span>, <span class="at">extra =</span> <span class="dv">104</span>, <span class="at">box.palette =</span> <span class="st">"Blues"</span>,</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="at">main =</span> <span class="st">"Classification Tree (grown)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="three_methods_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(ctree_pruned, <span class="at">type =</span> <span class="dv">2</span>, <span class="at">extra =</span> <span class="dv">104</span>, <span class="at">box.palette =</span> <span class="st">"GnBu"</span>,</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="at">main =</span> <span class="st">"Classification Tree (pruned, 1-SE rule)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="three_methods_files/figure-html/unnamed-chunk-15-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Each internal node displays the variable and threshold that best separates responders from non-responders. Each leaf (terminal node) reports the predicted class, the probability of <code>high_response</code>, and the number of patients in that subgroup.</p>
<p>For example, a path like:If <code>gene_14 ≥ 0.98</code> and <code>gene_08 ≥ 2.03</code> → predict <em>High response (p = 0.93)</em></p>
<p>shows that patients with high expression of those two genes have about a 93 % probability of meaningful tumor shrinkage.</p>
<p>In regression trees, we minimized the within-node variance.<br>
</p>
<p>In classification trees, we minimize the <strong>impurity</strong> of the node, typically measured by the <strong>Gini index</strong>:</p>
<p><span class="math display">\[
I_{\text {Gini }}(S)=1-\sum_{k=1}^K p_k^2
\]</span></p>
<p>where <span class="math inline">\(p_k\)</span> is the proportion of observations in class <span class="math inline">\(k\)</span> within node <span class="math inline">\(S\)</span>.</p>
<p>A node is pure (impurity <span class="math inline">\(=0\)</span> ) if all observations belong to the same class, and most impure (maximum) when classes are evenly mixed.</p>
<p>Each split is chosen to maximize impurity reduction:</p>
<p><span class="math display">\[
\Delta I=I(\text { parent })-\frac{n_L}{n_{\text {parent }}} I(\text { left })-\frac{n_R}{n_{\text {parent }}} I(\text { right })
\]</span></p>
<p>rpart() performs this optimization automatically, evaluating all candidate thresholds for numeric variables and the best grouping for categorical ones.</p>
</section>
<section id="predictions-and-confusing-matrix" class="level3" data-number="3.16.4">
<h3 data-number="3.16.4" class="anchored" data-anchor-id="predictions-and-confusing-matrix"><span class="header-section-number">3.16.4</span> Predictions and confusing matrix</h3>
<p>Once the pruned tree is finalized, we can generate predictions and evaluate its performance on the test set.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions on test data</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>pred_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(ctree_pruned, <span class="at">newdata =</span> test_cls, <span class="at">type =</span> <span class="st">"prob"</span>)[, <span class="dv">2</span>]</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>pred_class <span class="ot">&lt;-</span> <span class="fu">as.integer</span>(pred_prob <span class="sc">&gt;=</span> <span class="fl">0.5</span>)</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="co"># True labels</span></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>y_true <span class="ot">&lt;-</span> test_cls<span class="sc">$</span>high_response</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>cm <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="at">Predicted =</span> pred_class, <span class="at">True =</span> y_true)</span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>cm</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         True
Predicted    0    1
        0 1845   38
        1   43 1074</code></pre>
</div>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Accuracy, sensitivity, specificity</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>accuracy  <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(cm)) <span class="sc">/</span> <span class="fu">sum</span>(cm)</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>sensitivity <span class="ot">&lt;-</span> cm[<span class="st">"1"</span>, <span class="st">"1"</span>] <span class="sc">/</span> <span class="fu">sum</span>(cm[, <span class="st">"1"</span>])  <span class="co"># recall</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>specificity <span class="ot">&lt;-</span> cm[<span class="st">"0"</span>, <span class="st">"0"</span>] <span class="sc">/</span> <span class="fu">sum</span>(cm[, <span class="st">"0"</span>])</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">Accuracy =</span> accuracy, <span class="at">Sensitivity =</span> sensitivity, <span class="at">Specificity =</span> specificity)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Accuracy Sensitivity Specificity 
  0.9730000   0.9658273   0.9772246 </code></pre>
</div>
</div>
</section>
<section id="roc-and-auc-for-the-classification-tree" class="level3" data-number="3.16.5">
<h3 data-number="3.16.5" class="anchored" data-anchor-id="roc-and-auc-for-the-classification-tree"><span class="header-section-number">3.16.5</span> ROC and AUC for the classification tree</h3>
<p>The ROC curve visualizes the trade-off between sensitivity and specificity as we vary the decision threshold on the predicted probability.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>roc_tree <span class="ot">&lt;-</span> <span class="fu">roc</span>(y_true, pred_prob)</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(roc_tree, <span class="at">col =</span> <span class="st">"#2b8cbe"</span>, <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a><span class="at">main =</span> <span class="fu">sprintf</span>(<span class="st">"ROC curve (AUC = %.3f)"</span>, <span class="fu">auc</span>(roc_tree)))</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="dv">0</span>, <span class="at">b =</span> <span class="dv">1</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"gray"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="three_methods_files/figure-html/ct-class-tree-roc-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>An AUC close to 1 indicates strong discrimination between high and low responders.<br>
</p>
<p>In clinical prediction tasks, AUC values between 0.8 and 0.9 are considered good, and above 0.9 excellent.</p>
</section>
<section id="interpreting-the-classification-trees" class="level3" data-number="3.16.6">
<h3 data-number="3.16.6" class="anchored" data-anchor-id="interpreting-the-classification-trees"><span class="header-section-number">3.16.6</span> Interpreting the classification trees</h3>
<p>The <strong>grown tree</strong> explores all possible splits that reduce impurity, achieving near-perfect fit on training data but risking overfitting.<br>
</p>
<p>The <strong>pruned tree</strong>, selected by the 1-SE rule, retains only the most stable, clinically interpretable decision rules.</p>
<p>Each path from root to leaf forms an explicit “if–then” rule linking biological and clinical features to treatment response.<br>
</p>
<p>This interpretability is valuable in medicine: unlike logistic regression coefficients, tree rules are easily read and discussed with clinicians.</p>
<p>Although a single classification tree is highly interpretable, it has important limitations:</p>
<p>A first limitation is <strong>high variance</strong>. Small changes in the data may lead the tree to choose very different splitting variables, thresholds, and rule structures. The model therefore tends to overfit training data and generalize poorly to unseen patients.</p>
<p>A second limitation is that the tree can capture only one hierarchy of interactions at a time. If multiple patterns or gene combinations can predict response, the tree must choose between them, discarding alternative useful pathways.</p>
<p>A third limitation is <strong>instability in high-dimensional settings</strong>. In our dataset of more than 2,000 gene expression variables, many predictors are only weakly informative. The greedy splitting process may select noise variables simply because they provide small, random decreases in impurity. For these reasons, while a pruned tree is clinically interpretable, it rarely matches the predictive performance of modern ensemble methods.</p>
</section>
<section id="ensemble-methods-for-classification-random-forest-and-xgboost" class="level3" data-number="3.16.7">
<h3 data-number="3.16.7" class="anchored" data-anchor-id="ensemble-methods-for-classification-random-forest-and-xgboost"><span class="header-section-number">3.16.7</span> Ensemble methods for classification: Random Forest and XGBoost</h3>
<p>In the previous section, we fitted a <strong>single classification tree</strong> to predict the probability of high response (<code>high_response</code>). Although interpretable, single trees tend to have <strong>high variance</strong> they fit training data too well and generalize poorly. Two powerful ensemble methods <strong>Random Forest</strong> and <strong>XGBoost</strong> can dramatically improve performance by combining the predictions of many trees.</p>
</section>
<section id="random-forest-classifier" class="level3" data-number="3.16.8">
<h3 data-number="3.16.8" class="anchored" data-anchor-id="random-forest-classifier"><span class="header-section-number">3.16.8</span> Random Forest classifier</h3>
<p>Random Forest (RF) builds many trees, each trained on a <strong>bootstrap sample</strong> of the training data and a <strong>random subset of predictors</strong> at each split. Each tree votes for the predicted class, and the forest aggregates these votes.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ranger)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Make sure the outcome is a factor with levels 0 and 1</span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>train_cls <span class="ot">&lt;-</span> train_cls <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">high_response =</span> <span class="fu">factor</span>(high_response, <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)))</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>test_cls  <span class="ot">&lt;-</span> test_cls  <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">high_response =</span> <span class="fu">factor</span>(high_response, <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)))</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the random forest classifier</span></span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>rf_class <span class="ot">&lt;-</span> <span class="fu">ranger</span>(</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>  high_response <span class="sc">~</span> .,</span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train_cls,</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">num.trees =</span> <span class="dv">800</span>,</span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry =</span> <span class="fu">floor</span>(<span class="fu">sqrt</span>(<span class="fu">ncol</span>(train_cls) <span class="sc">-</span> <span class="dv">1</span>)),</span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">min.node.size =</span> <span class="dv">5</span>,</span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">importance =</span> <span class="st">"impurity"</span>,</span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">probability =</span> <span class="cn">TRUE</span>,      <span class="co"># ensures probability predictions</span></span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">oob.error =</span> <span class="cn">TRUE</span></span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a>rf_class</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Ranger result

Call:
 ranger(high_response ~ ., data = train_cls, num.trees = 800,      mtry = floor(sqrt(ncol(train_cls) - 1)), min.node.size = 5,      importance = "impurity", probability = TRUE, oob.error = TRUE) 

Type:                             Probability estimation 
Number of trees:                  800 
Sample size:                      7000 
Number of independent variables:  2005 
Mtry:                             44 
Target node size:                 5 
Variable importance mode:         impurity 
Splitrule:                        gini 
OOB prediction error (Brier s.):  0.04554791 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># OOB error (classification): use sqrt only for regression. For classification:</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>rf_class<span class="sc">$</span>prediction.error   <span class="co"># OOB misclassification error</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.04554791</code></pre>
</div>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on test data</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>pred_obj <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_class, <span class="at">data =</span> test_cls)</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Examine the structure if curious:</span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a><span class="co"># str(pred_obj$predictions)</span></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract probability for class "1"</span></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a><span class="co"># If the column has names "0" and "1", use them:</span></span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>pred_rf_prob <span class="ot">&lt;-</span> pred_obj<span class="sc">$</span>predictions[, <span class="st">"1"</span>]</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert probabilities into class predictions</span></span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a>pred_rf_class <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(pred_rf_prob <span class="sc">&gt;=</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a>cm_rf <span class="ot">&lt;-</span> <span class="fu">table</span>(</span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">Predicted =</span> pred_rf_class,</span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">True =</span> test_cls<span class="sc">$</span>high_response</span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a>cm_rf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         True
Predicted    0    1
        0 1853   56
        1   35 1056</code></pre>
</div>
</div>
<p>Random Forest performs well in many clinical applications because it averages hundreds of decorrelated trees, reducing the variance inherent in single-tree models. The bootstrap sampling at the tree level and the random subset of predictors at each split ensure that individual trees explore different parts of the feature space.</p>
<p>However, in ultra–high-dimensional settings such as our chemotherapy trial, several challenges emerge:</p>
<p>First, when the number of predictors is extremely large (more than 2,000 gene features), the chance of selecting truly informative predictors at each split becomes small. The majority of splits may involve irrelevant variables, weakening each individual tree.</p>
<p>Second, if the data contain many weak or noisy predictors, Random Forest tends to produce noisy decision boundaries. Averaging many weak learners helps, but does not completely overcome this issue.</p>
<p>Third, even though Random Forest reduces variance, it does not reduce bias. When the signal requires subtle, multi-variable interactions, shallow random subtrees may not capture those interactions efficiently.</p>
<p>Nevertheless, in our classification task the Random Forest performs remarkably well, achieving an AUC close to 0.996 largely because the signal-to-noise ratio for the binary target is far higher than for the continuous regression outcome studied earlier.</p>
</section>
<section id="xgboost-for-classification" class="level3" data-number="3.16.9">
<h3 data-number="3.16.9" class="anchored" data-anchor-id="xgboost-for-classification"><span class="header-section-number">3.16.9</span> XGboost for classification</h3>
<p>Random forests reduce variance by averaging many decorrelated trees, but they do not directly address model <strong>bias</strong>. Boosting methods particularly <em>gradient boosting</em> take the opposite strategy: build many trees <strong>sequentially</strong>, where each new tree tries to correct the mistakes (the residuals) of the ensemble so far.</p>
<p>XGBoost (<em>Extreme Gradient Boosting</em>) is the most widely used implementation of gradient boosting for tabular data. It fits many shallow trees, each one focusing on the patterns the previous trees failed to capture. The final model is a weighted sum of these trees, typically yielding excellent predictive performance.</p>
<p>For binary classification (our <em>high_response</em> task), XGBoost builds trees that predict the <strong>log-odds</strong> of response and uses a differentiable loss function (usually logistic loss) to guide the sequence of improvements.</p>
<p>Boosting follows this conceptual sequence:</p>
<ol type="1">
<li>Start with a simple model, usually predicting the average log-odds of class 1 .</li>
<li>Compute residuals, which for classification are the gradients of logistic loss.</li>
<li>Grow a small tree that best predicts these residuals.</li>
<li>Add the tree to the model, scaled by a “learning rate”.</li>
<li>Repeat hundreds of times, gradually refining the model.</li>
</ol>
<p>The trees are intentionally shallow ( <span class="math inline">\(2-6\)</span> splits) so that each one captures only simple interactions; the strength comes from the accumulation of many small improvements.</p>
<section id="preparing-the-data-to-run-xgboost" class="level4" data-number="3.16.9.1">
<h4 data-number="3.16.9.1" class="anchored" data-anchor-id="preparing-the-data-to-run-xgboost"><span class="header-section-number">3.16.9.1</span> Preparing the data to run XGboost</h4>
<p>XGBoost requires: - the outcome encoded as 0/1 numeric - predictors in a numeric matrix (no factors)</p>
<p>We therefore recode the data consistently.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert outcome to numeric 0/1</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>train_xgb <span class="ot">&lt;-</span> train_cls <span class="sc">%&gt;%</span></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">high_response =</span> <span class="fu">as.numeric</span>(<span class="fu">as.character</span>(high_response)))</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>test_xgb <span class="ot">&lt;-</span> test_cls <span class="sc">%&gt;%</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">high_response =</span> <span class="fu">as.numeric</span>(<span class="fu">as.character</span>(high_response)))</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert predictors to a numeric matrix</span></span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> train_xgb<span class="sc">$</span>high_response</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>X_train <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(high_response <span class="sc">~</span> . <span class="sc">-</span> <span class="dv">1</span>, <span class="at">data =</span> train_xgb)</span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a>y_test  <span class="ot">&lt;-</span> test_xgb<span class="sc">$</span>high_response</span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a>X_test  <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(high_response <span class="sc">~</span> . <span class="sc">-</span> <span class="dv">1</span>, <span class="at">data =</span> test_xgb)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="fitting-xgboost" class="level3" data-number="3.16.10">
<h3 data-number="3.16.10" class="anchored" data-anchor-id="fitting-xgboost"><span class="header-section-number">3.16.10</span> Fitting XGboost</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>xgb_fit <span class="ot">&lt;-</span> <span class="fu">xgboost</span>(</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> X_train,</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">label =</span> y_train,</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">objective =</span> <span class="st">"binary:logistic"</span>,</span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">nrounds =</span> <span class="dv">150</span>,</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">eta =</span> <span class="fl">0.1</span>,             <span class="co"># learning rate</span></span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">max_depth =</span> <span class="dv">4</span>,</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">min_child_weight =</span> <span class="dv">3</span>,</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">subsample =</span> <span class="fl">0.8</span>,</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">colsample_bytree =</span> <span class="fl">0.6</span>,</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">eval_metric =</span> <span class="st">"logloss"</span>,</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">verbose =</span> <span class="dv">0</span></span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict probabilities on the test set</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>pred_xgb_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(xgb_fit, <span class="at">newdata =</span> X_test)</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to classes</span></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>pred_xgb_class <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(pred_xgb_prob <span class="sc">&gt;=</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>cm_xgb <span class="ot">&lt;-</span> <span class="fu">table</span>(</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">Predicted =</span> pred_xgb_class,</span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">True =</span> y_test</span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>cm_xgb</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         True
Predicted    0    1
        0 1852   27
        1   36 1085</code></pre>
</div>
</div>
</section>
<section id="prediction-and-evaluation" class="level3" data-number="3.16.11">
<h3 data-number="3.16.11" class="anchored" data-anchor-id="prediction-and-evaluation"><span class="header-section-number">3.16.11</span> Prediction and Evaluation</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict probabilities on the test set</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>pred_xgb_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(xgb_fit, <span class="at">newdata =</span> X_test)</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to classes</span></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>pred_xgb_class <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(pred_xgb_prob <span class="sc">&gt;=</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a>cm_xgb <span class="ot">&lt;-</span> <span class="fu">table</span>(</span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">Predicted =</span> pred_xgb_class,</span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">True =</span> y_test</span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a>cm_xgb</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         True
Predicted    0    1
        0 1852   27
        1   36 1085</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>auc_xgb <span class="ot">&lt;-</span> <span class="fu">roc</span>(y_test, pred_xgb_prob)<span class="sc">$</span>auc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting levels: control = 0, case = 1</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting direction: controls &lt; cases</code></pre>
</div>
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>auc_xgb</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Area under the curve: 0.9982</code></pre>
</div>
</div>
<p>XGBoost consistently achieves state-of-the-art performance in tasks involving complex interactions and high dimensionality. Several characteristics make it particularly effective for clinical biomarker modelling:</p>
<p>The first characteristic is the use of <strong>gradient boosting</strong>, where each tree is trained to correct the errors of the previous ensemble. This iterative refinement allows the model to approximate highly nonlinear decision boundaries.</p>
<p>A second strength is <strong>regularization</strong>, both L1 (sparsity) and L2 (shrinkage), which prevents overfitting even when thousands of predictors are available.</p>
<p>A third advantage is <strong>column and row subsampling</strong>, which improves generalization and stabilizes tree structure in datasets dominated by noisy features.</p>
<p>In practice, XGBoost reliably identifies subtle combinations of gene expression patterns that predict tumour response. In our benchmark, it achieves the highest AUC (≈0.998), outperforming both Random Forest and all linear models.</p>
</section>
<section id="re-fitting-the-logistic-regression-model" class="level3" data-number="3.16.12">
<h3 data-number="3.16.12" class="anchored" data-anchor-id="re-fitting-the-logistic-regression-model"><span class="header-section-number">3.16.12</span> Re-fitting the logistic regression model</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure high_response is a factor with correct levels</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>train_cls <span class="ot">&lt;-</span> train_cls <span class="sc">%&gt;%</span> </span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">high_response =</span> <span class="fu">factor</span>(high_response, <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)))</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>test_cls <span class="ot">&lt;-</span> test_cls <span class="sc">%&gt;%</span> </span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">high_response =</span> <span class="fu">factor</span>(high_response, <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)))</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit logistic regression using all predictors</span></span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a>glm_logit <span class="ot">&lt;-</span> <span class="fu">glm</span>(</span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a>  high_response <span class="sc">~</span> .,</span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train_cls,</span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"logit"</span>)</span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: glm.fit: algorithm did not converge</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
</div>
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glm_logit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = high_response ~ ., family = binomial(link = "logit"), 
    data = train_cls)

Coefficients:
                    Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)       -4.621e+02  2.773e+06       0        1
treatmentchemo    -8.278e+00  1.878e+05       0        1
dose_intensity     6.959e+00  1.766e+05       0        1
patient_age       -2.166e-02  8.222e+02       0        1
tumor_gradeG2     -7.342e-01  3.083e+04       0        1
tumor_gradeG3      2.364e+00  3.768e+04       0        1
performance_score -1.027e+00  2.072e+04       0        1
gene_01           -2.212e+00  4.662e+04       0        1
gene_02           -7.427e-01  4.241e+04       0        1
gene_03           -3.158e+00  4.725e+04       0        1
gene_04            9.486e-01  4.378e+04       0        1
gene_05           -4.389e+00  7.996e+04       0        1
gene_06           -1.842e+00  4.131e+04       0        1
gene_07            1.930e+00  3.861e+04       0        1
gene_08            2.282e+01  6.418e+04       0        1
gene_09            9.822e-01  4.462e+04       0        1
gene_10            1.280e+00  4.667e+04       0        1
gene_11            2.077e+00  3.995e+04       0        1
gene_12           -2.437e+00  4.802e+04       0        1
gene_13            2.341e+00  4.225e+04       0        1
gene_14            2.053e+01  5.508e+04       0        1
gene_15            9.468e-01  4.515e+04       0        1
gene_16            6.128e+00  4.592e+04       0        1
gene_17            7.882e-01  4.680e+04       0        1
gene_18            4.287e-01  4.268e+04       0        1
gene_19            1.653e+01  5.858e+04       0        1
gene_20            2.324e+00  4.520e+04       0        1
gene_21           -1.283e+00  4.395e+04       0        1
gene_22           -5.782e-01  4.702e+04       0        1
gene_23           -1.581e+00  4.540e+04       0        1
gene_24            1.716e+00  4.456e+04       0        1
gene_25           -4.102e-01  4.384e+04       0        1
gene_26           -2.000e+00  4.913e+04       0        1
gene_27            3.614e+00  4.093e+04       0        1
gene_28            6.128e-01  4.493e+04       0        1
gene_29            8.504e-01  4.281e+04       0        1
gene_30           -2.530e+00  4.641e+04       0        1
gene_31           -3.446e+00  4.469e+04       0        1
gene_32           -2.765e-01  4.748e+04       0        1
gene_33           -3.891e+00  4.253e+04       0        1
gene_34           -3.956e+00  4.809e+04       0        1
gene_35           -2.129e+00  5.121e+04       0        1
gene_36           -9.715e-01  4.366e+04       0        1
gene_37           -1.589e+00  4.420e+04       0        1
gene_38            5.142e+00  3.811e+04       0        1
gene_39            2.661e-01  4.945e+04       0        1
gene_40           -1.244e+00  4.491e+04       0        1
gene_41           -2.145e+00  5.060e+04       0        1
gene_42            4.458e+00  4.953e+04       0        1
gene_43           -3.837e+00  4.729e+04       0        1
gene_44            2.744e+00  4.553e+04       0        1
gene_45           -1.568e+00  4.570e+04       0        1
gene_46            3.832e+00  4.357e+04       0        1
gene_47           -2.475e+00  4.548e+04       0        1
gene_48            2.453e-01  4.128e+04       0        1
gene_49           -2.177e+00  4.477e+04       0        1
gene_50           -6.271e+00  4.365e+04       0        1
gene_51           -1.659e+00  4.482e+04       0        1
gene_52            3.285e+00  4.935e+04       0        1
gene_53           -1.122e+00  4.460e+04       0        1
gene_54           -6.524e-01  4.474e+04       0        1
gene_55           -2.202e+00  4.442e+04       0        1
gene_56            3.408e+00  4.526e+04       0        1
gene_57            2.738e+00  4.440e+04       0        1
gene_58            2.583e+00  4.773e+04       0        1
gene_59            6.975e+00  5.021e+04       0        1
gene_60            1.172e+00  4.405e+04       0        1
gene_61           -9.131e-02  4.524e+04       0        1
gene_62            2.406e+00  4.190e+04       0        1
gene_63            3.997e-01  5.010e+04       0        1
gene_64           -1.135e+00  4.828e+04       0        1
gene_65            4.063e+00  4.414e+04       0        1
gene_66           -1.088e+00  4.680e+04       0        1
gene_67           -2.286e+00  4.265e+04       0        1
gene_68            1.654e+00  4.198e+04       0        1
gene_69            5.896e+00  5.183e+04       0        1
gene_70            5.891e+00  4.547e+04       0        1
gene_71            2.611e-01  5.184e+04       0        1
gene_72            2.922e+00  4.375e+04       0        1
gene_73           -1.924e+00  4.488e+04       0        1
gene_74            1.038e+00  4.410e+04       0        1
gene_75           -2.215e+00  4.109e+04       0        1
gene_76            4.540e+00  4.780e+04       0        1
gene_77           -3.158e+00  4.802e+04       0        1
gene_78           -3.506e+00  4.589e+04       0        1
gene_79           -2.927e+00  4.191e+04       0        1
gene_80            2.597e+00  4.655e+04       0        1
gene_81           -1.492e+00  4.337e+04       0        1
gene_82           -1.498e+00  4.254e+04       0        1
gene_83            5.030e+00  4.701e+04       0        1
gene_84           -4.174e+00  4.740e+04       0        1
gene_85            1.376e+00  5.021e+04       0        1
gene_86           -2.173e+00  4.203e+04       0        1
gene_87            6.469e-01  4.557e+04       0        1
gene_88            4.718e+00  4.305e+04       0        1
gene_89           -7.473e-01  4.108e+04       0        1
gene_90            4.478e+00  4.646e+04       0        1
gene_91            6.719e-01  4.189e+04       0        1
gene_92           -1.357e+00  3.860e+04       0        1
gene_93           -2.028e+00  4.716e+04       0        1
gene_94            4.859e-01  4.491e+04       0        1
gene_95           -5.528e+00  4.313e+04       0        1
gene_96           -1.793e+00  4.081e+04       0        1
gene_97            3.023e+00  4.402e+04       0        1
gene_98            1.444e+00  4.280e+04       0        1
gene_99           -1.882e+00  4.675e+04       0        1
gene_100           1.193e+00  4.722e+04       0        1
gene_101          -1.037e+00  4.967e+04       0        1
gene_102           2.372e-01  5.024e+04       0        1
gene_103          -1.412e+00  4.609e+04       0        1
gene_104          -4.912e-01  4.202e+04       0        1
gene_105           1.137e+00  4.385e+04       0        1
gene_106           4.062e+00  4.768e+04       0        1
gene_107          -7.803e-01  4.720e+04       0        1
gene_108          -9.054e-01  4.635e+04       0        1
gene_109           3.636e-02  4.771e+04       0        1
gene_110           4.039e+00  4.948e+04       0        1
gene_111          -3.650e-01  4.800e+04       0        1
gene_112          -5.082e-01  4.727e+04       0        1
gene_113           3.804e+00  4.764e+04       0        1
gene_114           7.492e-01  4.832e+04       0        1
gene_115           2.187e+00  4.164e+04       0        1
gene_116           1.498e+00  4.494e+04       0        1
gene_117          -3.397e+00  4.496e+04       0        1
gene_118          -4.769e+00  4.317e+04       0        1
gene_119          -5.671e+00  4.560e+04       0        1
gene_120           2.918e+00  4.405e+04       0        1
gene_121          -7.076e-01  4.937e+04       0        1
gene_122           1.587e+00  5.137e+04       0        1
gene_123           1.183e+00  4.403e+04       0        1
gene_124           4.967e-01  4.565e+04       0        1
gene_125           4.209e-01  4.616e+04       0        1
gene_126          -4.480e+00  4.030e+04       0        1
gene_127           3.821e-01  4.558e+04       0        1
gene_128           5.950e-01  4.174e+04       0        1
gene_129           8.982e-01  4.744e+04       0        1
gene_130           6.619e+00  4.112e+04       0        1
gene_131           4.464e+00  4.339e+04       0        1
gene_132          -1.777e+00  4.740e+04       0        1
gene_133          -1.909e+00  4.621e+04       0        1
gene_134           1.323e+00  5.198e+04       0        1
gene_135           4.360e-01  4.512e+04       0        1
gene_136          -2.448e-01  4.373e+04       0        1
gene_137           3.273e+00  4.782e+04       0        1
gene_138          -8.534e-01  4.348e+04       0        1
gene_139           1.737e+00  4.482e+04       0        1
gene_140           5.835e-01  4.177e+04       0        1
gene_141           3.470e-01  4.834e+04       0        1
gene_142          -1.937e+00  4.312e+04       0        1
gene_143          -1.651e+00  4.304e+04       0        1
gene_144           4.570e+00  4.325e+04       0        1
gene_145           3.153e+00  4.067e+04       0        1
gene_146           5.275e+00  4.348e+04       0        1
gene_147          -1.483e+00  4.363e+04       0        1
gene_148          -2.958e-02  4.225e+04       0        1
gene_149          -3.688e+00  4.154e+04       0        1
gene_150           9.275e-01  4.784e+04       0        1
gene_151          -5.656e-01  4.404e+04       0        1
gene_152           2.940e+00  4.794e+04       0        1
gene_153          -3.666e+00  4.248e+04       0        1
gene_154           1.317e+00  4.763e+04       0        1
gene_155          -2.161e+00  4.824e+04       0        1
gene_156           3.332e-01  4.345e+04       0        1
gene_157           3.172e-01  4.478e+04       0        1
gene_158           2.478e+00  4.561e+04       0        1
gene_159           4.667e-01  4.394e+04       0        1
gene_160          -6.058e-02  4.095e+04       0        1
gene_161          -2.649e+00  4.911e+04       0        1
gene_162          -2.890e+00  4.458e+04       0        1
gene_163          -7.251e+00  4.371e+04       0        1
gene_164          -2.047e+00  4.171e+04       0        1
gene_165          -5.061e+00  4.354e+04       0        1
gene_166           7.553e-01  4.502e+04       0        1
gene_167          -2.852e-02  4.653e+04       0        1
gene_168          -2.234e+00  4.414e+04       0        1
gene_169           2.251e+00  4.216e+04       0        1
gene_170          -2.140e+00  4.171e+04       0        1
gene_171          -4.561e+00  4.652e+04       0        1
gene_172           3.325e-01  4.530e+04       0        1
gene_173          -2.772e+00  4.871e+04       0        1
gene_174           5.240e+00  4.474e+04       0        1
gene_175          -6.821e-01  4.325e+04       0        1
gene_176          -2.296e+00  4.745e+04       0        1
gene_177          -1.768e+00  4.990e+04       0        1
gene_178          -1.185e+00  4.235e+04       0        1
gene_179          -1.682e-01  4.601e+04       0        1
gene_180           5.008e-01  4.357e+04       0        1
gene_181          -2.323e+00  4.555e+04       0        1
gene_182          -2.141e-01  4.417e+04       0        1
gene_183          -6.508e+00  4.843e+04       0        1
gene_184          -3.876e-01  5.237e+04       0        1
gene_185          -4.831e+00  5.099e+04       0        1
gene_186           1.607e+00  4.597e+04       0        1
gene_187           1.196e+00  3.984e+04       0        1
gene_188          -9.955e-01  4.216e+04       0        1
gene_189          -1.895e-01  4.066e+04       0        1
gene_190          -2.020e+00  4.303e+04       0        1
gene_191          -3.128e-01  4.382e+04       0        1
gene_192          -1.828e-01  4.421e+04       0        1
gene_193          -2.463e+00  4.313e+04       0        1
gene_194          -3.139e+00  4.694e+04       0        1
gene_195           1.669e+00  4.536e+04       0        1
gene_196           1.327e+00  4.274e+04       0        1
gene_197           7.651e-01  4.379e+04       0        1
gene_198          -9.987e-01  3.909e+04       0        1
gene_199           1.432e+00  4.699e+04       0        1
gene_200           1.708e+00  4.330e+04       0        1
gene_201           1.432e+00  4.088e+04       0        1
gene_202          -1.752e-01  4.601e+04       0        1
gene_203           2.493e-01  4.802e+04       0        1
gene_204           2.382e-01  4.575e+04       0        1
gene_205           4.263e+00  4.812e+04       0        1
gene_206           3.454e+00  5.045e+04       0        1
gene_207           2.120e+00  4.273e+04       0        1
gene_208          -2.129e+00  4.805e+04       0        1
gene_209          -1.790e+00  4.308e+04       0        1
gene_210           8.272e-01  4.554e+04       0        1
gene_211           6.137e-01  4.337e+04       0        1
gene_212          -5.409e+00  4.810e+04       0        1
gene_213          -1.533e-01  4.505e+04       0        1
gene_214          -1.951e+00  4.556e+04       0        1
gene_215           2.366e-01  4.497e+04       0        1
gene_216           2.184e+00  4.512e+04       0        1
gene_217           1.044e+00  5.006e+04       0        1
gene_218          -4.528e+00  4.084e+04       0        1
gene_219           1.097e+00  4.869e+04       0        1
gene_220          -3.870e+00  5.055e+04       0        1
gene_221           3.625e+00  4.455e+04       0        1
gene_222           1.383e+00  4.559e+04       0        1
gene_223          -1.465e+00  4.229e+04       0        1
gene_224          -1.179e-01  4.149e+04       0        1
gene_225           3.002e+00  4.608e+04       0        1
gene_226           2.169e+00  4.702e+04       0        1
gene_227          -1.582e+00  4.787e+04       0        1
gene_228          -5.287e-01  4.381e+04       0        1
gene_229           1.781e+00  4.702e+04       0        1
gene_230           2.701e+00  4.665e+04       0        1
gene_231           3.633e+00  4.633e+04       0        1
gene_232           1.938e+00  4.614e+04       0        1
gene_233          -2.560e-01  4.556e+04       0        1
gene_234           2.724e+00  4.349e+04       0        1
gene_235          -3.001e+00  4.297e+04       0        1
gene_236           2.106e+00  4.579e+04       0        1
gene_237           3.547e+00  4.587e+04       0        1
gene_238          -1.336e+00  4.541e+04       0        1
gene_239           1.106e+00  4.266e+04       0        1
gene_240          -3.480e+00  4.834e+04       0        1
gene_241          -2.709e+00  4.536e+04       0        1
gene_242           4.642e+00  4.548e+04       0        1
gene_243           2.182e+00  4.801e+04       0        1
gene_244          -1.936e+00  5.015e+04       0        1
gene_245          -3.615e+00  4.716e+04       0        1
gene_246           1.442e+00  4.277e+04       0        1
gene_247          -9.744e-01  4.986e+04       0        1
gene_248           9.580e-01  4.321e+04       0        1
gene_249          -2.059e+00  4.610e+04       0        1
gene_250           1.594e-01  4.910e+04       0        1
gene_251          -1.352e+00  4.986e+04       0        1
gene_252           3.080e-01  4.598e+04       0        1
gene_253          -3.477e+00  4.465e+04       0        1
gene_254          -1.354e-01  4.761e+04       0        1
gene_255           5.796e-01  4.022e+04       0        1
gene_256           2.342e-01  4.579e+04       0        1
gene_257           9.246e-01  4.313e+04       0        1
gene_258          -7.595e-01  4.219e+04       0        1
gene_259           4.144e-01  4.053e+04       0        1
gene_260           4.332e-01  5.213e+04       0        1
gene_261           2.518e-01  4.748e+04       0        1
gene_262           2.832e-01  4.334e+04       0        1
gene_263          -1.215e+00  4.927e+04       0        1
gene_264          -6.575e-01  4.671e+04       0        1
gene_265           3.110e+00  4.458e+04       0        1
gene_266          -7.142e-02  4.160e+04       0        1
gene_267          -6.993e+00  3.863e+04       0        1
gene_268          -2.294e+00  5.181e+04       0        1
gene_269          -4.704e-01  4.201e+04       0        1
gene_270           2.413e+00  4.814e+04       0        1
gene_271          -2.261e+00  4.779e+04       0        1
gene_272           2.378e+00  4.643e+04       0        1
gene_273           5.864e+00  4.511e+04       0        1
gene_274          -2.986e-02  4.328e+04       0        1
gene_275          -1.085e+00  4.642e+04       0        1
gene_276           1.287e+00  4.484e+04       0        1
gene_277          -3.019e+00  4.954e+04       0        1
gene_278           1.745e+00  4.149e+04       0        1
gene_279           2.216e+00  4.425e+04       0        1
gene_280          -4.258e+00  4.570e+04       0        1
gene_281          -2.161e+00  4.899e+04       0        1
gene_282           4.481e+00  4.267e+04       0        1
gene_283           2.118e+00  4.813e+04       0        1
gene_284           5.219e-01  4.631e+04       0        1
gene_285          -7.065e-01  4.359e+04       0        1
gene_286          -3.430e+00  4.428e+04       0        1
gene_287          -3.563e+00  4.240e+04       0        1
gene_288          -1.568e+00  4.526e+04       0        1
gene_289           6.221e-01  4.600e+04       0        1
gene_290           6.298e-01  4.453e+04       0        1
gene_291           5.415e+00  4.422e+04       0        1
gene_292           1.869e+00  4.645e+04       0        1
gene_293          -3.148e+00  4.636e+04       0        1
gene_294          -1.668e+00  4.147e+04       0        1
gene_295           3.672e-01  4.436e+04       0        1
gene_296          -8.683e-01  4.406e+04       0        1
gene_297           3.314e-01  4.833e+04       0        1
gene_298          -1.275e+00  4.728e+04       0        1
gene_299           6.062e+00  4.491e+04       0        1
gene_300           2.598e+00  4.520e+04       0        1
gene_301           1.850e+00  4.521e+04       0        1
gene_302          -3.570e+00  4.717e+04       0        1
gene_303          -6.820e+00  4.307e+04       0        1
gene_304          -2.797e+00  4.643e+04       0        1
gene_305          -5.872e+00  4.913e+04       0        1
gene_306          -2.113e+00  4.658e+04       0        1
gene_307           2.420e+00  4.306e+04       0        1
gene_308          -2.822e+00  4.468e+04       0        1
gene_309          -3.103e+00  4.224e+04       0        1
gene_310           2.030e+00  4.563e+04       0        1
gene_311           5.971e+00  4.588e+04       0        1
gene_312          -5.964e-01  4.499e+04       0        1
gene_313          -4.573e-01  4.548e+04       0        1
gene_314          -4.406e+00  4.631e+04       0        1
gene_315           3.110e+00  4.531e+04       0        1
gene_316           4.651e+00  4.789e+04       0        1
gene_317          -1.195e+00  4.345e+04       0        1
gene_318          -2.066e+00  4.442e+04       0        1
gene_319           3.228e+00  4.853e+04       0        1
gene_320          -4.109e-01  4.335e+04       0        1
gene_321          -5.503e-01  3.950e+04       0        1
gene_322          -1.539e+00  4.845e+04       0        1
gene_323          -1.307e+00  4.024e+04       0        1
gene_324           2.196e+00  4.166e+04       0        1
gene_325           3.813e+00  4.612e+04       0        1
gene_326          -9.091e-01  4.297e+04       0        1
gene_327          -1.330e+00  4.539e+04       0        1
gene_328           3.412e+00  4.788e+04       0        1
gene_329           1.019e+00  4.519e+04       0        1
gene_330          -3.148e+00  4.569e+04       0        1
gene_331          -2.178e+00  4.514e+04       0        1
gene_332           2.923e-01  4.247e+04       0        1
gene_333          -5.608e+00  4.480e+04       0        1
gene_334           2.087e+00  4.479e+04       0        1
gene_335          -3.092e+00  4.185e+04       0        1
gene_336           3.317e+00  4.647e+04       0        1
gene_337           5.799e+00  4.624e+04       0        1
gene_338           5.077e+00  4.460e+04       0        1
gene_339          -1.906e+00  4.311e+04       0        1
gene_340          -8.799e-02  4.096e+04       0        1
gene_341           7.554e-01  4.398e+04       0        1
gene_342          -1.246e+00  4.725e+04       0        1
gene_343          -6.766e-01  4.512e+04       0        1
gene_344          -4.900e+00  4.225e+04       0        1
gene_345          -3.186e+00  4.111e+04       0        1
gene_346          -2.108e+00  4.198e+04       0        1
gene_347          -6.956e-01  4.782e+04       0        1
gene_348          -3.225e-01  4.455e+04       0        1
gene_349          -1.654e+00  4.371e+04       0        1
gene_350          -8.766e-01  4.164e+04       0        1
gene_351          -4.415e+00  4.052e+04       0        1
gene_352           9.497e-01  4.551e+04       0        1
gene_353          -3.802e+00  4.503e+04       0        1
gene_354          -3.836e-01  4.143e+04       0        1
gene_355          -2.089e-01  4.648e+04       0        1
gene_356          -4.737e+00  4.749e+04       0        1
gene_357          -3.869e+00  4.330e+04       0        1
gene_358          -6.505e-01  4.738e+04       0        1
gene_359          -1.538e+00  4.789e+04       0        1
gene_360           3.088e+00  4.954e+04       0        1
gene_361           2.085e+00  4.709e+04       0        1
gene_362           1.933e-01  4.924e+04       0        1
gene_363          -2.374e+00  4.234e+04       0        1
gene_364          -1.360e+00  4.334e+04       0        1
gene_365           2.175e+00  4.642e+04       0        1
gene_366           3.988e+00  4.506e+04       0        1
gene_367          -5.516e-01  4.329e+04       0        1
gene_368          -2.202e-01  4.763e+04       0        1
gene_369          -3.600e-01  5.285e+04       0        1
gene_370           2.094e+00  5.000e+04       0        1
gene_371           1.891e-01  4.153e+04       0        1
gene_372           1.564e-01  4.573e+04       0        1
gene_373          -1.258e+00  4.437e+04       0        1
gene_374           2.449e+00  4.578e+04       0        1
gene_375           3.106e+00  4.604e+04       0        1
gene_376          -6.705e+00  4.637e+04       0        1
gene_377           1.306e+00  4.189e+04       0        1
gene_378           2.014e+00  4.590e+04       0        1
gene_379          -6.571e+00  4.433e+04       0        1
gene_380          -1.437e+00  4.554e+04       0        1
gene_381           3.388e+00  4.162e+04       0        1
gene_382           2.069e+00  5.106e+04       0        1
gene_383           4.472e+00  4.447e+04       0        1
gene_384           4.643e+00  4.493e+04       0        1
gene_385          -5.686e+00  4.352e+04       0        1
gene_386           1.405e+00  4.289e+04       0        1
gene_387          -4.461e+00  4.700e+04       0        1
gene_388          -1.708e+00  4.459e+04       0        1
gene_389          -5.913e-01  4.419e+04       0        1
gene_390           1.296e+00  4.860e+04       0        1
gene_391          -4.617e+00  4.262e+04       0        1
gene_392           1.383e+00  4.584e+04       0        1
gene_393          -4.128e+00  4.375e+04       0        1
gene_394          -1.505e+00  4.897e+04       0        1
gene_395          -8.764e-01  4.479e+04       0        1
gene_396          -5.389e+00  4.492e+04       0        1
gene_397           4.210e+00  4.077e+04       0        1
gene_398          -2.503e+00  4.586e+04       0        1
gene_399          -3.358e+00  4.188e+04       0        1
gene_400          -2.317e+00  4.373e+04       0        1
gene_401          -2.786e+00  4.492e+04       0        1
gene_402          -4.930e+00  4.549e+04       0        1
gene_403           4.375e+00  4.384e+04       0        1
gene_404           1.170e+00  4.287e+04       0        1
gene_405           2.586e-01  4.963e+04       0        1
gene_406          -1.642e+00  4.091e+04       0        1
gene_407           2.658e-01  4.339e+04       0        1
gene_408           3.152e-01  4.734e+04       0        1
gene_409           9.770e-01  4.461e+04       0        1
gene_410          -3.940e+00  4.737e+04       0        1
gene_411          -4.174e+00  4.178e+04       0        1
gene_412          -2.118e+00  4.058e+04       0        1
gene_413           1.445e-01  4.729e+04       0        1
gene_414           2.999e-01  4.603e+04       0        1
gene_415           1.280e+00  4.448e+04       0        1
gene_416           9.304e-04  4.692e+04       0        1
gene_417          -8.362e-01  4.790e+04       0        1
gene_418          -1.977e+00  4.802e+04       0        1
gene_419          -4.002e-02  4.089e+04       0        1
gene_420           2.897e+00  4.024e+04       0        1
gene_421          -2.077e+00  4.120e+04       0        1
gene_422          -3.559e+00  4.475e+04       0        1
gene_423          -1.076e-02  4.296e+04       0        1
gene_424           2.175e+00  4.358e+04       0        1
gene_425           9.485e-01  4.532e+04       0        1
gene_426          -4.263e+00  4.457e+04       0        1
gene_427           3.443e+00  4.480e+04       0        1
gene_428           1.873e+00  4.443e+04       0        1
gene_429           3.211e+00  4.117e+04       0        1
gene_430          -9.417e-01  4.550e+04       0        1
gene_431          -1.805e+00  4.608e+04       0        1
gene_432           3.512e+00  4.393e+04       0        1
gene_433          -1.633e+00  4.340e+04       0        1
gene_434           4.951e+00  4.258e+04       0        1
gene_435          -1.160e+00  4.372e+04       0        1
gene_436          -1.217e+00  4.676e+04       0        1
gene_437           1.697e-02  4.401e+04       0        1
gene_438          -7.155e-01  4.216e+04       0        1
gene_439           2.581e+00  4.200e+04       0        1
gene_440           4.170e-01  4.369e+04       0        1
gene_441          -2.590e+00  4.497e+04       0        1
gene_442           1.282e+00  4.747e+04       0        1
gene_443           2.953e+00  4.608e+04       0        1
gene_444           4.070e+00  4.476e+04       0        1
gene_445           1.946e+00  4.561e+04       0        1
gene_446          -4.309e+00  4.495e+04       0        1
gene_447           6.913e+00  4.902e+04       0        1
gene_448           4.915e+00  4.468e+04       0        1
gene_449          -2.049e+00  4.626e+04       0        1
gene_450           8.218e-02  4.183e+04       0        1
gene_451           4.184e+00  4.245e+04       0        1
gene_452          -4.858e+00  4.363e+04       0        1
gene_453          -7.136e-02  4.529e+04       0        1
gene_454           4.997e-01  4.727e+04       0        1
gene_455          -2.759e+00  4.339e+04       0        1
gene_456          -9.128e-02  4.445e+04       0        1
gene_457          -1.384e-01  4.294e+04       0        1
gene_458           2.198e+00  4.075e+04       0        1
gene_459           6.027e+00  4.358e+04       0        1
gene_460          -4.130e+00  4.455e+04       0        1
gene_461          -1.087e+00  4.152e+04       0        1
gene_462           1.639e+00  4.596e+04       0        1
gene_463           2.876e-01  4.820e+04       0        1
gene_464          -1.185e+00  4.812e+04       0        1
gene_465          -1.790e-01  4.846e+04       0        1
gene_466          -5.517e+00  4.188e+04       0        1
gene_467           2.883e+00  4.213e+04       0        1
gene_468          -2.714e+00  4.659e+04       0        1
gene_469          -1.700e+00  4.917e+04       0        1
gene_470          -3.545e+00  4.290e+04       0        1
gene_471           3.398e+00  4.634e+04       0        1
gene_472          -9.803e-01  5.062e+04       0        1
gene_473          -1.703e-01  4.382e+04       0        1
gene_474          -1.267e+00  4.636e+04       0        1
gene_475           9.380e-01  4.322e+04       0        1
gene_476           1.397e-01  4.943e+04       0        1
gene_477          -2.662e+00  4.110e+04       0        1
gene_478          -1.295e+00  4.864e+04       0        1
gene_479          -8.941e-02  4.173e+04       0        1
gene_480           2.345e+00  4.116e+04       0        1
gene_481          -2.435e+00  4.437e+04       0        1
gene_482          -1.243e+00  4.679e+04       0        1
gene_483          -1.924e+00  4.051e+04       0        1
gene_484           2.086e-01  4.802e+04       0        1
gene_485           4.874e-01  4.770e+04       0        1
gene_486          -4.277e+00  4.420e+04       0        1
gene_487          -2.068e+00  4.389e+04       0        1
gene_488           1.060e+00  4.015e+04       0        1
gene_489           2.943e+00  4.192e+04       0        1
gene_490           1.255e-01  4.503e+04       0        1
gene_491          -2.419e+00  4.574e+04       0        1
gene_492          -3.358e+00  4.441e+04       0        1
gene_493           2.267e+00  4.342e+04       0        1
gene_494           1.095e+00  4.808e+04       0        1
gene_495           1.602e+00  4.106e+04       0        1
gene_496           2.833e+00  4.383e+04       0        1
gene_497           9.113e-01  4.807e+04       0        1
gene_498          -8.802e-01  4.556e+04       0        1
gene_499          -2.074e+00  4.252e+04       0        1
gene_500          -1.218e+00  4.394e+04       0        1
gene_501           1.970e-01  4.089e+04       0        1
gene_502           7.694e-01  4.126e+04       0        1
gene_503           2.464e+00  4.530e+04       0        1
gene_504           4.226e+00  4.590e+04       0        1
gene_505          -2.558e+00  4.467e+04       0        1
gene_506          -2.442e-01  4.164e+04       0        1
gene_507          -2.245e+00  4.164e+04       0        1
gene_508           3.672e+00  4.419e+04       0        1
gene_509           1.992e+00  4.186e+04       0        1
gene_510           2.991e+00  4.542e+04       0        1
gene_511          -4.555e-01  4.234e+04       0        1
gene_512          -2.137e+00  3.984e+04       0        1
gene_513           1.714e-02  4.583e+04       0        1
gene_514          -6.371e-01  4.507e+04       0        1
gene_515           4.668e+00  4.404e+04       0        1
gene_516          -3.285e-01  4.357e+04       0        1
gene_517           1.341e+00  4.476e+04       0        1
gene_518           2.766e+00  4.178e+04       0        1
gene_519          -2.116e+00  4.498e+04       0        1
gene_520          -4.000e+00  4.460e+04       0        1
gene_521          -5.364e+00  4.321e+04       0        1
gene_522          -2.682e+00  4.531e+04       0        1
gene_523           1.289e+00  4.200e+04       0        1
gene_524           1.318e+00  5.069e+04       0        1
gene_525           3.477e+00  4.556e+04       0        1
gene_526           3.411e+00  4.325e+04       0        1
gene_527          -1.331e+00  4.363e+04       0        1
gene_528          -8.127e-01  4.420e+04       0        1
gene_529           2.431e+00  4.734e+04       0        1
gene_530           3.156e+00  4.627e+04       0        1
gene_531          -4.530e+00  4.369e+04       0        1
gene_532           2.734e+00  4.312e+04       0        1
gene_533           2.862e+00  4.475e+04       0        1
gene_534          -3.681e+00  4.890e+04       0        1
gene_535          -4.697e+00  4.917e+04       0        1
gene_536           1.198e+00  4.264e+04       0        1
gene_537           1.399e+00  4.307e+04       0        1
gene_538           2.251e+00  4.826e+04       0        1
gene_539           2.880e+00  4.726e+04       0        1
gene_540          -2.163e+00  4.410e+04       0        1
gene_541          -9.378e-01  4.780e+04       0        1
gene_542           5.088e-01  4.302e+04       0        1
gene_543          -9.462e-02  4.277e+04       0        1
gene_544          -2.899e+00  3.998e+04       0        1
gene_545           3.009e-01  4.619e+04       0        1
gene_546           3.133e+00  4.704e+04       0        1
gene_547           2.286e+00  4.201e+04       0        1
gene_548          -1.448e-01  4.130e+04       0        1
gene_549           2.857e+00  4.459e+04       0        1
gene_550          -2.901e+00  4.765e+04       0        1
gene_551          -7.065e-01  3.942e+04       0        1
gene_552           2.579e+00  4.365e+04       0        1
gene_553           4.465e+00  4.530e+04       0        1
gene_554           8.412e-02  4.361e+04       0        1
gene_555          -3.513e-01  4.285e+04       0        1
gene_556           3.132e+00  4.518e+04       0        1
gene_557           2.855e+00  4.647e+04       0        1
gene_558          -2.126e+00  4.341e+04       0        1
gene_559          -2.158e+00  4.173e+04       0        1
gene_560          -2.889e-01  4.444e+04       0        1
gene_561           1.077e+00  4.649e+04       0        1
gene_562          -3.558e-01  4.556e+04       0        1
gene_563           2.474e+00  4.377e+04       0        1
gene_564           9.546e-01  4.180e+04       0        1
gene_565          -2.042e+00  4.038e+04       0        1
gene_566          -2.558e-01  4.238e+04       0        1
gene_567          -1.067e+00  4.078e+04       0        1
gene_568          -4.891e+00  4.382e+04       0        1
gene_569           1.140e+00  4.523e+04       0        1
gene_570          -1.624e+00  4.334e+04       0        1
gene_571          -1.736e+00  4.446e+04       0        1
gene_572          -6.087e-01  4.620e+04       0        1
gene_573          -1.885e+00  4.047e+04       0        1
gene_574          -2.661e+00  4.702e+04       0        1
gene_575          -1.908e+00  4.130e+04       0        1
gene_576          -9.007e-01  4.410e+04       0        1
gene_577          -1.923e+00  4.431e+04       0        1
gene_578           1.481e-01  4.609e+04       0        1
gene_579           9.415e-01  4.335e+04       0        1
gene_580           7.978e+00  4.615e+04       0        1
gene_581           3.917e+00  4.480e+04       0        1
gene_582           5.127e+00  4.618e+04       0        1
gene_583           1.321e-02  4.325e+04       0        1
gene_584          -8.675e-01  4.825e+04       0        1
gene_585           3.679e+00  4.543e+04       0        1
gene_586          -3.585e+00  4.637e+04       0        1
gene_587          -5.324e-01  4.350e+04       0        1
gene_588           3.538e-02  4.596e+04       0        1
gene_589           1.991e+00  4.664e+04       0        1
gene_590          -2.826e+00  4.349e+04       0        1
gene_591           1.218e+00  4.405e+04       0        1
gene_592           2.416e+00  4.530e+04       0        1
gene_593          -1.083e+00  4.488e+04       0        1
gene_594           8.546e-01  4.778e+04       0        1
gene_595           3.314e+00  4.065e+04       0        1
gene_596           1.612e+00  4.737e+04       0        1
gene_597           5.927e-01  4.293e+04       0        1
gene_598          -1.821e+00  4.783e+04       0        1
gene_599          -6.325e-01  4.666e+04       0        1
gene_600          -2.468e+00  4.591e+04       0        1
gene_601           1.339e+00  4.279e+04       0        1
gene_602           6.609e-01  4.277e+04       0        1
gene_603           2.702e-01  4.524e+04       0        1
gene_604           1.806e-01  5.046e+04       0        1
gene_605           1.807e-01  4.959e+04       0        1
gene_606           6.877e-01  4.099e+04       0        1
gene_607          -6.379e-01  4.291e+04       0        1
gene_608           2.756e+00  4.766e+04       0        1
gene_609          -5.140e+00  4.501e+04       0        1
gene_610          -1.637e+00  4.271e+04       0        1
gene_611          -2.630e+00  4.364e+04       0        1
gene_612          -2.532e+00  4.745e+04       0        1
gene_613           1.481e-01  4.455e+04       0        1
gene_614          -1.518e+00  4.358e+04       0        1
gene_615           3.080e+00  4.120e+04       0        1
gene_616           4.295e+00  4.696e+04       0        1
gene_617           2.233e+00  4.338e+04       0        1
gene_618          -3.166e+00  4.601e+04       0        1
gene_619           7.019e-01  4.581e+04       0        1
gene_620           5.388e+00  4.473e+04       0        1
gene_621           5.773e+00  4.665e+04       0        1
gene_622          -2.674e+00  4.728e+04       0        1
gene_623           1.926e+00  4.182e+04       0        1
gene_624           6.735e-02  4.335e+04       0        1
gene_625          -2.146e+00  4.751e+04       0        1
gene_626          -1.630e+00  4.679e+04       0        1
gene_627           1.747e-02  4.856e+04       0        1
gene_628           3.792e+00  4.516e+04       0        1
gene_629          -1.482e+00  4.827e+04       0        1
gene_630           3.162e+00  4.407e+04       0        1
gene_631          -6.158e-01  4.661e+04       0        1
gene_632           2.757e+00  4.434e+04       0        1
gene_633           2.784e+00  4.800e+04       0        1
gene_634          -1.475e+00  4.299e+04       0        1
gene_635           1.734e+00  4.781e+04       0        1
gene_636          -6.420e-01  4.823e+04       0        1
gene_637          -2.210e+00  4.544e+04       0        1
gene_638           3.507e+00  5.009e+04       0        1
gene_639           3.896e+00  4.889e+04       0        1
gene_640          -6.137e-01  4.970e+04       0        1
gene_641          -3.775e+00  4.902e+04       0        1
gene_642           1.346e+00  4.790e+04       0        1
gene_643          -7.777e-01  3.889e+04       0        1
gene_644          -3.138e+00  4.353e+04       0        1
gene_645           3.284e+00  4.087e+04       0        1
gene_646          -6.107e+00  4.500e+04       0        1
gene_647           6.319e-02  4.826e+04       0        1
gene_648          -1.115e+00  4.622e+04       0        1
gene_649          -6.775e-01  4.060e+04       0        1
gene_650           7.928e-03  4.289e+04       0        1
gene_651           1.379e+00  4.255e+04       0        1
gene_652          -2.327e+00  4.558e+04       0        1
gene_653           2.849e+00  4.484e+04       0        1
gene_654           4.665e+00  4.647e+04       0        1
gene_655          -6.885e-01  4.349e+04       0        1
gene_656           4.813e+00  4.388e+04       0        1
gene_657          -2.084e+00  4.688e+04       0        1
gene_658          -1.377e+00  4.279e+04       0        1
gene_659          -4.729e+00  4.676e+04       0        1
gene_660           1.790e+00  4.871e+04       0        1
gene_661          -9.000e-01  4.557e+04       0        1
gene_662           1.711e+00  4.594e+04       0        1
gene_663           1.681e+00  4.442e+04       0        1
gene_664          -5.551e+00  4.228e+04       0        1
gene_665           4.114e+00  4.680e+04       0        1
gene_666           1.167e+00  4.469e+04       0        1
gene_667           1.351e+00  4.161e+04       0        1
gene_668          -5.125e-01  4.395e+04       0        1
gene_669          -8.853e-01  4.519e+04       0        1
gene_670           3.057e+00  4.702e+04       0        1
gene_671          -1.887e+00  4.650e+04       0        1
gene_672          -2.572e+00  4.343e+04       0        1
gene_673           2.743e+00  4.611e+04       0        1
gene_674          -1.259e+00  4.887e+04       0        1
gene_675          -1.955e-01  4.509e+04       0        1
gene_676           1.982e+00  4.535e+04       0        1
gene_677           1.859e+00  4.147e+04       0        1
gene_678           1.414e+00  4.319e+04       0        1
gene_679           1.611e+00  4.542e+04       0        1
gene_680           6.742e-01  4.874e+04       0        1
gene_681          -8.128e-01  4.593e+04       0        1
gene_682          -1.662e+00  4.662e+04       0        1
gene_683           5.410e-01  4.688e+04       0        1
gene_684          -5.013e+00  4.113e+04       0        1
gene_685          -8.981e-01  4.747e+04       0        1
gene_686           2.928e+00  4.669e+04       0        1
gene_687           1.210e+00  4.085e+04       0        1
gene_688           4.249e+00  4.411e+04       0        1
gene_689          -1.074e+00  4.200e+04       0        1
gene_690          -1.610e+00  4.577e+04       0        1
gene_691           1.016e+00  4.607e+04       0        1
gene_692           7.392e-01  4.213e+04       0        1
gene_693          -2.116e+00  4.226e+04       0        1
gene_694          -1.689e+00  4.404e+04       0        1
gene_695          -1.865e+00  4.412e+04       0        1
gene_696          -1.066e+00  4.828e+04       0        1
gene_697           2.718e-01  4.556e+04       0        1
gene_698           1.421e+00  4.464e+04       0        1
gene_699          -2.734e+00  4.311e+04       0        1
gene_700          -2.167e+00  4.685e+04       0        1
gene_701          -4.436e-02  4.631e+04       0        1
gene_702           9.633e-01  4.382e+04       0        1
gene_703           6.131e-01  4.720e+04       0        1
gene_704           1.276e-01  4.622e+04       0        1
gene_705          -3.528e+00  4.396e+04       0        1
gene_706          -1.235e+00  4.501e+04       0        1
gene_707          -6.893e-01  3.876e+04       0        1
gene_708          -8.714e-01  4.670e+04       0        1
gene_709           1.446e+00  5.238e+04       0        1
gene_710           3.143e+00  4.723e+04       0        1
gene_711           1.231e+00  4.347e+04       0        1
gene_712          -1.700e-01  4.884e+04       0        1
gene_713           3.156e+00  4.547e+04       0        1
gene_714          -2.413e+00  4.720e+04       0        1
gene_715          -2.059e+00  4.259e+04       0        1
gene_716           3.154e+00  4.860e+04       0        1
gene_717           2.189e+00  4.490e+04       0        1
gene_718          -1.157e+00  4.471e+04       0        1
gene_719           1.294e+00  4.886e+04       0        1
gene_720          -9.630e-01  4.205e+04       0        1
gene_721           5.420e+00  4.525e+04       0        1
gene_722           3.168e+00  4.708e+04       0        1
gene_723          -1.271e+00  4.575e+04       0        1
gene_724          -3.907e+00  4.654e+04       0        1
gene_725          -1.685e+00  4.560e+04       0        1
gene_726           1.168e+00  4.545e+04       0        1
gene_727          -4.606e+00  4.622e+04       0        1
gene_728          -2.458e+00  4.414e+04       0        1
gene_729          -8.098e-01  4.918e+04       0        1
gene_730           1.254e+00  4.245e+04       0        1
gene_731          -1.524e+00  4.201e+04       0        1
gene_732           3.909e+00  3.997e+04       0        1
gene_733          -6.874e-02  4.530e+04       0        1
gene_734           1.622e+00  4.351e+04       0        1
gene_735           1.689e+00  4.575e+04       0        1
gene_736          -1.296e+00  5.090e+04       0        1
gene_737          -8.091e-01  4.233e+04       0        1
gene_738          -3.905e-01  4.745e+04       0        1
gene_739           7.930e-01  4.608e+04       0        1
gene_740           8.763e-01  4.393e+04       0        1
gene_741          -7.933e+00  4.882e+04       0        1
gene_742           1.038e+00  4.257e+04       0        1
gene_743           1.342e+00  4.484e+04       0        1
gene_744           3.030e-01  4.969e+04       0        1
gene_745           5.218e-01  4.658e+04       0        1
gene_746           9.767e-01  4.532e+04       0        1
gene_747           1.509e+00  4.333e+04       0        1
gene_748          -8.020e-01  4.929e+04       0        1
gene_749          -8.922e-01  4.335e+04       0        1
gene_750          -1.428e+00  4.332e+04       0        1
gene_751           1.836e+00  4.454e+04       0        1
gene_752           1.005e+00  4.526e+04       0        1
gene_753           2.835e+00  4.520e+04       0        1
gene_754          -3.176e+00  4.529e+04       0        1
gene_755           1.005e+00  4.539e+04       0        1
gene_756          -2.033e+00  4.675e+04       0        1
gene_757          -1.344e+00  4.608e+04       0        1
gene_758           1.429e+00  4.517e+04       0        1
gene_759           1.310e+00  4.582e+04       0        1
gene_760           4.113e+00  4.871e+04       0        1
gene_761           6.236e-01  4.611e+04       0        1
gene_762          -1.231e+00  4.009e+04       0        1
gene_763           2.514e+00  4.530e+04       0        1
gene_764           5.875e-01  4.484e+04       0        1
gene_765          -1.570e+00  4.262e+04       0        1
gene_766           3.793e-01  4.420e+04       0        1
gene_767          -4.305e-01  4.549e+04       0        1
gene_768          -3.419e+00  4.340e+04       0        1
gene_769          -1.855e+00  4.824e+04       0        1
gene_770          -5.353e-01  4.534e+04       0        1
gene_771           2.638e+00  4.600e+04       0        1
gene_772          -4.158e+00  4.663e+04       0        1
gene_773          -1.709e+00  4.685e+04       0        1
gene_774          -3.186e+00  4.663e+04       0        1
gene_775           3.965e-01  4.655e+04       0        1
gene_776          -2.519e+00  4.296e+04       0        1
gene_777           2.340e+00  4.139e+04       0        1
gene_778          -1.039e-01  5.186e+04       0        1
gene_779           8.801e-01  4.696e+04       0        1
gene_780           1.346e+00  4.714e+04       0        1
gene_781           3.323e+00  4.648e+04       0        1
gene_782          -2.793e+00  4.629e+04       0        1
gene_783           1.354e+00  4.553e+04       0        1
gene_784           1.570e+00  4.567e+04       0        1
gene_785           5.125e+00  4.268e+04       0        1
gene_786           1.501e+00  4.827e+04       0        1
gene_787           3.835e+00  4.877e+04       0        1
gene_788           3.139e+00  4.663e+04       0        1
gene_789           3.328e+00  4.290e+04       0        1
gene_790          -1.168e+00  4.640e+04       0        1
gene_791           1.502e+00  4.311e+04       0        1
gene_792          -6.208e+00  4.026e+04       0        1
gene_793           5.806e+00  4.449e+04       0        1
gene_794          -5.033e+00  4.543e+04       0        1
gene_795           1.845e+00  4.708e+04       0        1
gene_796           5.526e-01  4.548e+04       0        1
gene_797           1.395e+00  4.316e+04       0        1
gene_798           1.790e-01  4.067e+04       0        1
gene_799          -5.005e+00  4.315e+04       0        1
gene_800          -8.736e-01  4.652e+04       0        1
gene_801          -2.979e+00  4.611e+04       0        1
gene_802           1.280e+00  4.534e+04       0        1
gene_803           5.364e-01  4.754e+04       0        1
gene_804           8.406e-01  3.916e+04       0        1
gene_805           2.559e-01  4.443e+04       0        1
gene_806          -2.301e+00  4.710e+04       0        1
gene_807           6.020e-01  4.875e+04       0        1
gene_808          -1.555e+00  4.521e+04       0        1
gene_809          -1.538e+00  4.055e+04       0        1
gene_810          -4.207e-01  4.664e+04       0        1
gene_811           2.163e+00  4.800e+04       0        1
gene_812          -6.904e-01  4.678e+04       0        1
gene_813          -7.437e-01  4.440e+04       0        1
gene_814          -1.942e+00  4.629e+04       0        1
gene_815           3.878e+00  4.620e+04       0        1
gene_816           1.957e+00  4.391e+04       0        1
gene_817          -2.241e+00  4.469e+04       0        1
gene_818          -4.586e+00  4.389e+04       0        1
gene_819          -2.876e+00  4.735e+04       0        1
gene_820          -3.498e+00  4.498e+04       0        1
gene_821           1.930e-01  5.485e+04       0        1
gene_822          -1.055e+00  4.180e+04       0        1
gene_823           4.467e+00  4.448e+04       0        1
gene_824           5.184e+00  4.434e+04       0        1
gene_825           3.502e+00  4.444e+04       0        1
gene_826           2.935e+00  4.837e+04       0        1
gene_827           2.549e+00  4.424e+04       0        1
gene_828          -1.001e-01  4.452e+04       0        1
gene_829          -6.847e-01  4.308e+04       0        1
gene_830           5.466e+00  4.608e+04       0        1
gene_831          -2.046e+00  4.809e+04       0        1
gene_832          -2.143e+00  4.248e+04       0        1
gene_833          -8.540e-01  4.963e+04       0        1
gene_834          -1.778e+00  4.255e+04       0        1
gene_835           2.184e-01  4.736e+04       0        1
gene_836           1.819e+00  4.550e+04       0        1
gene_837          -3.661e+00  4.490e+04       0        1
gene_838          -2.826e+00  4.584e+04       0        1
gene_839           8.377e-01  4.570e+04       0        1
gene_840           3.790e+00  4.332e+04       0        1
gene_841           2.024e+00  4.784e+04       0        1
gene_842           9.931e-01  4.432e+04       0        1
gene_843          -1.433e+00  4.824e+04       0        1
gene_844          -4.872e+00  4.217e+04       0        1
gene_845          -2.521e+00  4.537e+04       0        1
gene_846          -9.664e-01  4.405e+04       0        1
gene_847           2.460e+00  4.324e+04       0        1
gene_848          -4.631e+00  4.554e+04       0        1
gene_849          -1.976e+00  4.455e+04       0        1
gene_850          -8.899e-01  4.067e+04       0        1
gene_851           7.086e-01  4.441e+04       0        1
gene_852          -1.425e+00  4.599e+04       0        1
gene_853           7.351e-02  4.510e+04       0        1
gene_854          -1.100e+00  4.442e+04       0        1
gene_855          -3.259e+00  4.250e+04       0        1
gene_856          -2.169e+00  4.751e+04       0        1
gene_857          -1.188e+00  4.099e+04       0        1
gene_858          -8.495e-01  4.167e+04       0        1
gene_859           2.114e+00  4.918e+04       0        1
gene_860           3.614e+00  4.403e+04       0        1
gene_861           4.660e+00  4.453e+04       0        1
gene_862          -3.940e+00  5.030e+04       0        1
gene_863           2.131e+00  5.129e+04       0        1
gene_864          -7.683e-01  4.321e+04       0        1
gene_865          -1.266e+00  4.642e+04       0        1
gene_866           4.440e-01  4.270e+04       0        1
gene_867           1.620e+00  4.486e+04       0        1
gene_868          -1.432e+00  4.264e+04       0        1
gene_869           2.699e+00  4.481e+04       0        1
gene_870          -3.012e+00  4.466e+04       0        1
gene_871           6.437e-01  4.795e+04       0        1
gene_872           1.692e+00  4.467e+04       0        1
gene_873          -3.300e+00  3.673e+04       0        1
gene_874          -1.538e+00  4.884e+04       0        1
gene_875          -3.173e+00  4.500e+04       0        1
gene_876          -4.478e-01  4.558e+04       0        1
gene_877          -1.201e+00  4.524e+04       0        1
gene_878          -2.492e+00  4.641e+04       0        1
gene_879          -5.053e+00  4.198e+04       0        1
gene_880          -9.210e-01  4.673e+04       0        1
gene_881           1.750e+00  4.553e+04       0        1
gene_882          -5.076e+00  4.205e+04       0        1
gene_883          -2.995e+00  5.088e+04       0        1
gene_884          -4.250e-01  3.922e+04       0        1
gene_885           6.669e-01  4.453e+04       0        1
gene_886           2.409e+00  4.467e+04       0        1
gene_887          -1.736e+00  4.238e+04       0        1
gene_888          -1.246e+00  4.555e+04       0        1
gene_889           1.178e+00  4.590e+04       0        1
gene_890           4.644e+00  4.617e+04       0        1
gene_891          -1.991e+00  4.750e+04       0        1
gene_892          -1.732e+00  4.247e+04       0        1
gene_893           1.943e+00  4.612e+04       0        1
gene_894          -2.648e-01  4.124e+04       0        1
gene_895           4.294e+00  4.367e+04       0        1
gene_896          -1.410e+00  4.348e+04       0        1
gene_897          -6.037e-01  4.733e+04       0        1
gene_898          -9.878e-01  4.328e+04       0        1
gene_899          -4.229e-02  4.434e+04       0        1
gene_900           2.039e+00  4.443e+04       0        1
gene_901           3.091e+00  4.222e+04       0        1
gene_902           8.632e-01  4.648e+04       0        1
gene_903           1.282e+00  4.271e+04       0        1
gene_904           1.915e+00  5.077e+04       0        1
gene_905           1.114e+00  4.793e+04       0        1
gene_906          -1.187e+00  4.446e+04       0        1
gene_907          -3.123e+00  4.585e+04       0        1
gene_908           4.164e+00  4.239e+04       0        1
gene_909          -4.876e+00  4.688e+04       0        1
gene_910          -2.238e+00  4.607e+04       0        1
gene_911          -4.799e+00  4.448e+04       0        1
gene_912           2.180e+00  4.725e+04       0        1
gene_913          -2.983e+00  4.750e+04       0        1
gene_914           3.400e+00  4.595e+04       0        1
gene_915           1.826e+00  4.560e+04       0        1
gene_916          -3.154e+00  4.465e+04       0        1
gene_917           1.340e+00  4.792e+04       0        1
gene_918           1.972e+00  4.600e+04       0        1
gene_919           1.865e+00  4.282e+04       0        1
gene_920          -1.228e+00  5.063e+04       0        1
gene_921          -1.954e-01  4.801e+04       0        1
gene_922           1.690e+00  4.640e+04       0        1
gene_923           2.282e-01  4.074e+04       0        1
gene_924           1.636e+00  4.331e+04       0        1
gene_925           2.422e+00  4.496e+04       0        1
gene_926           1.214e+00  4.694e+04       0        1
gene_927           4.149e+00  4.465e+04       0        1
gene_928           1.135e+00  4.207e+04       0        1
gene_929           5.723e-01  4.329e+04       0        1
gene_930          -2.377e+00  4.423e+04       0        1
gene_931          -4.726e+00  4.830e+04       0        1
gene_932           1.014e+00  4.436e+04       0        1
gene_933          -1.322e+00  5.150e+04       0        1
gene_934          -3.191e+00  4.537e+04       0        1
gene_935           3.577e+00  4.410e+04       0        1
gene_936           2.534e+00  4.408e+04       0        1
gene_937           1.849e+00  4.050e+04       0        1
gene_938           7.854e-01  4.786e+04       0        1
gene_939          -9.236e-02  4.298e+04       0        1
gene_940           3.176e-01  4.538e+04       0        1
gene_941          -1.262e+00  4.112e+04       0        1
gene_942           2.550e+00  4.468e+04       0        1
gene_943           5.054e-01  4.581e+04       0        1
gene_944          -4.079e+00  4.309e+04       0        1
gene_945          -2.815e+00  4.688e+04       0        1
gene_946           8.553e-01  4.514e+04       0        1
gene_947          -7.293e+00  4.208e+04       0        1
gene_948           1.993e+00  4.319e+04       0        1
gene_949          -8.090e-01  4.573e+04       0        1
gene_950           8.820e-01  4.168e+04       0        1
gene_951           7.165e-01  4.611e+04       0        1
gene_952          -3.548e+00  4.286e+04       0        1
gene_953          -1.700e+00  4.078e+04       0        1
gene_954           7.803e-02  4.641e+04       0        1
gene_955           3.434e-01  4.467e+04       0        1
gene_956           1.194e+00  4.442e+04       0        1
gene_957           2.396e+00  4.483e+04       0        1
gene_958          -3.507e+00  4.720e+04       0        1
gene_959          -1.454e+00  4.262e+04       0        1
gene_960           2.701e+00  4.318e+04       0        1
gene_961           2.113e+00  4.887e+04       0        1
gene_962          -3.750e+00  4.419e+04       0        1
gene_963          -1.169e+00  4.055e+04       0        1
gene_964           1.824e+00  4.573e+04       0        1
gene_965           4.620e-02  4.747e+04       0        1
gene_966          -3.456e+00  4.883e+04       0        1
gene_967          -1.113e+00  4.320e+04       0        1
gene_968           2.089e-01  4.837e+04       0        1
gene_969          -1.209e+00  4.587e+04       0        1
gene_970          -4.935e+00  4.713e+04       0        1
gene_971           6.075e-01  4.532e+04       0        1
gene_972          -3.233e+00  4.956e+04       0        1
gene_973           1.264e-01  4.650e+04       0        1
gene_974           1.695e+00  4.968e+04       0        1
gene_975           3.694e-01  4.513e+04       0        1
gene_976          -1.343e+00  4.565e+04       0        1
gene_977          -2.361e+00  4.592e+04       0        1
gene_978           1.206e+00  4.301e+04       0        1
gene_979          -2.761e-01  4.129e+04       0        1
gene_980          -2.709e+00  5.111e+04       0        1
gene_981           3.487e+00  4.241e+04       0        1
gene_982           2.991e+00  4.535e+04       0        1
gene_983           2.702e+00  4.926e+04       0        1
gene_984          -2.480e+00  4.310e+04       0        1
gene_985           7.496e-01  4.730e+04       0        1
gene_986          -1.228e+00  4.397e+04       0        1
gene_987           2.161e+00  4.447e+04       0        1
gene_988           3.477e+00  4.325e+04       0        1
gene_989           8.830e-01  4.534e+04       0        1
gene_990          -2.003e+00  4.835e+04       0        1
gene_991           8.186e-01  5.077e+04       0        1
gene_992           2.170e+00  4.301e+04       0        1
gene_993          -1.638e+00  4.084e+04       0        1
gene_994           3.863e+00  4.189e+04       0        1
gene_995           1.350e-01  4.176e+04       0        1
gene_996           3.502e-01  4.061e+04       0        1
gene_997          -8.334e-01  4.415e+04       0        1
gene_998           2.309e+00  4.436e+04       0        1
gene_999           1.790e+00  4.894e+04       0        1
gene_1000         -1.042e+00  4.477e+04       0        1
gene_1001         -2.129e+00  4.994e+04       0        1
gene_1002         -1.948e+00  4.342e+04       0        1
gene_1003          2.414e-01  4.797e+04       0        1
gene_1004          1.606e-01  4.460e+04       0        1
gene_1005         -1.672e+00  4.531e+04       0        1
gene_1006         -1.086e+00  4.248e+04       0        1
gene_1007          8.641e-01  4.465e+04       0        1
gene_1008         -1.028e+00  4.518e+04       0        1
gene_1009          1.827e-01  4.830e+04       0        1
gene_1010         -1.355e+00  4.699e+04       0        1
gene_1011          2.431e+00  4.615e+04       0        1
gene_1012          3.974e+00  4.591e+04       0        1
gene_1013         -3.100e+00  4.370e+04       0        1
gene_1014          1.152e+00  4.050e+04       0        1
gene_1015         -2.145e+00  4.784e+04       0        1
gene_1016         -8.182e-01  4.067e+04       0        1
gene_1017         -8.775e-01  4.684e+04       0        1
gene_1018          5.715e-02  4.649e+04       0        1
gene_1019         -3.465e+00  4.299e+04       0        1
gene_1020          1.723e+00  4.323e+04       0        1
gene_1021          9.837e-01  4.419e+04       0        1
gene_1022         -3.035e+00  4.956e+04       0        1
gene_1023         -1.946e+00  4.542e+04       0        1
gene_1024         -2.095e-01  5.199e+04       0        1
gene_1025          3.862e+00  4.412e+04       0        1
gene_1026         -5.518e-01  4.994e+04       0        1
gene_1027          6.009e-01  4.647e+04       0        1
gene_1028         -8.577e-02  4.817e+04       0        1
gene_1029          1.328e+00  4.205e+04       0        1
gene_1030          7.588e-01  4.578e+04       0        1
gene_1031          3.705e-01  4.365e+04       0        1
gene_1032          1.830e+00  4.710e+04       0        1
gene_1033         -2.457e+00  4.440e+04       0        1
gene_1034          2.183e+00  4.325e+04       0        1
gene_1035         -4.250e-01  4.284e+04       0        1
gene_1036          1.059e+00  4.448e+04       0        1
gene_1037         -3.442e+00  4.302e+04       0        1
gene_1038         -1.089e+00  4.144e+04       0        1
gene_1039          4.663e-01  4.344e+04       0        1
gene_1040          2.102e+00  4.716e+04       0        1
gene_1041          1.917e+00  4.689e+04       0        1
gene_1042         -4.450e-01  4.430e+04       0        1
gene_1043         -8.219e-01  4.780e+04       0        1
gene_1044         -3.349e+00  4.145e+04       0        1
gene_1045         -1.710e+00  4.786e+04       0        1
gene_1046          4.749e+00  4.494e+04       0        1
gene_1047         -1.854e+00  3.961e+04       0        1
gene_1048         -5.982e-01  4.470e+04       0        1
gene_1049         -5.689e+00  4.298e+04       0        1
gene_1050          3.477e+00  4.264e+04       0        1
gene_1051          5.995e-01  4.471e+04       0        1
gene_1052         -3.585e+00  4.501e+04       0        1
gene_1053         -2.602e-01  4.681e+04       0        1
gene_1054         -1.937e+00  4.892e+04       0        1
gene_1055         -4.330e+00  4.471e+04       0        1
gene_1056          3.986e+00  4.265e+04       0        1
gene_1057         -1.368e+00  4.603e+04       0        1
gene_1058          1.626e+00  4.487e+04       0        1
gene_1059         -4.095e+00  4.437e+04       0        1
gene_1060         -2.036e+00  4.399e+04       0        1
gene_1061         -1.745e+00  4.072e+04       0        1
gene_1062          7.200e-02  4.246e+04       0        1
gene_1063         -1.671e+00  3.842e+04       0        1
gene_1064          3.338e+00  4.397e+04       0        1
gene_1065          2.286e+00  4.266e+04       0        1
gene_1066         -6.691e-01  5.045e+04       0        1
gene_1067         -9.421e-01  4.120e+04       0        1
gene_1068         -3.903e+00  4.418e+04       0        1
gene_1069         -1.743e+00  4.128e+04       0        1
gene_1070          3.176e+00  4.207e+04       0        1
gene_1071         -4.552e+00  4.608e+04       0        1
gene_1072         -1.501e+00  4.658e+04       0        1
gene_1073         -4.294e-03  4.478e+04       0        1
gene_1074         -1.752e-01  4.337e+04       0        1
gene_1075         -1.079e+00  4.854e+04       0        1
gene_1076          3.033e+00  3.915e+04       0        1
gene_1077         -2.082e+00  4.961e+04       0        1
gene_1078          3.081e+00  4.249e+04       0        1
gene_1079          4.878e-01  4.919e+04       0        1
gene_1080          2.349e+00  4.819e+04       0        1
gene_1081         -2.652e+00  4.435e+04       0        1
gene_1082         -8.060e-01  4.598e+04       0        1
gene_1083         -2.295e-02  4.267e+04       0        1
gene_1084          5.345e-01  4.513e+04       0        1
gene_1085          1.399e+00  4.460e+04       0        1
gene_1086         -3.366e+00  4.316e+04       0        1
gene_1087          4.186e+00  4.446e+04       0        1
gene_1088          2.012e+00  4.579e+04       0        1
gene_1089          4.849e+00  4.377e+04       0        1
gene_1090          1.922e+00  4.479e+04       0        1
gene_1091          1.334e+00  4.395e+04       0        1
gene_1092          5.613e-02  4.515e+04       0        1
gene_1093          1.700e-01  4.015e+04       0        1
gene_1094          1.686e+00  4.500e+04       0        1
gene_1095          4.657e+00  4.678e+04       0        1
gene_1096         -1.781e-02  4.892e+04       0        1
gene_1097          4.413e+00  4.586e+04       0        1
gene_1098         -1.923e+00  4.517e+04       0        1
gene_1099         -2.292e+00  4.578e+04       0        1
gene_1100         -4.251e+00  4.102e+04       0        1
gene_1101          3.203e+00  4.111e+04       0        1
gene_1102         -2.579e+00  4.466e+04       0        1
gene_1103         -9.769e-01  5.046e+04       0        1
gene_1104         -2.868e+00  4.492e+04       0        1
gene_1105          3.545e+00  4.030e+04       0        1
gene_1106         -1.271e+00  4.298e+04       0        1
gene_1107          1.351e+00  4.449e+04       0        1
gene_1108          2.464e+00  4.063e+04       0        1
gene_1109         -2.515e+00  4.272e+04       0        1
gene_1110          3.369e+00  4.355e+04       0        1
gene_1111         -9.170e-01  4.519e+04       0        1
gene_1112         -1.063e-01  4.693e+04       0        1
gene_1113         -2.123e-01  4.776e+04       0        1
gene_1114          4.068e-02  4.918e+04       0        1
gene_1115          2.033e+00  4.709e+04       0        1
gene_1116         -9.148e-01  4.545e+04       0        1
gene_1117         -3.669e+00  4.497e+04       0        1
gene_1118          5.810e+00  3.963e+04       0        1
gene_1119         -4.507e-01  4.376e+04       0        1
gene_1120         -3.585e+00  4.852e+04       0        1
gene_1121         -1.658e+00  4.539e+04       0        1
gene_1122         -9.343e-01  4.461e+04       0        1
gene_1123         -2.194e+00  4.327e+04       0        1
gene_1124          9.192e-01  4.829e+04       0        1
gene_1125         -3.591e+00  4.416e+04       0        1
gene_1126         -9.191e-01  4.651e+04       0        1
gene_1127          1.754e+00  4.711e+04       0        1
gene_1128          1.072e-02  4.181e+04       0        1
gene_1129          3.705e+00  4.337e+04       0        1
gene_1130          1.406e+00  4.468e+04       0        1
gene_1131          3.424e+00  4.607e+04       0        1
gene_1132          2.307e+00  4.824e+04       0        1
gene_1133          3.142e+00  4.918e+04       0        1
gene_1134         -1.835e+00  4.621e+04       0        1
gene_1135         -9.615e-01  4.098e+04       0        1
gene_1136         -3.006e-01  4.709e+04       0        1
gene_1137          4.830e+00  4.284e+04       0        1
gene_1138          2.401e+00  4.266e+04       0        1
gene_1139          1.105e+00  4.560e+04       0        1
gene_1140          1.436e+00  4.421e+04       0        1
gene_1141         -1.342e+00  4.343e+04       0        1
gene_1142         -7.544e-01  4.361e+04       0        1
gene_1143          1.423e-01  4.724e+04       0        1
gene_1144         -1.234e+00  4.702e+04       0        1
gene_1145          3.038e+00  4.685e+04       0        1
gene_1146         -1.922e+00  4.582e+04       0        1
gene_1147         -1.035e+00  4.552e+04       0        1
gene_1148          4.400e+00  4.435e+04       0        1
gene_1149         -2.200e+00  4.499e+04       0        1
gene_1150          4.080e+00  4.285e+04       0        1
gene_1151         -4.714e+00  4.347e+04       0        1
gene_1152          2.043e+00  4.643e+04       0        1
gene_1153          3.495e+00  4.542e+04       0        1
gene_1154         -1.475e+00  4.303e+04       0        1
gene_1155         -4.290e-01  5.249e+04       0        1
gene_1156         -1.532e+00  4.326e+04       0        1
gene_1157         -5.786e-01  4.832e+04       0        1
gene_1158          2.140e+00  4.565e+04       0        1
gene_1159          2.767e+00  4.381e+04       0        1
gene_1160         -3.908e+00  4.391e+04       0        1
gene_1161          6.464e+00  4.290e+04       0        1
gene_1162         -9.201e-01  4.742e+04       0        1
gene_1163          1.038e+00  4.662e+04       0        1
gene_1164          1.173e+00  4.565e+04       0        1
gene_1165          3.138e+00  4.222e+04       0        1
gene_1166          1.440e+00  4.751e+04       0        1
gene_1167          7.610e-01  4.148e+04       0        1
gene_1168          1.956e+00  4.283e+04       0        1
gene_1169         -4.948e+00  4.284e+04       0        1
gene_1170          8.334e-01  4.543e+04       0        1
gene_1171          4.752e+00  4.501e+04       0        1
gene_1172          2.384e-01  4.051e+04       0        1
gene_1173         -7.514e-01  4.087e+04       0        1
gene_1174          2.471e+00  4.022e+04       0        1
gene_1175          1.602e+00  4.402e+04       0        1
gene_1176          2.991e+00  4.881e+04       0        1
gene_1177         -4.921e+00  3.922e+04       0        1
gene_1178          2.085e+00  4.017e+04       0        1
gene_1179         -1.811e+00  4.468e+04       0        1
gene_1180          2.259e+00  4.411e+04       0        1
gene_1181         -1.914e+00  4.526e+04       0        1
gene_1182         -4.199e+00  4.582e+04       0        1
gene_1183          2.146e+00  4.183e+04       0        1
gene_1184         -2.058e+00  4.870e+04       0        1
gene_1185         -3.055e+00  4.592e+04       0        1
gene_1186          4.077e-02  4.317e+04       0        1
gene_1187          3.510e+00  4.580e+04       0        1
gene_1188         -1.814e-01  4.400e+04       0        1
gene_1189          7.554e-01  4.633e+04       0        1
gene_1190         -1.688e+00  4.724e+04       0        1
gene_1191          9.593e-01  4.422e+04       0        1
gene_1192          4.095e-01  4.208e+04       0        1
gene_1193          1.872e-01  4.422e+04       0        1
gene_1194         -3.137e+00  4.499e+04       0        1
gene_1195          3.465e+00  5.147e+04       0        1
gene_1196          6.887e-01  4.843e+04       0        1
gene_1197         -4.966e+00  4.322e+04       0        1
gene_1198          5.376e+00  5.001e+04       0        1
gene_1199          2.073e+00  4.338e+04       0        1
gene_1200         -7.942e-01  4.487e+04       0        1
gene_1201          4.956e+00  4.325e+04       0        1
gene_1202         -8.074e-01  4.282e+04       0        1
gene_1203          3.758e+00  4.480e+04       0        1
gene_1204          1.495e+00  4.569e+04       0        1
gene_1205         -6.231e+00  4.480e+04       0        1
gene_1206         -1.253e-01  4.481e+04       0        1
gene_1207         -6.408e+00  4.538e+04       0        1
gene_1208          2.728e+00  4.683e+04       0        1
gene_1209         -1.633e+00  4.626e+04       0        1
gene_1210         -1.716e-01  4.709e+04       0        1
gene_1211         -3.446e+00  4.226e+04       0        1
gene_1212          1.575e+00  4.303e+04       0        1
gene_1213         -8.974e-01  4.412e+04       0        1
gene_1214         -6.632e+00  4.577e+04       0        1
gene_1215          1.584e+00  4.896e+04       0        1
gene_1216         -5.466e-01  4.694e+04       0        1
gene_1217          2.576e-01  4.648e+04       0        1
gene_1218         -8.841e-01  4.688e+04       0        1
gene_1219          2.781e+00  4.680e+04       0        1
gene_1220         -1.458e+00  4.274e+04       0        1
gene_1221          1.380e+00  4.498e+04       0        1
gene_1222          4.707e+00  4.935e+04       0        1
gene_1223          2.362e-01  4.511e+04       0        1
gene_1224         -9.443e-01  5.271e+04       0        1
gene_1225          1.329e+00  4.964e+04       0        1
gene_1226         -6.422e-01  4.914e+04       0        1
gene_1227          4.490e+00  5.037e+04       0        1
gene_1228          9.185e-01  4.745e+04       0        1
gene_1229         -3.051e+00  4.292e+04       0        1
gene_1230         -5.312e-01  4.705e+04       0        1
gene_1231         -1.931e-01  4.285e+04       0        1
gene_1232          2.293e+00  5.274e+04       0        1
gene_1233         -4.267e-01  4.271e+04       0        1
gene_1234          2.064e+00  4.876e+04       0        1
gene_1235         -5.604e-01  4.348e+04       0        1
gene_1236         -4.790e+00  4.840e+04       0        1
gene_1237          1.970e+00  4.270e+04       0        1
gene_1238          1.058e-01  4.130e+04       0        1
gene_1239          1.272e+00  4.606e+04       0        1
gene_1240         -2.495e+00  4.172e+04       0        1
gene_1241          3.571e+00  4.288e+04       0        1
gene_1242          4.338e+00  4.701e+04       0        1
gene_1243          2.691e+00  4.677e+04       0        1
gene_1244          1.896e-01  4.539e+04       0        1
gene_1245          8.149e-01  4.943e+04       0        1
gene_1246          5.468e-01  4.428e+04       0        1
gene_1247         -4.066e+00  4.933e+04       0        1
gene_1248          2.247e-02  4.851e+04       0        1
gene_1249         -4.116e+00  4.306e+04       0        1
gene_1250         -1.085e+00  4.479e+04       0        1
gene_1251         -3.368e-01  4.711e+04       0        1
gene_1252          1.590e+00  4.628e+04       0        1
gene_1253         -1.585e+00  4.397e+04       0        1
gene_1254         -3.613e+00  4.883e+04       0        1
gene_1255          3.175e+00  4.592e+04       0        1
gene_1256          6.001e+00  5.205e+04       0        1
gene_1257          2.828e+00  4.368e+04       0        1
gene_1258          6.820e-02  4.650e+04       0        1
gene_1259          4.128e+00  4.405e+04       0        1
gene_1260         -3.961e+00  4.037e+04       0        1
gene_1261         -3.490e-01  4.210e+04       0        1
gene_1262         -2.329e+00  4.317e+04       0        1
gene_1263         -4.320e-01  4.564e+04       0        1
gene_1264         -1.860e+00  4.790e+04       0        1
gene_1265         -3.580e+00  4.602e+04       0        1
gene_1266         -1.551e+00  4.930e+04       0        1
gene_1267         -1.152e+00  4.605e+04       0        1
gene_1268         -6.082e+00  4.664e+04       0        1
gene_1269         -2.913e+00  4.839e+04       0        1
gene_1270         -1.904e+00  4.467e+04       0        1
gene_1271         -3.303e+00  4.108e+04       0        1
gene_1272          3.744e+00  4.553e+04       0        1
gene_1273          3.404e+00  4.373e+04       0        1
gene_1274          1.022e-01  4.604e+04       0        1
gene_1275          5.636e-01  4.680e+04       0        1
gene_1276         -5.799e+00  4.379e+04       0        1
gene_1277          3.808e-01  4.648e+04       0        1
gene_1278          2.249e+00  4.570e+04       0        1
gene_1279         -1.821e+00  4.183e+04       0        1
gene_1280         -4.884e+00  4.445e+04       0        1
gene_1281         -2.281e-01  5.052e+04       0        1
gene_1282          1.419e-01  4.565e+04       0        1
gene_1283         -1.688e+00  4.619e+04       0        1
gene_1284          1.380e+00  4.604e+04       0        1
gene_1285         -2.042e+00  4.485e+04       0        1
gene_1286         -4.857e+00  4.600e+04       0        1
gene_1287         -2.401e+00  4.568e+04       0        1
gene_1288         -2.460e+00  4.564e+04       0        1
gene_1289          6.224e+00  4.332e+04       0        1
gene_1290          1.359e+00  4.827e+04       0        1
gene_1291          2.706e+00  4.610e+04       0        1
gene_1292          7.370e-01  4.563e+04       0        1
gene_1293         -9.135e-02  4.495e+04       0        1
gene_1294         -1.129e+00  4.352e+04       0        1
gene_1295         -4.447e+00  4.578e+04       0        1
gene_1296         -1.482e+00  4.513e+04       0        1
gene_1297          1.821e+00  4.494e+04       0        1
gene_1298         -5.118e-01  4.327e+04       0        1
gene_1299          1.220e+00  4.462e+04       0        1
gene_1300         -1.150e+00  5.144e+04       0        1
gene_1301         -8.632e-02  4.824e+04       0        1
gene_1302          7.638e-01  4.509e+04       0        1
gene_1303         -2.062e-01  4.474e+04       0        1
gene_1304         -4.036e+00  4.480e+04       0        1
gene_1305          1.817e+00  4.825e+04       0        1
gene_1306          4.666e+00  4.319e+04       0        1
gene_1307         -1.783e+00  4.232e+04       0        1
gene_1308         -4.148e+00  4.688e+04       0        1
gene_1309         -4.615e-01  5.086e+04       0        1
gene_1310         -7.959e-01  4.111e+04       0        1
gene_1311          3.070e+00  3.900e+04       0        1
gene_1312         -9.908e-01  4.569e+04       0        1
gene_1313          2.757e-01  4.322e+04       0        1
gene_1314          1.376e-02  4.742e+04       0        1
gene_1315          3.068e+00  4.669e+04       0        1
gene_1316         -2.206e+00  4.489e+04       0        1
gene_1317         -9.317e-01  4.975e+04       0        1
gene_1318         -2.446e+00  4.344e+04       0        1
gene_1319          2.078e+00  4.627e+04       0        1
gene_1320         -5.517e-01  4.175e+04       0        1
gene_1321         -4.960e+00  5.056e+04       0        1
gene_1322          1.179e+00  4.168e+04       0        1
gene_1323         -2.164e-01  4.867e+04       0        1
gene_1324          1.198e+00  4.024e+04       0        1
gene_1325         -1.420e+00  4.217e+04       0        1
gene_1326          1.200e+00  4.451e+04       0        1
gene_1327         -1.217e+00  4.552e+04       0        1
gene_1328          5.363e+00  4.604e+04       0        1
gene_1329          2.956e-03  4.140e+04       0        1
gene_1330          1.369e-01  4.402e+04       0        1
gene_1331         -5.950e-01  4.551e+04       0        1
gene_1332         -2.149e+00  4.447e+04       0        1
gene_1333          5.401e+00  4.536e+04       0        1
gene_1334          2.076e+00  4.204e+04       0        1
gene_1335          6.672e-02  4.803e+04       0        1
gene_1336          1.641e+00  3.754e+04       0        1
gene_1337         -4.073e+00  4.378e+04       0        1
gene_1338         -6.217e+00  4.624e+04       0        1
gene_1339          4.675e+00  4.542e+04       0        1
gene_1340         -3.036e+00  4.568e+04       0        1
gene_1341         -2.035e+00  4.640e+04       0        1
gene_1342         -7.674e-02  4.457e+04       0        1
gene_1343          5.412e+00  4.844e+04       0        1
gene_1344         -2.262e-01  4.251e+04       0        1
gene_1345         -4.385e-01  4.093e+04       0        1
gene_1346          7.339e-02  4.228e+04       0        1
gene_1347         -1.728e+00  4.421e+04       0        1
gene_1348         -6.545e-03  4.232e+04       0        1
gene_1349         -9.868e-01  4.374e+04       0        1
gene_1350         -7.339e-01  4.429e+04       0        1
gene_1351          7.208e-01  4.541e+04       0        1
gene_1352          1.794e+00  4.792e+04       0        1
gene_1353          7.918e-01  4.176e+04       0        1
gene_1354         -8.510e-01  4.233e+04       0        1
gene_1355          1.038e+00  4.557e+04       0        1
gene_1356         -5.587e-01  4.360e+04       0        1
gene_1357         -4.478e+00  4.650e+04       0        1
gene_1358          1.891e+00  4.540e+04       0        1
gene_1359         -4.152e+00  4.506e+04       0        1
gene_1360         -9.909e-01  4.565e+04       0        1
gene_1361          3.778e+00  4.406e+04       0        1
gene_1362          7.588e-01  4.841e+04       0        1
gene_1363          4.959e+00  4.364e+04       0        1
gene_1364          1.482e+00  4.382e+04       0        1
gene_1365          4.843e+00  4.406e+04       0        1
gene_1366          1.219e+00  4.684e+04       0        1
gene_1367         -1.347e+00  4.554e+04       0        1
gene_1368          4.104e-03  4.868e+04       0        1
gene_1369          4.203e-01  4.138e+04       0        1
gene_1370          1.223e+00  4.174e+04       0        1
gene_1371          2.179e+00  5.265e+04       0        1
gene_1372         -4.853e+00  4.159e+04       0        1
gene_1373         -2.021e+00  4.877e+04       0        1
gene_1374         -1.684e+00  4.811e+04       0        1
gene_1375          9.751e-03  4.511e+04       0        1
gene_1376         -2.245e+00  4.363e+04       0        1
gene_1377         -6.714e+00  4.485e+04       0        1
gene_1378         -1.161e+00  4.742e+04       0        1
gene_1379         -7.239e-01  4.883e+04       0        1
gene_1380         -2.596e+00  4.370e+04       0        1
gene_1381         -1.688e+00  4.495e+04       0        1
gene_1382         -1.319e+00  4.836e+04       0        1
gene_1383          1.108e+00  4.462e+04       0        1
gene_1384         -2.770e+00  4.496e+04       0        1
gene_1385          2.690e+00  4.313e+04       0        1
gene_1386         -1.084e-01  4.271e+04       0        1
gene_1387         -1.555e+00  4.925e+04       0        1
gene_1388         -6.706e+00  4.512e+04       0        1
gene_1389          4.131e+00  4.567e+04       0        1
gene_1390         -2.297e+00  4.576e+04       0        1
gene_1391          1.227e+00  4.330e+04       0        1
gene_1392         -2.252e+00  4.585e+04       0        1
gene_1393         -3.665e+00  4.363e+04       0        1
gene_1394          2.236e+00  4.013e+04       0        1
gene_1395         -1.983e+00  4.885e+04       0        1
gene_1396          5.950e-01  4.508e+04       0        1
gene_1397         -8.185e-01  4.499e+04       0        1
gene_1398         -2.970e+00  4.443e+04       0        1
gene_1399         -5.699e+00  4.478e+04       0        1
gene_1400         -1.771e+00  4.168e+04       0        1
gene_1401         -4.225e+00  4.833e+04       0        1
gene_1402          8.945e-01  4.661e+04       0        1
gene_1403         -3.065e+00  4.031e+04       0        1
gene_1404         -4.077e-01  4.649e+04       0        1
gene_1405         -1.101e+00  4.555e+04       0        1
gene_1406          2.636e+00  4.643e+04       0        1
gene_1407         -6.238e-01  4.355e+04       0        1
gene_1408          2.968e+00  4.504e+04       0        1
gene_1409         -1.085e-01  4.103e+04       0        1
gene_1410         -1.723e+00  4.605e+04       0        1
gene_1411         -1.542e+00  4.276e+04       0        1
gene_1412          3.211e+00  4.683e+04       0        1
gene_1413         -1.789e+00  4.104e+04       0        1
gene_1414          1.949e+00  4.428e+04       0        1
gene_1415         -2.861e-01  4.104e+04       0        1
gene_1416         -2.025e+00  4.786e+04       0        1
gene_1417         -8.071e-01  4.519e+04       0        1
gene_1418         -2.631e+00  4.864e+04       0        1
gene_1419         -8.050e-02  4.455e+04       0        1
gene_1420          1.541e+00  4.658e+04       0        1
gene_1421          1.244e+00  4.659e+04       0        1
gene_1422         -3.084e-01  4.062e+04       0        1
gene_1423          9.861e-01  5.029e+04       0        1
gene_1424         -1.754e+00  4.401e+04       0        1
gene_1425          2.064e+00  3.983e+04       0        1
gene_1426         -5.027e+00  4.382e+04       0        1
gene_1427          3.935e-01  4.710e+04       0        1
gene_1428         -2.822e+00  4.561e+04       0        1
gene_1429         -2.352e+00  4.561e+04       0        1
gene_1430          1.662e+00  4.686e+04       0        1
gene_1431          2.440e+00  4.451e+04       0        1
gene_1432         -5.947e-01  4.831e+04       0        1
gene_1433          1.412e+00  4.767e+04       0        1
gene_1434          4.495e+00  4.344e+04       0        1
gene_1435         -9.674e-01  4.698e+04       0        1
gene_1436          6.433e+00  4.593e+04       0        1
gene_1437         -4.447e+00  4.827e+04       0        1
gene_1438          1.732e+00  4.592e+04       0        1
gene_1439          5.857e-01  4.689e+04       0        1
gene_1440          3.694e+00  4.517e+04       0        1
gene_1441         -3.954e+00  4.290e+04       0        1
gene_1442          8.360e-01  4.545e+04       0        1
gene_1443          1.685e+00  4.473e+04       0        1
gene_1444          3.019e+00  4.124e+04       0        1
gene_1445          3.285e+00  4.459e+04       0        1
gene_1446          9.405e-01  4.569e+04       0        1
gene_1447         -9.025e-01  4.719e+04       0        1
gene_1448          3.100e-01  4.547e+04       0        1
gene_1449          5.656e-01  4.834e+04       0        1
gene_1450         -1.084e+00  4.181e+04       0        1
gene_1451          1.154e+00  5.133e+04       0        1
gene_1452          1.830e+00  4.366e+04       0        1
gene_1453         -1.078e+00  4.811e+04       0        1
gene_1454         -2.626e+00  4.822e+04       0        1
gene_1455          4.646e-02  4.632e+04       0        1
gene_1456          9.236e-01  4.517e+04       0        1
gene_1457         -4.333e-01  4.333e+04       0        1
gene_1458         -1.304e+00  4.292e+04       0        1
gene_1459         -2.210e+00  4.437e+04       0        1
gene_1460          3.108e+00  4.957e+04       0        1
gene_1461         -2.137e+00  4.487e+04       0        1
gene_1462         -5.413e-01  4.497e+04       0        1
gene_1463         -2.054e+00  4.091e+04       0        1
gene_1464         -2.834e-01  4.455e+04       0        1
gene_1465          1.696e+00  4.255e+04       0        1
gene_1466          1.991e-01  4.240e+04       0        1
gene_1467          2.840e+00  4.588e+04       0        1
gene_1468         -7.285e+00  4.539e+04       0        1
gene_1469         -1.470e+00  4.060e+04       0        1
gene_1470         -2.317e+00  4.791e+04       0        1
gene_1471          6.604e-01  4.153e+04       0        1
gene_1472          4.739e+00  5.203e+04       0        1
gene_1473         -1.865e-01  4.440e+04       0        1
gene_1474         -4.549e-01  4.439e+04       0        1
gene_1475          6.999e-02  4.427e+04       0        1
gene_1476          1.873e+00  4.371e+04       0        1
gene_1477         -2.658e+00  4.475e+04       0        1
gene_1478          1.252e-01  4.931e+04       0        1
gene_1479          2.240e+00  4.646e+04       0        1
gene_1480          4.774e+00  4.434e+04       0        1
gene_1481          2.607e+00  4.501e+04       0        1
gene_1482         -1.690e+00  4.607e+04       0        1
gene_1483          2.682e+00  4.703e+04       0        1
gene_1484         -5.665e-01  4.619e+04       0        1
gene_1485          2.373e+00  4.263e+04       0        1
gene_1486          4.809e+00  4.548e+04       0        1
gene_1487         -1.690e+00  4.456e+04       0        1
gene_1488         -2.823e-01  4.475e+04       0        1
gene_1489          3.598e+00  4.652e+04       0        1
gene_1490          7.180e+00  4.473e+04       0        1
gene_1491         -9.748e-01  3.989e+04       0        1
gene_1492         -1.643e+00  4.613e+04       0        1
gene_1493         -3.474e-01  4.767e+04       0        1
gene_1494         -1.266e+00  4.325e+04       0        1
gene_1495         -1.154e+00  4.364e+04       0        1
gene_1496          1.067e+00  4.841e+04       0        1
gene_1497         -7.616e-01  4.354e+04       0        1
gene_1498         -3.715e+00  4.397e+04       0        1
gene_1499          1.910e+00  4.474e+04       0        1
gene_1500         -1.482e+00  4.638e+04       0        1
gene_1501          1.759e-01  4.483e+04       0        1
gene_1502         -1.909e-02  4.292e+04       0        1
gene_1503         -2.536e+00  4.940e+04       0        1
gene_1504         -2.207e+00  4.666e+04       0        1
gene_1505          9.596e-01  4.931e+04       0        1
gene_1506          1.821e+00  4.528e+04       0        1
gene_1507          6.495e-01  4.578e+04       0        1
gene_1508          2.457e+00  4.540e+04       0        1
gene_1509         -3.736e+00  4.585e+04       0        1
gene_1510          3.455e+00  4.027e+04       0        1
gene_1511         -1.407e+00  4.475e+04       0        1
gene_1512          2.169e+00  4.386e+04       0        1
gene_1513         -9.476e-01  4.419e+04       0        1
gene_1514          1.968e+00  4.713e+04       0        1
gene_1515         -8.794e-01  4.774e+04       0        1
gene_1516         -8.761e-01  4.786e+04       0        1
gene_1517         -3.024e+00  4.146e+04       0        1
gene_1518         -3.108e+00  4.586e+04       0        1
gene_1519          4.281e+00  4.264e+04       0        1
gene_1520         -1.772e+00  5.104e+04       0        1
gene_1521          1.369e+00  4.052e+04       0        1
gene_1522         -2.080e+00  4.455e+04       0        1
gene_1523          1.531e+00  4.229e+04       0        1
gene_1524          1.309e+00  3.935e+04       0        1
gene_1525         -4.421e+00  4.445e+04       0        1
gene_1526         -2.468e+00  4.431e+04       0        1
gene_1527         -2.973e+00  4.783e+04       0        1
gene_1528          5.051e+00  4.350e+04       0        1
gene_1529         -8.222e-01  4.058e+04       0        1
gene_1530          3.545e+00  4.426e+04       0        1
gene_1531         -4.494e+00  4.787e+04       0        1
gene_1532         -2.099e+00  4.475e+04       0        1
gene_1533         -4.359e-01  4.645e+04       0        1
gene_1534          1.718e+00  4.692e+04       0        1
gene_1535         -1.359e+00  4.625e+04       0        1
gene_1536         -1.125e+00  4.660e+04       0        1
gene_1537         -1.154e-01  4.837e+04       0        1
gene_1538          3.658e-01  4.581e+04       0        1
gene_1539          2.165e+00  4.696e+04       0        1
gene_1540          1.872e+00  4.121e+04       0        1
gene_1541         -1.484e+00  4.667e+04       0        1
gene_1542          1.216e+00  4.402e+04       0        1
gene_1543          4.111e+00  4.225e+04       0        1
gene_1544         -7.536e-01  4.665e+04       0        1
gene_1545         -4.572e+00  4.653e+04       0        1
gene_1546         -8.387e-01  4.386e+04       0        1
gene_1547          5.215e+00  4.979e+04       0        1
gene_1548         -1.447e+00  4.880e+04       0        1
gene_1549         -3.758e+00  4.499e+04       0        1
gene_1550         -2.768e+00  4.021e+04       0        1
gene_1551          1.822e+00  4.638e+04       0        1
gene_1552         -1.257e+00  3.920e+04       0        1
gene_1553          1.585e+00  5.138e+04       0        1
gene_1554         -2.851e+00  4.585e+04       0        1
gene_1555          3.708e-01  4.176e+04       0        1
gene_1556          2.445e+00  4.579e+04       0        1
gene_1557         -1.391e+00  4.617e+04       0        1
gene_1558          1.649e+00  4.786e+04       0        1
gene_1559          2.404e+00  4.619e+04       0        1
gene_1560          1.014e+00  4.576e+04       0        1
gene_1561          1.957e+00  4.452e+04       0        1
gene_1562          1.785e+00  4.376e+04       0        1
gene_1563          1.031e+00  5.017e+04       0        1
gene_1564         -4.808e+00  4.652e+04       0        1
gene_1565         -1.517e+00  4.605e+04       0        1
gene_1566         -1.435e+00  4.199e+04       0        1
gene_1567         -5.240e+00  4.506e+04       0        1
gene_1568         -3.883e+00  4.571e+04       0        1
gene_1569         -2.167e+00  4.249e+04       0        1
gene_1570          3.667e-01  4.608e+04       0        1
gene_1571          9.684e-01  4.467e+04       0        1
gene_1572          4.212e+00  4.437e+04       0        1
gene_1573         -2.118e+00  4.335e+04       0        1
gene_1574          2.694e+00  4.072e+04       0        1
gene_1575         -1.998e+00  4.243e+04       0        1
gene_1576         -3.456e+00  4.243e+04       0        1
gene_1577          3.774e-01  4.100e+04       0        1
gene_1578          1.948e+00  4.317e+04       0        1
gene_1579          2.027e+00  4.715e+04       0        1
gene_1580          3.638e+00  4.389e+04       0        1
gene_1581         -3.364e+00  4.489e+04       0        1
gene_1582         -9.686e-01  4.418e+04       0        1
gene_1583          1.308e+00  4.624e+04       0        1
gene_1584          5.594e-01  4.511e+04       0        1
gene_1585         -2.039e+00  4.796e+04       0        1
gene_1586         -2.243e-01  4.438e+04       0        1
gene_1587         -1.326e+00  4.369e+04       0        1
gene_1588          4.238e-01  4.846e+04       0        1
gene_1589         -4.372e+00  4.457e+04       0        1
gene_1590          3.662e+00  4.366e+04       0        1
gene_1591         -1.591e+00  4.483e+04       0        1
gene_1592          4.985e+00  4.383e+04       0        1
gene_1593          9.002e-01  4.547e+04       0        1
gene_1594         -3.753e+00  4.733e+04       0        1
gene_1595         -2.466e+00  4.389e+04       0        1
gene_1596         -2.223e+00  4.469e+04       0        1
gene_1597          7.536e+00  4.491e+04       0        1
gene_1598         -9.320e-01  4.373e+04       0        1
gene_1599         -1.520e+00  4.824e+04       0        1
gene_1600          8.426e-01  4.406e+04       0        1
gene_1601          9.058e-01  4.629e+04       0        1
gene_1602         -3.036e+00  4.965e+04       0        1
gene_1603          5.809e-01  4.796e+04       0        1
gene_1604         -4.762e+00  4.501e+04       0        1
gene_1605         -1.786e+00  4.513e+04       0        1
gene_1606         -5.960e-01  4.902e+04       0        1
gene_1607          4.894e-01  4.588e+04       0        1
gene_1608          2.651e+00  4.363e+04       0        1
gene_1609          5.570e+00  4.134e+04       0        1
gene_1610         -2.070e+00  4.720e+04       0        1
gene_1611          2.327e+00  5.003e+04       0        1
gene_1612         -1.987e+00  4.685e+04       0        1
gene_1613          2.873e-01  4.652e+04       0        1
gene_1614         -2.134e-01  4.579e+04       0        1
gene_1615         -6.541e-01  4.427e+04       0        1
gene_1616          3.615e+00  4.179e+04       0        1
gene_1617          3.411e+00  4.510e+04       0        1
gene_1618         -2.782e+00  4.108e+04       0        1
gene_1619          5.818e+00  4.151e+04       0        1
gene_1620         -9.357e-01  4.537e+04       0        1
gene_1621         -3.170e+00  4.077e+04       0        1
gene_1622          7.685e-01  4.336e+04       0        1
gene_1623         -6.303e-01  4.732e+04       0        1
gene_1624         -4.966e+00  4.482e+04       0        1
gene_1625         -3.222e+00  4.488e+04       0        1
gene_1626         -2.990e+00  4.552e+04       0        1
gene_1627         -2.804e+00  4.952e+04       0        1
gene_1628         -2.118e+00  4.448e+04       0        1
gene_1629          4.430e+00  4.049e+04       0        1
gene_1630          2.539e+00  4.647e+04       0        1
gene_1631         -4.313e+00  4.936e+04       0        1
gene_1632         -1.747e+00  4.488e+04       0        1
gene_1633          7.503e-01  4.466e+04       0        1
gene_1634          3.554e+00  4.516e+04       0        1
gene_1635          1.936e+00  4.506e+04       0        1
gene_1636         -1.269e+00  4.846e+04       0        1
gene_1637         -9.387e-01  4.447e+04       0        1
gene_1638         -5.299e+00  4.489e+04       0        1
gene_1639         -5.135e-01  4.455e+04       0        1
gene_1640         -4.525e+00  4.782e+04       0        1
gene_1641          7.199e-01  4.355e+04       0        1
gene_1642         -3.667e+00  4.527e+04       0        1
gene_1643          9.477e-01  4.476e+04       0        1
gene_1644         -1.458e+00  4.559e+04       0        1
gene_1645          6.978e-02  4.328e+04       0        1
gene_1646          6.620e-01  4.653e+04       0        1
gene_1647         -4.168e+00  4.523e+04       0        1
gene_1648          4.175e+00  4.460e+04       0        1
gene_1649         -2.185e+00  4.034e+04       0        1
gene_1650          9.186e-01  4.263e+04       0        1
gene_1651          1.861e+00  4.443e+04       0        1
gene_1652          2.712e+00  4.387e+04       0        1
gene_1653          2.092e+00  4.403e+04       0        1
gene_1654          2.464e+00  4.915e+04       0        1
gene_1655         -3.039e-01  5.021e+04       0        1
gene_1656          2.596e-01  4.152e+04       0        1
gene_1657         -5.286e-01  4.142e+04       0        1
gene_1658          2.222e+00  4.077e+04       0        1
gene_1659          1.700e+00  4.503e+04       0        1
gene_1660         -3.774e+00  3.790e+04       0        1
gene_1661         -5.386e-01  4.326e+04       0        1
gene_1662         -3.262e+00  4.543e+04       0        1
gene_1663         -1.795e+00  4.301e+04       0        1
gene_1664          2.794e-01  4.371e+04       0        1
gene_1665          2.886e+00  4.604e+04       0        1
gene_1666         -1.772e+00  4.498e+04       0        1
gene_1667         -1.657e+00  4.637e+04       0        1
gene_1668          1.624e-01  4.494e+04       0        1
gene_1669          6.403e-01  4.789e+04       0        1
gene_1670          2.546e+00  4.600e+04       0        1
gene_1671          3.066e+00  4.431e+04       0        1
gene_1672          1.268e+00  4.195e+04       0        1
gene_1673          1.628e+00  4.584e+04       0        1
gene_1674          3.234e-01  4.492e+04       0        1
gene_1675         -9.319e-02  4.717e+04       0        1
gene_1676          5.838e+00  4.445e+04       0        1
gene_1677          4.015e+00  4.600e+04       0        1
gene_1678         -3.168e-02  4.430e+04       0        1
gene_1679          9.034e-01  4.166e+04       0        1
gene_1680         -8.474e+00  5.008e+04       0        1
gene_1681          1.193e+00  4.584e+04       0        1
gene_1682          2.930e+00  4.186e+04       0        1
gene_1683          4.123e+00  4.250e+04       0        1
gene_1684         -1.937e-01  4.526e+04       0        1
gene_1685         -5.475e+00  4.457e+04       0        1
gene_1686         -3.304e+00  4.316e+04       0        1
gene_1687          5.365e+00  4.596e+04       0        1
gene_1688         -8.293e-01  4.135e+04       0        1
gene_1689         -2.235e+00  4.528e+04       0        1
gene_1690          2.524e+00  4.054e+04       0        1
gene_1691          1.266e+00  4.271e+04       0        1
gene_1692          7.854e-01  4.955e+04       0        1
gene_1693          2.252e-01  4.789e+04       0        1
gene_1694          9.940e-02  4.284e+04       0        1
gene_1695         -2.257e+00  4.105e+04       0        1
gene_1696         -2.315e+00  4.298e+04       0        1
gene_1697          2.266e+00  4.288e+04       0        1
gene_1698         -2.985e+00  4.417e+04       0        1
gene_1699          4.288e-01  4.623e+04       0        1
gene_1700          1.539e+00  4.367e+04       0        1
gene_1701         -4.187e-01  4.920e+04       0        1
gene_1702          5.530e-03  4.617e+04       0        1
gene_1703         -1.143e-01  4.330e+04       0        1
gene_1704          3.258e+00  4.524e+04       0        1
gene_1705         -3.206e+00  4.931e+04       0        1
gene_1706         -3.000e+00  4.567e+04       0        1
gene_1707          2.530e+00  4.325e+04       0        1
gene_1708         -2.444e-01  4.209e+04       0        1
gene_1709         -6.140e-01  4.562e+04       0        1
gene_1710          1.397e+00  4.267e+04       0        1
gene_1711         -4.760e+00  4.649e+04       0        1
gene_1712          7.637e-01  4.329e+04       0        1
gene_1713          2.813e-01  4.299e+04       0        1
gene_1714          3.442e+00  4.405e+04       0        1
gene_1715         -1.294e+00  3.947e+04       0        1
gene_1716         -1.951e+00  4.091e+04       0        1
gene_1717         -5.730e-01  4.657e+04       0        1
gene_1718          4.898e+00  4.661e+04       0        1
gene_1719         -1.228e+00  4.326e+04       0        1
gene_1720          1.048e+00  3.683e+04       0        1
gene_1721          1.056e+00  4.671e+04       0        1
gene_1722         -1.998e+00  4.808e+04       0        1
gene_1723          7.141e-01  4.372e+04       0        1
gene_1724         -9.667e-01  4.702e+04       0        1
gene_1725          9.627e-01  4.882e+04       0        1
gene_1726          4.329e+00  4.482e+04       0        1
gene_1727         -5.438e+00  4.645e+04       0        1
gene_1728          6.427e-01  4.623e+04       0        1
gene_1729          1.653e+00  4.532e+04       0        1
gene_1730         -3.123e-01  4.811e+04       0        1
gene_1731         -3.066e+00  4.138e+04       0        1
gene_1732         -1.299e+00  4.466e+04       0        1
gene_1733         -6.992e-01  4.640e+04       0        1
gene_1734          5.114e+00  4.394e+04       0        1
gene_1735          9.848e-01  4.206e+04       0        1
gene_1736          1.455e-01  4.171e+04       0        1
gene_1737         -7.871e-01  4.534e+04       0        1
gene_1738          3.073e+00  4.662e+04       0        1
gene_1739         -2.731e-01  4.850e+04       0        1
gene_1740          2.206e+00  4.713e+04       0        1
gene_1741         -4.350e+00  4.404e+04       0        1
gene_1742          1.219e+00  4.374e+04       0        1
gene_1743          1.904e+00  4.496e+04       0        1
gene_1744         -2.047e+00  4.623e+04       0        1
gene_1745         -2.323e+00  4.198e+04       0        1
gene_1746          3.564e+00  4.681e+04       0        1
gene_1747          1.131e+00  4.505e+04       0        1
gene_1748         -3.820e-01  4.358e+04       0        1
gene_1749          2.005e+00  4.390e+04       0        1
gene_1750          1.673e-01  4.262e+04       0        1
gene_1751         -4.282e-01  4.189e+04       0        1
gene_1752          1.196e+00  4.611e+04       0        1
gene_1753          2.635e+00  4.379e+04       0        1
gene_1754         -2.561e+00  4.366e+04       0        1
gene_1755          7.525e-01  5.186e+04       0        1
gene_1756          2.146e+00  4.866e+04       0        1
gene_1757          8.176e-01  4.667e+04       0        1
gene_1758         -3.054e+00  4.585e+04       0        1
gene_1759         -2.221e+00  4.362e+04       0        1
gene_1760         -1.552e+00  4.338e+04       0        1
gene_1761         -1.090e+00  4.598e+04       0        1
gene_1762         -4.435e+00  4.616e+04       0        1
gene_1763          1.641e+00  4.272e+04       0        1
gene_1764         -1.468e+00  4.219e+04       0        1
gene_1765          3.268e-01  4.510e+04       0        1
gene_1766          1.498e+00  4.466e+04       0        1
gene_1767         -1.593e+00  4.412e+04       0        1
gene_1768          9.333e+00  4.727e+04       0        1
gene_1769         -2.547e+00  4.443e+04       0        1
gene_1770         -4.199e-01  5.109e+04       0        1
gene_1771          6.607e+00  4.287e+04       0        1
gene_1772         -1.396e+00  4.192e+04       0        1
gene_1773          1.693e+00  4.183e+04       0        1
gene_1774         -8.657e-01  4.652e+04       0        1
gene_1775         -3.702e+00  4.242e+04       0        1
gene_1776         -1.018e-01  4.528e+04       0        1
gene_1777         -8.130e-02  4.833e+04       0        1
gene_1778         -2.987e+00  4.428e+04       0        1
gene_1779          5.787e+00  4.625e+04       0        1
gene_1780         -2.520e+00  4.247e+04       0        1
gene_1781          9.092e-01  4.584e+04       0        1
gene_1782         -1.091e+00  4.630e+04       0        1
gene_1783          3.479e+00  4.867e+04       0        1
gene_1784          1.304e+00  4.078e+04       0        1
gene_1785          3.128e+00  4.227e+04       0        1
gene_1786          1.749e+00  4.413e+04       0        1
gene_1787          3.248e+00  4.539e+04       0        1
gene_1788          1.660e-01  4.430e+04       0        1
gene_1789         -5.521e-01  4.298e+04       0        1
gene_1790          2.181e+00  4.411e+04       0        1
gene_1791          5.359e+00  4.872e+04       0        1
gene_1792          2.699e+00  4.250e+04       0        1
gene_1793          1.735e+00  4.981e+04       0        1
gene_1794          3.053e+00  4.433e+04       0        1
gene_1795          4.244e+00  4.468e+04       0        1
gene_1796         -1.489e-01  4.244e+04       0        1
gene_1797         -3.534e+00  4.320e+04       0        1
gene_1798          1.438e+00  4.448e+04       0        1
gene_1799         -5.403e-01  4.995e+04       0        1
gene_1800          3.799e+00  4.244e+04       0        1
gene_1801         -4.469e+00  4.388e+04       0        1
gene_1802          1.226e-01  4.715e+04       0        1
gene_1803          1.578e-01  4.846e+04       0        1
gene_1804          3.198e+00  4.148e+04       0        1
gene_1805          8.954e-01  4.256e+04       0        1
gene_1806          2.105e+00  4.230e+04       0        1
gene_1807         -1.800e+00  4.601e+04       0        1
gene_1808         -1.679e+00  4.505e+04       0        1
gene_1809         -5.093e+00  4.509e+04       0        1
gene_1810         -5.995e+00  4.307e+04       0        1
gene_1811          3.194e+00  4.734e+04       0        1
gene_1812          4.577e+00  4.439e+04       0        1
gene_1813          3.769e+00  4.221e+04       0        1
gene_1814         -1.481e+00  4.319e+04       0        1
gene_1815          1.072e+00  4.364e+04       0        1
gene_1816          2.201e+00  4.478e+04       0        1
gene_1817          3.042e+00  4.584e+04       0        1
gene_1818         -3.227e+00  4.983e+04       0        1
gene_1819          6.854e-01  4.416e+04       0        1
gene_1820         -1.181e+00  4.760e+04       0        1
gene_1821         -1.091e+00  5.063e+04       0        1
gene_1822          5.724e+00  4.312e+04       0        1
gene_1823         -3.354e+00  4.737e+04       0        1
gene_1824         -3.030e+00  4.750e+04       0        1
gene_1825          2.508e+00  4.527e+04       0        1
gene_1826          4.931e+00  4.325e+04       0        1
gene_1827          1.599e+00  4.566e+04       0        1
gene_1828          1.709e+00  4.577e+04       0        1
gene_1829          5.294e-01  4.722e+04       0        1
gene_1830          4.151e-01  4.296e+04       0        1
gene_1831          2.305e+00  4.403e+04       0        1
gene_1832         -1.565e+00  4.440e+04       0        1
gene_1833         -1.810e+00  4.332e+04       0        1
gene_1834          2.738e+00  4.844e+04       0        1
gene_1835          5.403e+00  4.463e+04       0        1
gene_1836         -3.602e+00  4.377e+04       0        1
gene_1837          4.964e+00  4.328e+04       0        1
gene_1838         -6.321e-01  4.259e+04       0        1
gene_1839         -6.946e-01  4.223e+04       0        1
gene_1840          5.724e+00  4.335e+04       0        1
gene_1841          1.672e+00  4.392e+04       0        1
gene_1842         -2.837e+00  4.303e+04       0        1
gene_1843         -4.647e+00  4.725e+04       0        1
gene_1844          2.637e-01  4.856e+04       0        1
gene_1845          4.285e+00  4.850e+04       0        1
gene_1846          3.081e+00  4.719e+04       0        1
gene_1847         -7.393e-01  4.236e+04       0        1
gene_1848          9.182e-01  4.562e+04       0        1
gene_1849         -4.452e+00  5.138e+04       0        1
gene_1850          1.236e-01  4.727e+04       0        1
gene_1851         -4.020e+00  4.868e+04       0        1
gene_1852          4.382e+00  4.546e+04       0        1
gene_1853         -4.731e-01  4.353e+04       0        1
gene_1854         -1.040e+00  4.292e+04       0        1
gene_1855          1.862e+00  4.313e+04       0        1
gene_1856         -2.007e+00  4.048e+04       0        1
gene_1857         -3.148e+00  4.697e+04       0        1
gene_1858          1.598e+00  5.104e+04       0        1
gene_1859         -8.518e-01  4.781e+04       0        1
gene_1860          3.207e+00  4.984e+04       0        1
gene_1861          3.551e-01  4.540e+04       0        1
gene_1862          2.209e+00  4.853e+04       0        1
gene_1863          3.307e+00  4.260e+04       0        1
gene_1864          1.577e+00  4.201e+04       0        1
gene_1865         -2.195e+00  4.628e+04       0        1
gene_1866          1.308e+00  4.838e+04       0        1
gene_1867          5.235e-01  4.401e+04       0        1
gene_1868          2.226e+00  4.748e+04       0        1
gene_1869          2.399e+00  4.646e+04       0        1
gene_1870          2.088e+00  4.734e+04       0        1
gene_1871         -5.780e+00  4.617e+04       0        1
gene_1872         -9.138e-02  4.782e+04       0        1
gene_1873          2.750e+00  4.466e+04       0        1
gene_1874         -2.277e+00  4.716e+04       0        1
gene_1875         -2.248e+00  4.122e+04       0        1
gene_1876         -2.518e+00  4.751e+04       0        1
gene_1877         -9.207e-01  4.619e+04       0        1
gene_1878          4.518e+00  4.925e+04       0        1
gene_1879          4.868e-01  4.352e+04       0        1
gene_1880         -3.013e+00  4.470e+04       0        1
gene_1881         -7.474e-01  4.477e+04       0        1
gene_1882         -1.817e+00  4.574e+04       0        1
gene_1883          5.072e-04  4.547e+04       0        1
gene_1884          3.804e+00  4.508e+04       0        1
gene_1885         -6.117e-01  4.067e+04       0        1
gene_1886         -3.685e-01  3.758e+04       0        1
gene_1887         -3.663e+00  4.447e+04       0        1
gene_1888         -5.949e-01  4.140e+04       0        1
gene_1889         -1.894e+00  4.560e+04       0        1
gene_1890         -1.000e+00  4.224e+04       0        1
gene_1891          1.093e+00  4.388e+04       0        1
gene_1892          1.128e+00  4.802e+04       0        1
gene_1893         -1.274e+00  4.619e+04       0        1
gene_1894         -1.141e-01  4.724e+04       0        1
gene_1895         -7.431e-01  4.646e+04       0        1
gene_1896          2.452e+00  4.629e+04       0        1
gene_1897         -5.916e+00  4.332e+04       0        1
gene_1898          2.974e+00  4.503e+04       0        1
gene_1899          1.403e+00  4.248e+04       0        1
gene_1900         -9.403e-01  4.530e+04       0        1
gene_1901         -1.364e+00  5.014e+04       0        1
gene_1902          6.917e-01  4.739e+04       0        1
gene_1903          5.604e+00  4.891e+04       0        1
gene_1904         -2.718e-01  4.448e+04       0        1
gene_1905         -6.167e+00  4.785e+04       0        1
gene_1906          3.260e+00  4.284e+04       0        1
gene_1907         -2.029e+00  4.652e+04       0        1
gene_1908         -9.541e-01  4.301e+04       0        1
gene_1909          2.588e+00  4.420e+04       0        1
gene_1910         -3.082e+00  4.041e+04       0        1
gene_1911         -6.889e-01  3.985e+04       0        1
gene_1912         -2.588e+00  4.420e+04       0        1
gene_1913         -1.332e+00  4.172e+04       0        1
gene_1914         -1.864e+00  4.328e+04       0        1
gene_1915          1.082e+00  4.750e+04       0        1
gene_1916         -2.359e+00  4.139e+04       0        1
gene_1917          9.670e-01  5.042e+04       0        1
gene_1918          2.797e+00  4.980e+04       0        1
gene_1919         -5.734e-01  4.701e+04       0        1
gene_1920          1.762e+00  4.741e+04       0        1
gene_1921          3.352e+00  4.217e+04       0        1
gene_1922         -3.825e+00  4.135e+04       0        1
gene_1923          4.200e+00  4.114e+04       0        1
gene_1924         -3.798e+00  5.010e+04       0        1
gene_1925          8.670e-01  4.303e+04       0        1
gene_1926         -1.187e+00  4.600e+04       0        1
gene_1927         -1.399e+00  4.472e+04       0        1
gene_1928         -2.551e+00  4.574e+04       0        1
gene_1929         -1.320e+00  4.552e+04       0        1
gene_1930         -7.666e-01  4.726e+04       0        1
gene_1931          5.893e-01  4.429e+04       0        1
gene_1932         -4.100e+00  4.662e+04       0        1
gene_1933         -1.557e+00  4.564e+04       0        1
gene_1934         -2.254e+00  5.375e+04       0        1
gene_1935          1.432e-01  4.368e+04       0        1
gene_1936         -2.600e+00  4.574e+04       0        1
gene_1937          3.983e+00  4.846e+04       0        1
gene_1938          1.907e+00  4.659e+04       0        1
gene_1939         -1.327e+00  4.601e+04       0        1
gene_1940         -1.102e-01  4.659e+04       0        1
gene_1941          2.959e+00  4.772e+04       0        1
gene_1942          3.799e-01  4.154e+04       0        1
gene_1943         -1.225e+00  4.524e+04       0        1
gene_1944          2.061e+00  4.500e+04       0        1
gene_1945          2.572e-02  4.393e+04       0        1
gene_1946          2.810e-01  4.577e+04       0        1
gene_1947          3.117e+00  4.127e+04       0        1
gene_1948          2.474e+00  4.942e+04       0        1
gene_1949         -1.696e+00  4.316e+04       0        1
gene_1950          4.786e+00  4.547e+04       0        1
gene_1951          3.334e-01  4.307e+04       0        1
gene_1952          5.287e+00  4.212e+04       0        1
gene_1953         -1.336e+00  4.370e+04       0        1
gene_1954          3.956e+00  4.528e+04       0        1
gene_1955          4.266e+00  4.303e+04       0        1
gene_1956          6.683e+00  4.736e+04       0        1
gene_1957         -1.155e+00  4.139e+04       0        1
gene_1958         -2.613e+00  4.488e+04       0        1
gene_1959         -2.227e+00  4.932e+04       0        1
gene_1960         -2.028e+00  4.680e+04       0        1
gene_1961          1.014e+00  4.796e+04       0        1
gene_1962          2.957e+00  4.321e+04       0        1
gene_1963          1.115e+00  4.643e+04       0        1
gene_1964          1.298e-01  5.170e+04       0        1
gene_1965         -2.162e+00  4.364e+04       0        1
gene_1966          2.879e+00  4.540e+04       0        1
gene_1967         -3.023e+00  4.331e+04       0        1
gene_1968         -2.556e+00  4.457e+04       0        1
gene_1969          3.769e+00  4.578e+04       0        1
gene_1970         -3.316e+00  4.140e+04       0        1
gene_1971          3.201e+00  4.358e+04       0        1
gene_1972          4.366e-01  4.180e+04       0        1
gene_1973         -5.561e-01  4.601e+04       0        1
gene_1974          2.545e+00  4.356e+04       0        1
gene_1975         -2.534e-01  4.949e+04       0        1
gene_1976          3.089e+00  4.706e+04       0        1
gene_1977          5.419e-01  4.423e+04       0        1
gene_1978         -2.079e+00  3.955e+04       0        1
gene_1979          1.290e+00  4.777e+04       0        1
gene_1980          4.105e+00  4.199e+04       0        1
gene_1981          3.979e+00  4.539e+04       0        1
gene_1982          3.983e+00  4.899e+04       0        1
gene_1983         -4.914e-01  4.483e+04       0        1
gene_1984          2.728e+00  4.577e+04       0        1
gene_1985         -1.871e+00  4.485e+04       0        1
gene_1986         -3.255e+00  4.380e+04       0        1
gene_1987          2.699e+00  4.764e+04       0        1
gene_1988         -1.213e+00  4.706e+04       0        1
gene_1989         -3.045e+00  4.811e+04       0        1
gene_1990          3.386e-01  4.240e+04       0        1
gene_1991          4.574e+00  4.269e+04       0        1
gene_1992          1.527e+00  4.531e+04       0        1
gene_1993          3.999e+00  4.749e+04       0        1
gene_1994         -1.513e+00  4.258e+04       0        1
gene_1995          2.346e+00  4.511e+04       0        1
gene_1996         -2.262e+00  4.305e+04       0        1
gene_1997          1.744e+00  5.087e+04       0        1
gene_1998          1.934e+00  4.444e+04       0        1
gene_1999          8.743e-01  4.277e+04       0        1
gene_2000          1.115e+00  4.687e+04       0        1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 9.2741e+03  on 6999  degrees of freedom
Residual deviance: 2.0032e-07  on 4993  degrees of freedom
AIC: 4014

Number of Fisher Scoring iterations: 25</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted probabilities</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>pred_logit_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(glm_logit, <span class="at">newdata =</span> test_cls, <span class="at">type =</span> <span class="st">"response"</span>)</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted classes</span></span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>pred_logit_class <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(pred_logit_prob <span class="sc">&gt;=</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a>cm_logit <span class="ot">&lt;-</span> <span class="fu">table</span>(</span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">Predicted =</span> pred_logit_class,</span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">True =</span> test_cls<span class="sc">$</span>high_response</span>
<span id="cb80-11"><a href="#cb80-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb80-12"><a href="#cb80-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-13"><a href="#cb80-13" aria-hidden="true" tabindex="-1"></a>cm_logit</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         True
Predicted    0    1
        0 1706  171
        1  182  941</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>auc_logit <span class="ot">&lt;-</span> <span class="fu">roc</span>(test_cls<span class="sc">$</span>high_response, pred_logit_prob)<span class="sc">$</span>auc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting levels: control = 0, case = 1</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting direction: controls &lt; cases</code></pre>
</div>
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>auc_logit</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Area under the curve: 0.939</code></pre>
</div>
</div>
</section>
<section id="unified-comparison" class="level3" data-number="3.16.13">
<h3 data-number="3.16.13" class="anchored" data-anchor-id="unified-comparison"><span class="header-section-number">3.16.13</span> Unified comparison</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># =======================================================</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Libraries</span></span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a><span class="co"># =======================================================</span></span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tibble)</span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a><span class="co"># =======================================================</span></span>
<span id="cb87-11"><a href="#cb87-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 0) Ensure outcome is coded correctly</span></span>
<span id="cb87-12"><a href="#cb87-12" aria-hidden="true" tabindex="-1"></a><span class="co"># =======================================================</span></span>
<span id="cb87-13"><a href="#cb87-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-14"><a href="#cb87-14" aria-hidden="true" tabindex="-1"></a>train_cls <span class="ot">&lt;-</span> train_cls <span class="sc">%&gt;%</span> </span>
<span id="cb87-15"><a href="#cb87-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">high_response =</span> <span class="fu">factor</span>(high_response, <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)))</span>
<span id="cb87-16"><a href="#cb87-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-17"><a href="#cb87-17" aria-hidden="true" tabindex="-1"></a>test_cls <span class="ot">&lt;-</span> test_cls <span class="sc">%&gt;%</span> </span>
<span id="cb87-18"><a href="#cb87-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">high_response =</span> <span class="fu">factor</span>(high_response, <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)))</span>
<span id="cb87-19"><a href="#cb87-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-20"><a href="#cb87-20" aria-hidden="true" tabindex="-1"></a><span class="co"># =======================================================</span></span>
<span id="cb87-21"><a href="#cb87-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) LOGISTIC REGRESSION</span></span>
<span id="cb87-22"><a href="#cb87-22" aria-hidden="true" tabindex="-1"></a><span class="co"># =======================================================</span></span>
<span id="cb87-23"><a href="#cb87-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-24"><a href="#cb87-24" aria-hidden="true" tabindex="-1"></a>pred_logit_prob  <span class="ot">&lt;-</span> <span class="fu">predict</span>(glm_logit, <span class="at">newdata =</span> test_cls, <span class="at">type =</span> <span class="st">"response"</span>)</span>
<span id="cb87-25"><a href="#cb87-25" aria-hidden="true" tabindex="-1"></a>pred_logit_class <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(pred_logit_prob <span class="sc">&gt;=</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb87-26"><a href="#cb87-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-27"><a href="#cb87-27" aria-hidden="true" tabindex="-1"></a>auc_logit <span class="ot">&lt;-</span> <span class="fu">roc</span>(test_cls<span class="sc">$</span>high_response, pred_logit_prob)<span class="sc">$</span>auc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting levels: control = 0, case = 1</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting direction: controls &lt; cases</code></pre>
</div>
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>cm_logit  <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="at">Predicted =</span> pred_logit_class, <span class="at">True =</span> test_cls<span class="sc">$</span>high_response)</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a><span class="co"># =======================================================</span></span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) CART CLASSIFICATION TREE (PRUNED)</span></span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a><span class="co"># =======================================================</span></span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Build a proper classification tree</span></span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>ct_class <span class="ot">&lt;-</span> <span class="fu">rpart</span>(</span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a>  high_response <span class="sc">~</span> .,</span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train_cls,</span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"class"</span>,</span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">rpart.control</span>(<span class="at">cp =</span> <span class="fl">0.001</span>, <span class="at">maxdepth =</span> <span class="dv">8</span>, <span class="at">minsplit =</span> <span class="dv">30</span>)</span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-15"><a href="#cb90-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Prune using 1-SE rule</span></span>
<span id="cb90-16"><a href="#cb90-16" aria-hidden="true" tabindex="-1"></a><span class="fu">printcp</span>(ct_class)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Classification tree:
rpart(formula = high_response ~ ., data = train_cls, method = "class", 
    control = rpart.control(cp = 0.001, maxdepth = 8, minsplit = 30))

Variables actually used in tree construction:
 [1] gene_05   gene_08   gene_1074 gene_112  gene_14   gene_1654 gene_1721
 [8] gene_19   gene_1982 gene_1986 gene_447  gene_567  gene_694  gene_726 
[15] gene_78  

Root node error: 2637/7000 = 0.37671

n= 7000 

          CP nsplit rel error   xerror      xstd
1  0.8862344      0  1.000000 1.000000 0.0153741
2  0.0125142      1  0.113766 0.124384 0.0067051
3  0.0113766      2  0.101251 0.110732 0.0063435
4  0.0068259      3  0.089875 0.102768 0.0061207
5  0.0026545      5  0.076223 0.094046 0.0058652
6  0.0024649      6  0.073568 0.094805 0.0058879
7  0.0022753      8  0.068639 0.096322 0.0059331
8  0.0020857     11  0.061813 0.095563 0.0059106
9  0.0018961     14  0.054608 0.097459 0.0059667
10 0.0016433     15  0.052711 0.096701 0.0059443
11 0.0011377     18  0.047782 0.096322 0.0059331
12 0.0010000     20  0.045506 0.096701 0.0059443</code></pre>
</div>
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>best_row <span class="ot">&lt;-</span> <span class="fu">which.min</span>(ct_class<span class="sc">$</span>cptable[,<span class="st">"xerror"</span>])</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>xerr_min <span class="ot">&lt;-</span> ct_class<span class="sc">$</span>cptable[best_row, <span class="st">"xerror"</span>]</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>xstd_min <span class="ot">&lt;-</span> ct_class<span class="sc">$</span>cptable[best_row, <span class="st">"xstd"</span>]</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>cp_1se   <span class="ot">&lt;-</span> ct_class<span class="sc">$</span>cptable[ct_class<span class="sc">$</span>cptable[,<span class="st">"xerror"</span>] <span class="sc">&lt;=</span> xerr_min <span class="sc">+</span> xstd_min, <span class="st">"CP"</span>][<span class="dv">1</span>]</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>ct_pruned_cls <span class="ot">&lt;-</span> <span class="fu">prune</span>(ct_class, <span class="at">cp =</span> cp_1se)</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict probabilities and classes</span></span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a>pred_tree_prob  <span class="ot">&lt;-</span> <span class="fu">predict</span>(ct_pruned_cls, <span class="at">newdata =</span> test_cls, <span class="at">type =</span> <span class="st">"prob"</span>)[, <span class="st">"1"</span>]</span>
<span id="cb92-10"><a href="#cb92-10" aria-hidden="true" tabindex="-1"></a>pred_tree_class <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(pred_tree_prob <span class="sc">&gt;=</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb92-11"><a href="#cb92-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-12"><a href="#cb92-12" aria-hidden="true" tabindex="-1"></a>auc_tree <span class="ot">&lt;-</span> <span class="fu">roc</span>(test_cls<span class="sc">$</span>high_response, pred_tree_prob)<span class="sc">$</span>auc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases</code></pre>
</div>
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>cm_tree  <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="at">Predicted =</span> pred_tree_class, <span class="at">True =</span> test_cls<span class="sc">$</span>high_response)</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a><span class="co"># =======================================================</span></span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 3) RANDOM FOREST (ranger)</span></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a><span class="co"># =======================================================</span></span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a>pred_rf_prob  <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_class, <span class="at">data =</span> test_cls)<span class="sc">$</span>predictions[, <span class="st">"1"</span>]</span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a>pred_rf_class <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(pred_rf_prob <span class="sc">&gt;=</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a>auc_rf <span class="ot">&lt;-</span> <span class="fu">roc</span>(test_cls<span class="sc">$</span>high_response, pred_rf_prob)<span class="sc">$</span>auc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases</code></pre>
</div>
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>cm_rf  <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="at">Predicted =</span> pred_rf_class, <span class="at">True =</span> test_cls<span class="sc">$</span>high_response)</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a><span class="co"># =======================================================</span></span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 4) XGBoost </span></span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a><span class="co"># =======================================================</span></span>
<span id="cb96-6"><a href="#cb96-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-7"><a href="#cb96-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Here: y_test is numeric 0/1, X_test is a numeric matrix</span></span>
<span id="cb96-8"><a href="#cb96-8" aria-hidden="true" tabindex="-1"></a>pred_xgb_prob  <span class="ot">&lt;-</span> <span class="fu">predict</span>(xgb_fit, <span class="at">newdata =</span> X_test)</span>
<span id="cb96-9"><a href="#cb96-9" aria-hidden="true" tabindex="-1"></a>pred_xgb_class <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(pred_xgb_prob <span class="sc">&gt;=</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb96-10"><a href="#cb96-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-11"><a href="#cb96-11" aria-hidden="true" tabindex="-1"></a>auc_xgb <span class="ot">&lt;-</span> <span class="fu">roc</span>(y_test, pred_xgb_prob)<span class="sc">$</span>auc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases</code></pre>
</div>
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>cm_xgb  <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="at">Predicted =</span> pred_xgb_class, <span class="at">True =</span> y_test)</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a><span class="co"># =======================================================</span></span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 5) PERFORMANCE SUMMARY TABLE</span></span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a><span class="co"># =======================================================</span></span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a>perf_summary <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">Model =</span> <span class="fu">c</span>(<span class="st">"Logistic Regression"</span>, <span class="st">"Pruned CART Tree"</span>, <span class="st">"Random Forest"</span>, <span class="st">"XGBoost"</span>),</span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">AUC   =</span> <span class="fu">c</span>(auc_logit, auc_tree, auc_rf, auc_xgb),</span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">Notes =</span> <span class="fu">c</span>(</span>
<span id="cb98-11"><a href="#cb98-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Linear baseline; interpretable"</span>,</span>
<span id="cb98-12"><a href="#cb98-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Simple non-linear rules; high variance"</span>,</span>
<span id="cb98-13"><a href="#cb98-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Strong low-variance ensemble"</span>,</span>
<span id="cb98-14"><a href="#cb98-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Best accuracy; low bias + low variance"</span></span>
<span id="cb98-15"><a href="#cb98-15" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb98-16"><a href="#cb98-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb98-17"><a href="#cb98-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-18"><a href="#cb98-18" aria-hidden="true" tabindex="-1"></a>perf_summary</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 3
  Model                 AUC Notes                                 
  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;                                 
1 Logistic Regression 0.939 Linear baseline; interpretable        
2 Pruned CART Tree    0.984 Simple non-linear rules; high variance
3 Random Forest       0.996 Strong low-variance ensemble          
4 XGBoost             0.998 Best accuracy; low bias + low variance</code></pre>
</div>
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="co"># =======================================================</span></span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 6) CONFUSION MATRICES (OPTIONAL PRINT)</span></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a><span class="co"># =======================================================</span></span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a><span class="fu">list</span>(</span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">Logistic_Regression =</span> cm_logit,</span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">CART_Pruned =</span> cm_tree,</span>
<span id="cb100-8"><a href="#cb100-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">Random_Forest =</span> cm_rf,</span>
<span id="cb100-9"><a href="#cb100-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">XGBoost =</span> cm_xgb</span>
<span id="cb100-10"><a href="#cb100-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$Logistic_Regression
         True
Predicted    0    1
        0 1706  171
        1  182  941

$CART_Pruned
         True
Predicted    0    1
        0 1845   38
        1   43 1074

$Random_Forest
         True
Predicted    0    1
        0 1853   56
        1   35 1056

$XGBoost
         True
Predicted    0    1
        0 1852   27
        1   36 1085</code></pre>
</div>
</div>
</section>
<section id="final-comparison-for-all-models-regarding-classification" class="level3" data-number="3.16.14">
<h3 data-number="3.16.14" class="anchored" data-anchor-id="final-comparison-for-all-models-regarding-classification"><span class="header-section-number">3.16.14</span> Final comparison for all models regarding classification</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
</colgroup>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>Model</td>
<td></td>
<td>Accuracy</td>
<td></td>
<td>Sensitivity (Recall)</td>
<td></td>
<td>Specificity</td>
<td></td>
<td>AUC (ROC)</td>
<td></td>
<td>Notes</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><strong>Logistic Regression (GLM)</strong></td>
<td></td>
<td>0.907</td>
<td></td>
<td>0.897</td>
<td></td>
<td>0.913</td>
<td></td>
<td><strong>0.939</strong></td>
<td></td>
<td>Linear baseline; no regularization</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><strong>LASSO Logistic Regression</strong></td>
<td></td>
<td>0.911</td>
<td></td>
<td>0.909</td>
<td></td>
<td>0.913</td>
<td></td>
<td><strong>0.948</strong></td>
<td></td>
<td>Sparse, interpretable; variable selection</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><strong>Ridge Logistic Regression</strong></td>
<td></td>
<td>0.910</td>
<td></td>
<td>0.922</td>
<td></td>
<td>0.903</td>
<td></td>
<td><strong>0.951</strong></td>
<td></td>
<td>Handles correlated genes; no sparsity</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><strong>Elastic Net Logistic Regression</strong></td>
<td></td>
<td>0.910</td>
<td></td>
<td>0.909</td>
<td></td>
<td>0.911</td>
<td></td>
<td><strong>0.949</strong></td>
<td></td>
<td>Best linear compromise; stabilizes groups of genes</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><strong>Pruned CART Tree</strong></td>
<td></td>
<td>0.973</td>
<td></td>
<td>0.966</td>
<td></td>
<td>0.977</td>
<td></td>
<td><strong>0.984</strong></td>
<td></td>
<td>Simple nonlinear rules; interpretable; high variance</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><strong>Random Forest</strong></td>
<td></td>
<td>0.972</td>
<td></td>
<td>0.950</td>
<td></td>
<td>0.982</td>
<td></td>
<td><strong>0.996</strong></td>
<td></td>
<td>Low variance ensemble; handles interactions</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><strong>XGBoost</strong></td>
<td></td>
<td><strong>0.987</strong></td>
<td></td>
<td><strong>0.976</strong></td>
<td></td>
<td><strong>0.981</strong></td>
<td></td>
<td><strong>0.998</strong></td>
<td></td>
<td>Best accuracy; low bias; robust in high dimension</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>The full benchmark highlights a clear hierarchy in classification performance. Penalized logistic regression models (LASSO, Ridge, Elastic Net) outperform standard logistic regression by stabilizing coefficients and reducing overfitting, but remain limited by their linear functional form. Pruned CART models provide interpretable if–then clinical rules and perform much better than linear methods, but still exhibit high variance in high-dimensional genomic settings. Random Forests further improve performance through bagging and feature subsampling, achieving an AUC above 0.99. XGBoost achieves the strongest overall performance (AUC ≈ 0.998), leveraging gradient boosting, regularization, and subsampling to capture subtle nonlinear gene–gene interactions. This pattern is consistent with modern biomedical machine learning: as complexity and dimensionality rise, ensemble tree-based models tend to dominate in predictive accuracy.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/danilosarti\.github\.io\/att_ml_ai_book");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./supervised_regression.html" class="pagination-link" aria-label="Supervised Learning: Regression tasks">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Supervised Learning: Regression tasks</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./neural_networks.html" class="pagination-link" aria-label="Neural networks and deep learning">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Neural networks and deep learning</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>