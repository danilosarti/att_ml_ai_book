<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>4&nbsp; Neural networks and deep learning – Introduction to Machine Learning and AI for Health Sciences</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./introd_bayesian.html" rel="next">
<link href="./three_methods.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="site_libs/quarto-diagram/mermaid.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./neural_networks.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Neural networks and deep learning</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Machine Learning and AI for Health Sciences</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction_AI.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to AI and Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./supervised_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Supervised Learning: Regression tasks</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./three_methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Supervised Learning: Tree Methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./neural_networks.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Neural networks and deep learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introd_bayesian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introduction to Bayesian methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro_missing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Introduction to missing data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./high_dims.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">High Dimension Data Strategies</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpretable.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Interpretable AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./genai_foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">GenAI: Foundations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./genai_app.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">GenAI: Applications</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#setting-up-r" id="toc-setting-up-r" class="nav-link active" data-scroll-target="#setting-up-r"><span class="header-section-number">4.1</span> Setting up R</a></li>
  <li><a href="#neuromorphism" id="toc-neuromorphism" class="nav-link" data-scroll-target="#neuromorphism"><span class="header-section-number">4.2</span> Neuromorphism</a></li>
  <li><a href="#what-is-inside-our-brain" id="toc-what-is-inside-our-brain" class="nav-link" data-scroll-target="#what-is-inside-our-brain"><span class="header-section-number">4.3</span> What is inside our brain!</a></li>
  <li><a href="#the-artificial-neuron-perceptron" id="toc-the-artificial-neuron-perceptron" class="nav-link" data-scroll-target="#the-artificial-neuron-perceptron"><span class="header-section-number">4.4</span> The artificial neuron (Perceptron)</a></li>
  <li><a href="#inputs-and-weights" id="toc-inputs-and-weights" class="nav-link" data-scroll-target="#inputs-and-weights"><span class="header-section-number">4.5</span> Inputs and Weights</a></li>
  <li><a href="#weighted-sum-aggregation" id="toc-weighted-sum-aggregation" class="nav-link" data-scroll-target="#weighted-sum-aggregation"><span class="header-section-number">4.6</span> Weighted Sum (Aggregation)</a></li>
  <li><a href="#nonlinear-activation-function" id="toc-nonlinear-activation-function" class="nav-link" data-scroll-target="#nonlinear-activation-function"><span class="header-section-number">4.7</span> Nonlinear Activation Function</a></li>
  <li><a href="#output" id="toc-output" class="nav-link" data-scroll-target="#output"><span class="header-section-number">4.8</span> Output</a></li>
  <li><a href="#learning-the-parameters" id="toc-learning-the-parameters" class="nav-link" data-scroll-target="#learning-the-parameters"><span class="header-section-number">4.9</span> Learning the Parameters</a></li>
  <li><a href="#geometric-interpretation" id="toc-geometric-interpretation" class="nav-link" data-scroll-target="#geometric-interpretation"><span class="header-section-number">4.10</span> Geometric Interpretation</a></li>
  <li><a href="#visualisation-of-a-perceptron" id="toc-visualisation-of-a-perceptron" class="nav-link" data-scroll-target="#visualisation-of-a-perceptron"><span class="header-section-number">4.11</span> Visualisation of a perceptron</a></li>
  <li><a href="#the-perceptron-as-the-building-block-of-neural-networks" id="toc-the-perceptron-as-the-building-block-of-neural-networks" class="nav-link" data-scroll-target="#the-perceptron-as-the-building-block-of-neural-networks"><span class="header-section-number">4.12</span> The Perceptron as the Building Block of Neural Networks</a></li>
  <li><a href="#from-a-single-perceptron-to-a-full-neural-network-the-layered-architecture" id="toc-from-a-single-perceptron-to-a-full-neural-network-the-layered-architecture" class="nav-link" data-scroll-target="#from-a-single-perceptron-to-a-full-neural-network-the-layered-architecture"><span class="header-section-number">4.13</span> From a Single Perceptron to a Full Neural Network (The Layered Architecture)</a></li>
  <li><a href="#deep-learning" id="toc-deep-learning" class="nav-link" data-scroll-target="#deep-learning"><span class="header-section-number">4.14</span> Deep learning</a></li>
  <li><a href="#from-tables-to-tensors" id="toc-from-tables-to-tensors" class="nav-link" data-scroll-target="#from-tables-to-tensors"><span class="header-section-number">4.15</span> From Tables to Tensors</a></li>
  <li><a href="#images-as-numerical-data-across-medical-modalities" id="toc-images-as-numerical-data-across-medical-modalities" class="nav-link" data-scroll-target="#images-as-numerical-data-across-medical-modalities"><span class="header-section-number">4.16</span> Images as Numerical Data Across Medical Modalities</a></li>
  <li><a href="#using-pretrained-architectures-for-medical-imaging" id="toc-using-pretrained-architectures-for-medical-imaging" class="nav-link" data-scroll-target="#using-pretrained-architectures-for-medical-imaging"><span class="header-section-number">4.17</span> Using Pretrained Architectures for Medical Imaging</a></li>
  <li><a href="#toy-data-for-the-chapter" id="toc-toy-data-for-the-chapter" class="nav-link" data-scroll-target="#toy-data-for-the-chapter"><span class="header-section-number">4.18</span> Toy Data for the chapter</a>
  <ul class="collapse">
  <li><a href="#image-compression" id="toc-image-compression" class="nav-link" data-scroll-target="#image-compression"><span class="header-section-number">4.18.1</span> Image compression</a></li>
  <li><a href="#what-the-figures-show" id="toc-what-the-figures-show" class="nav-link" data-scroll-target="#what-the-figures-show"><span class="header-section-number">4.18.2</span> What the figures show</a></li>
  </ul></li>
  <li><a href="#fitting-a-naive-neural-network-for-prediction-of-pneumonia" id="toc-fitting-a-naive-neural-network-for-prediction-of-pneumonia" class="nav-link" data-scroll-target="#fitting-a-naive-neural-network-for-prediction-of-pneumonia"><span class="header-section-number">4.19</span> Fitting a naive neural network for prediction of pneumonia</a>
  <ul class="collapse">
  <li><a href="#by-with-a-little-from-python" id="toc-by-with-a-little-from-python" class="nav-link" data-scroll-target="#by-with-a-little-from-python"><span class="header-section-number">4.19.1</span> By with a little from Python</a></li>
  <li><a href="#a-short-note-on-pytorch" id="toc-a-short-note-on-pytorch" class="nav-link" data-scroll-target="#a-short-note-on-pytorch"><span class="header-section-number">4.19.2</span> A short note on PyTorch</a></li>
  <li><a href="#evaluating-all-models-fitted-in-python" id="toc-evaluating-all-models-fitted-in-python" class="nav-link" data-scroll-target="#evaluating-all-models-fitted-in-python"><span class="header-section-number">4.19.3</span> Evaluating all models fitted in Python</a></li>
  </ul></li>
  <li><a href="#comparing-naive-approach-and-other-methods-fitted-in-python" id="toc-comparing-naive-approach-and-other-methods-fitted-in-python" class="nav-link" data-scroll-target="#comparing-naive-approach-and-other-methods-fitted-in-python"><span class="header-section-number">4.20</span> Comparing naive approach and other methods fitted in Python</a></li>
  <li><a href="#economic-and-regulatory-considerations-in-deploying-deep-learning-for-medical-imaging" id="toc-economic-and-regulatory-considerations-in-deploying-deep-learning-for-medical-imaging" class="nav-link" data-scroll-target="#economic-and-regulatory-considerations-in-deploying-deep-learning-for-medical-imaging"><span class="header-section-number">4.21</span> Economic and Regulatory Considerations in Deploying Deep Learning for Medical Imaging</a></li>
  <li><a href="#another-example-of-usage-of-neural-networks-in-large-datasets" id="toc-another-example-of-usage-of-neural-networks-in-large-datasets" class="nav-link" data-scroll-target="#another-example-of-usage-of-neural-networks-in-large-datasets"><span class="header-section-number">4.22</span> Another example of usage of neural networks in large datasets</a>
  <ul class="collapse">
  <li><a href="#comparing-multi-response-neural-networks-with-single-response-models" id="toc-comparing-multi-response-neural-networks-with-single-response-models" class="nav-link" data-scroll-target="#comparing-multi-response-neural-networks-with-single-response-models"><span class="header-section-number">4.22.1</span> Comparing multi-response neural networks with single-response models</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">4.22.2</span> Summary</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Neural networks and deep learning</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="setting-up-r" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="setting-up-r"><span class="header-section-number">4.1</span> Setting up R</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>required <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"reticulate"</span>,<span class="st">"ggplot2"</span>,<span class="st">"dplyr"</span>,<span class="st">"magick"</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>installed <span class="ot">&lt;-</span> <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>to_install <span class="ot">&lt;-</span> <span class="fu">setdiff</span>(required, installed)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">length</span>(to_install) <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="fu">install.packages</span>(to_install)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="neuromorphism" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="neuromorphism"><span class="header-section-number">4.2</span> Neuromorphism</h2>
<p>The inspiration for artificial neural networks comes from attempts to capture, in a very simplified mathematical form, how biological neurons compute.</p>
<p>This idea is known as neuromorphism (neuromorphic computing):</p>
<ul>
<li><p>representing computation using abstractions loosely inspired by the brain, where “neurons” receive signals, combine them, and produce outputs,</p></li>
<li><p>and “synapses” determine how strongly inputs influence the neuron.</p></li>
</ul>
<p>The goal was never to perfectly copy biology, but to learn from its ability to detect patterns, integrate evidence, and generalize. The reasons are that in fact biological systems are extremely complex to be perfectly copied.</p>
</section>
<section id="what-is-inside-our-brain" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="what-is-inside-our-brain"><span class="header-section-number">4.3</span> What is inside our brain!</h2>
<p>Neurons are specialized cells designed to receive, integrate, and transmit information. Neurons were first described by Santiago Jamon y Cajal, the father of neurology.</p>
<p>Although there are many neuronal subtypes, a “canonical” neuron has the manjor structural components show in <a href="#fig-neuron" class="quarto-xref">Figure&nbsp;<span>4.1</span></a>.</p>
<div id="fig-neuron" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-neuron-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/neuron.png" id="fig-neuron" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-neuron-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.1
</figcaption>
</figure>
</div>
<p>1. Dendrites (the input tree).</p>
<p>Dendrites are branched projections responsible for receiving incoming signals. Neurons typically receive thousands of excitatory and inhibitory synaptic inputs across their dendrites and soma.</p>
<p>These inputs arrive as postsynaptic potentials:</p>
<ul>
<li><p>EPSPs (excitatory postsynaptic potentials), which depolarize the membrane</p></li>
<li><p>IPSPs (inhibitory postsynaptic potentials), which hyperpolarize the membrane</p></li>
</ul>
<p>The spatial and temporal arrangement of these inputs contributes to how the neuron integrates information.</p>
<p>2. Synapses (<strong>weighted connections)</strong></p>
<p>Each point of contact between neurons is a synapse, usually located on the dendritic tree. Synapses differ in their strength, some exert strong influence, others weak, and these strengths are not fixed.</p>
<p>This plasticity is the biological basis for <strong>learning and memory</strong>.</p>
<ol start="3" type="1">
<li>Soma (Cell Body), the integrator</li>
</ol>
<p>The soma receives and integrates all incoming EPSPs and IPSPs. This process is essentially a biophysical weighted sum of excitatory and inhibitory inputs, influenced by electrical properties of the membrane and dendritic morphology.</p>
<p>If the integrated membrane potential reaches a critical threshold, the neuron fires.</p>
<p>4. Axon Initial Segment, the decision point</p>
<p>At the base of the axon lies the Axon Initial Segment (AIS), where voltage-gated sodium channels are densely clustered. This is the site where the neuron decides whether to generate an action potential. If the integrated signal surpasses the threshold (typically around -55 mV ), a rapid depolarization occurs the spike.</p>
<p>5. Axon, the output cable</p>
<p>Once initiated, the action potential propagates along the axon, often insulated by myelin, which speeds conduction. When it reaches the axon terminals, it triggers release of neurotransmitters into the synaptic cleft, thereby influencing other neurons.</p>
<p>In summary, a biological neuron performs three essential computational steps:</p>
<p>1. Receives signals from thousands of synapses (inputs)</p>
<p>2. Weights and integrates them electrically in the soma</p>
<p>3. Triggers an action potential if the integrated input crosses a threshold</p>
<p>4. Propagates that output to other neurons</p>
<p>This biological computation is analog, non-linear, and highly dynamic due to plasticity.</p>
</section>
<section id="the-artificial-neuron-perceptron" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="the-artificial-neuron-perceptron"><span class="header-section-number">4.4</span> The artificial neuron (Perceptron)</h2>
<p>The artificial neuron, often called a perceptron, is a mathematical abstraction inspired by the computational behavior of biological neurons. While biological neurons operate through complex electrophysiological processes, the perceptron captures their essential functional properties using a simplified, interpretable formalism. This abstraction forms the foundational building block of modern neural networks.</p>
</section>
<section id="inputs-and-weights" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="inputs-and-weights"><span class="header-section-number">4.5</span> Inputs and Weights</h2>
<p>A perceptron receives a set of numerical inputs</p>
<p><span class="math display">\[
x_1, x_2, \ldots, x_p,
\]</span></p>
<p>analogous to the synaptic signals arriving at a biological neuron’s dendrites.</p>
<p>Each input is associated with a weight:</p>
<p><span class="math display">\[
w_1, w_2, \ldots, w_p .
\]</span></p>
<p>These weights represent the relative importance or influence of each input on the neuron’s final response. Conceptually, they play the role of synaptic strengtris-stronger weights exert greater impact, while</p>
</section>
<section id="weighted-sum-aggregation" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="weighted-sum-aggregation"><span class="header-section-number">4.6</span> Weighted Sum (Aggregation)</h2>
<p>The perceptron aggregates the incoming signals by computing a weighted linear combination:</p>
<p><span class="math display">\[
z=w_1 x_1+w_2 x_2+\cdots+w_p x_p+b=\mathbf{w}^{\top} \mathbf{x}+b .
\]</span></p>
<p>The term <span class="math inline">\(b\)</span> is the bias, which shifts the decision boundary and functions similarly to the membrane resting potential in biological neurons. This operation mirrors the integration of excitatory and inhibitory postsynaptic potentials that occurs within the soma of a biological neuron.</p>
</section>
<section id="nonlinear-activation-function" class="level2" data-number="4.7">
<h2 data-number="4.7" class="anchored" data-anchor-id="nonlinear-activation-function"><span class="header-section-number">4.7</span> Nonlinear Activation Function</h2>
<p>Once the weighted sum is computed, the perceptron applies an activation function, denoted <span class="math inline">\(\sigma(z)\)</span>, to determine its output.</p>
<p>This step introduces nonlinearity, allowing neural networks to model any continuous function on compact domains when sufficiently deep, as guaranteed by the Universal Approximation Theorem.</p>
<p>Common activation functions include:</p>
<ul>
<li>Step function (original perceptron):</li>
</ul>
<p><span class="math display">\[
\sigma(z)= \begin{cases}1, &amp; z \geq 0 \\ 0, &amp; z&lt;0\end{cases}
\]</span></p>
<ul>
<li>Logistic (sigmoid) function:</li>
</ul>
<p><span class="math display">\[
\sigma(z)=\frac{1}{1+e^{-z}}
\]</span></p>
<ul>
<li>ReLU (Rectified Linear Unit):</li>
</ul>
<p><span class="math display">\[
\sigma(z)=\max (0, z)
\]</span></p>
<p>In biological terms, this activation function plays a role analogous to the axon initial segment, which determines whether the integrated membrane potential is sufficient to trigger an action potential.</p>
</section>
<section id="output" class="level2" data-number="4.8">
<h2 data-number="4.8" class="anchored" data-anchor-id="output"><span class="header-section-number">4.8</span> Output</h2>
<p>The final output of the perceptron is:</p>
<p><span class="math display">\[
\hat{y}=\sigma\left(\mathbf{w}^{\top} \mathbf{x}+b\right),
\]</span></p>
<p>a scalar value that reflects the neuron’s “decision” based on the inputs. With a sigmoid output, for example, <span class="math inline">\(\hat{y}\)</span> represents the probability of a particular class, making the perceptron suitable for binary classification problems.</p>
</section>
<section id="learning-the-parameters" class="level2" data-number="4.9">
<h2 data-number="4.9" class="anchored" data-anchor-id="learning-the-parameters"><span class="header-section-number">4.9</span> Learning the Parameters</h2>
<p>The perceptron is not static: it learns its weights and bias from data. Learning occurs by adjusting <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(b\)</span> to reduce prediction error, typically through optimization algorithms such as gradient descent.</p>
<p>This process is the computational analogue of synaptic plasticity in biological neurons. For a training example with true label <span class="math inline">\(y\)</span> and predicted output <span class="math inline">\(\hat{y}\)</span>, the weights are updated to reduce the difference between <span class="math inline">\(y\)</span> and <span class="math inline">\(\hat{y}\)</span> :</p>
<p><span class="math display">\[
w_j \leftarrow w_j-\eta \frac{\partial \mathcal{L}}{\partial w_j},
\]</span></p>
</section>
<section id="geometric-interpretation" class="level2" data-number="4.10">
<h2 data-number="4.10" class="anchored" data-anchor-id="geometric-interpretation"><span class="header-section-number">4.10</span> Geometric Interpretation</h2>
<p>Geometrically, the perceptron learns a linear decision boundary. For a binary classification task with output <span class="math inline">\(\hat{y} \in\{0,1\}\)</span>, the equation</p>
<p><span class="math display">\[
\mathbf{w}^{\top} \mathbf{x}+b=0
\]</span></p>
<p>represents a hyperplane that separates the two classes in input space. The perceptron adjusts its parameters during training until this hyperplane best divides the data.</p>
</section>
<section id="visualisation-of-a-perceptron" class="level2" data-number="4.11">
<h2 data-number="4.11" class="anchored" data-anchor-id="visualisation-of-a-perceptron"><span class="header-section-number">4.11</span> Visualisation of a perceptron</h2>
<p>The following diagram shows an illustration of a perceptron.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR

    x1["x₁"] --&gt; SUM
    x2["x₂"] --&gt; SUM
    x3["x₃"] --&gt; SUM

    SUM["z = w₁x₁ + w₂x₂ + w₃x₃ + b"] --&gt; ACT["σ(z)"]
    ACT --&gt; y["ŷ"]

</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>Which approximates a human neuron like shown in <a href="#fig-neuron_analogy" class="quarto-xref">Figure&nbsp;<span>4.2</span></a>.</p>
<div id="fig-neuron_analogy" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-neuron_analogy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/neuron_analogy.png" id="fig-neuron_analogy" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-neuron_analogy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.2
</figcaption>
</figure>
</div>
</section>
<section id="the-perceptron-as-the-building-block-of-neural-networks" class="level2" data-number="4.12">
<h2 data-number="4.12" class="anchored" data-anchor-id="the-perceptron-as-the-building-block-of-neural-networks"><span class="header-section-number">4.12</span> The Perceptron as the Building Block of Neural Networks</h2>
<p>Although a single perceptron can only model linear relationships, multiple perceptrons combined in layers can approximate highly complex functions.</p>
<p>Thus, the perceptron serves as the elemental computational unit for:</p>
<ul>
<li><p>Multilayer Perceptrons (MLPs) such as the ones used for handwritten digit classification</p></li>
<li><p>Convolutional Neural Networks (CNNs), used in Chest X-ray classification</p></li>
<li><p>Recurrent Neural Networks (RNNs), used in Speech recognition</p></li>
<li><p>Transformers and deep architectures as the ones used in GPT models.</p></li>
</ul>
<p>Every deep learning model ultimately relies on combinations of these simple units performing weighted</p>
</section>
<section id="from-a-single-perceptron-to-a-full-neural-network-the-layered-architecture" class="level2" data-number="4.13">
<h2 data-number="4.13" class="anchored" data-anchor-id="from-a-single-perceptron-to-a-full-neural-network-the-layered-architecture"><span class="header-section-number">4.13</span> From a Single Perceptron to a Full Neural Network (The Layered Architecture)</h2>
<p>The perceptron represents the simplest computational unit of artificial neural networks: it receives multiple inputs, applies a weighted sum, adds a bias, and transforms the result through a nonlinear activation function. Although this single unit is mathematically elegant, its expressive power is limited. A lone perceptron can only model linear decision boundaries; no matter how cleverly it is trained, it cannot capture patterns that require curved surfaces, interacting features, hierarchical structure, or multistage reasoning. To overcome these limitations, neural networks combine many perceptrons into a layered architecture.</p>
<p>A neural network is constructed by arranging perceptrons into layers, where the output of one layer becomes the input to the next. The first layer operates directly on the raw features and is conventionally called the input layer, although it performs no computation itself. The next layer, composed of multiple perceptrons, is known as a hidden layer. Each perceptron in this layer computes its own nonlinear transformation of the input, producing intermediate representations of the data. The network may contain several such hidden layers, each learning increasingly abstract and complex features. The final layer produces the network’s output, such as a class probability or a continuous prediction. See the next Figure.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR

    %% ==== INPUT LAYER ====
    subgraph L1["Layer L₁ (Input Layer)"]
        x1(("x₁"))
        x2(("x₂"))
        x3(("x₃"))
        b1(("+1"))
    end

    %% ==== HIDDEN LAYER 1 ====
    subgraph L2["Layer L₂"]
        h11(("h₁¹"))
        h12(("h₂¹"))
        h13(("h₃¹"))
        b2(("+1"))
    end

    %% ==== HIDDEN LAYER 2 ====
    subgraph L3["Layer L₃"]
        h21(("h₁²"))
        h22(("h₂²"))
        b3(("+1"))
    end

    %% ==== OUTPUT LAYER ====
    subgraph L4["Layer L₄ (Output Layer)"]
        y1(("ŷ₁"))
        y2(("ŷ₂"))
    end

    %% Connections: L1 → L2
    x1 --&gt; h11
    x1 --&gt; h12
    x1 --&gt; h13
    x2 --&gt; h11
    x2 --&gt; h12
    x2 --&gt; h13
    x3 --&gt; h11
    x3 --&gt; h12
    x3 --&gt; h13
    b1 --&gt; h11
    b1 --&gt; h12
    b1 --&gt; h13

    %% Connections: L2 → L3
    h11 --&gt; h21
    h11 --&gt; h22
    h12 --&gt; h21
    h12 --&gt; h22
    h13 --&gt; h21
    h13 --&gt; h22
    b2 --&gt; h21
    b2 --&gt; h22

    %% Connections: L3 → L4
    h21 --&gt; y1
    h21 --&gt; y2
    h22 --&gt; y1
    h22 --&gt; y2
    b3 --&gt; y1
    b3 --&gt; y2

    %% ==== Remove background from subgraphs ====
    style L1 fill:#ffffff00,stroke:#00000000
    style L2 fill:#ffffff00,stroke:#00000000
    style L3 fill:#ffffff00,stroke:#00000000
    style L4 fill:#ffffff00,stroke:#00000000

    %% ==== Style nodes (white background, circular outlines) ====
    classDef neuron fill:#ffffff,stroke:#333,stroke-width:1px,color:#000;

    class x1,x2,x3,b1,h11,h12,h13,b2,h21,h22,b3,y1,y2 neuron;
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>This layered composition is essential for the power of neural networks. A single nonlinear transformation is insufficient to approximate rich patterns, but the composition of many nonlinear transformations can represent functions of extraordinary complexity. In the early layers, the network tends to learn simple or local dependencies among the inputs. As information flows forward through successive layers, these low-level computations are combined into higher-level abstractions. This hierarchical arrangement mirrors the structure of many natural phenomena and is one reason why deep learning performs so effectively in fields such as imaging, signal processing, and biomedical prediction.</p>
<p>Mathematically, each layer applies an affine transformation followed by a nonlinear activation. If the input vector is denoted by xxx, the first hidden layer computes an intermediate vector</p>
<p><span class="math display">\[h(1)=σ(W(1)x+b(1))h^{(1)} = \sigma(W^{(1)}x + b^{(1)})h(1)=σ(W(1)x+b(1))\]</span>. A second layer takes these intermediate values and produces</p>
<p><span class="math display">\[h(2)=σ(W(2)h(1)+b(2))h^{(2)} = \sigma(W^{(2)} h^{(1)} + b^{(2)})h(2)=σ(W(2)h(1)+b(2))\]</span></p>
<p>This process continues until the output layer generates the final prediction. Without the nonlinear activation <span class="math inline">\(σ(⋅)\sigma(\cdot)σ(⋅)\)</span>, the entire network would collapse into a single linear transformation, no matter how many layers were added. Nonlinearity therefore plays a structural role in allowing the network to represent functions that curve, twist, or vary in ways that linear models never could.</p>
<p>The significance of layered architectures is further supported by the Universal Approximation Theorem, which shows that even a network with only one hidden layer can approximate any continuous function on a compact domain, provided it has a sufficient number of hidden units and an appropriate nonlinear activation. In practice, however, deep networks with multiple layers tend to learn more efficiently, generalize better, and capture hierarchical relationships in a way that shallow networks cannot. Additional depth allows the network to distribute complexity across many layers, enabling compact representations and facilitating learning from high-dimensional data.</p>
<p>The transition from a single perceptron to a full neural network is therefore a transition from a simple linear classifier to a flexible, hierarchical system capable of modeling intricate structures in data. This layered design underlies all modern deep learning methods, including multilayer perceptrons for tabular radiomics data, convolutional networks for medical imaging, recurrent architectures for temporal sequences, and transformer-based models for multimodal biomedical analysis. Regardless of the sophistication of the final architecture, the fundamental building block remains the perceptron, replicated and arranged into layers that collectively enable powerful function approximation.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR

A["Raw Pixels&lt;br&gt;(Chest X-ray)"] --&gt; B["Feature Extraction&lt;br&gt;(edges, textures)"]

B --&gt; C["High-level Patterns&lt;br&gt;(lobar opacity, asymmetry)"]
C --&gt; D["Diagnosis Probability&lt;br&gt;(e.g., Pneumonia)"]

</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="deep-learning" class="level2" data-number="4.14">
<h2 data-number="4.14" class="anchored" data-anchor-id="deep-learning"><span class="header-section-number">4.14</span> Deep learning</h2>
<p>Deep networks extend the idea of a simple artificial neuron by stacking many such units across multiple layers, allowing the model to construct representations that become increasingly abstract as information flows forward. In shallow architectures, the network can only capture limited interactions, but depth introduces the ability to disentangle structure, recognize hierarchical relationships, and model patterns that vary at different spatial or temporal scales. This is why modern deep learning is often associated with “representation learning”: instead of hand-crafting features, the network discovers them through layer-by-layer transformations.</p>
<p>Within this broad family, several architectural classes have emerged, each tailored to a particular kind of structure in the data. Multilayer Perceptrons are the simplest expression of depth and are effective for tabular biomedical data, where each patient is represented by independent covariates. Convolutional Neural Networks introduce spatial invariance and local receptive fields, making them naturally suited for imaging, where patterns such as edges, textures, or radiological opacities repeat across space. Recurrent architectures, and later Transformers, were originally designed to handle temporal dynamics and long-range dependencies, but they have since expanded far beyond sequence data and now play central roles in multimodal clinical modeling.</p>
<p>What unifies all these architectures is the idea that depth allows the model to progressively refine its internal view of the data,from raw measurements to meaningful abstractions,and ultimately to a prediction. In the context of medical imaging, this capacity is especially important. Radiological patterns rarely exist in isolation; instead, they emerge from subtle combinations of shape, density, context, and anatomical variation. A deep network can first detect local primitives, such as edges or small opacity clusters, then aggregate them into regional descriptors like lobar consolidation or architectural distortion, and finally integrate these into global assessments that approximate expert diagnostic reasoning. This capacity to learn multi-scale, hierarchical structure is precisely what distinguishes deep learning from traditional machine-learning approaches that rely on predefined features.</p>
<p>As a result, deep architectures have become central to a wide range of imaging applications: classification of chest X-rays and CT scans, segmentation of tumors or anatomical structures, detection of subtle pathologies that may escape hand-engineered filters, and even synthesis or enhancement of images under limited acquisition conditions. Their strength lies not only in predictive performance, but also in their flexibility: the same underlying principles can be adapted to different modalities, resolutions, and clinical objectives. That is why deep learning has become the dominant paradigm in modern medical imaging,because it aligns naturally with how visual information is structured and how diagnostic interpretation unfolds.</p>
<p>This broader perspective sets the stage for the toy dataset we analyze next. By working with a simplified, computationally manageable subset of chest radiographs, we can see how even a small CNN begins to enact this hierarchical processing, transforming raw pixel values into the kinds of radiological abstractions that drive clinical decisions.</p>
</section>
<section id="from-tables-to-tensors" class="level2" data-number="4.15">
<h2 data-number="4.15" class="anchored" data-anchor-id="from-tables-to-tensors"><span class="header-section-number">4.15</span> From Tables to Tensors</h2>
<p>Before diving into images, it is worth pausing to understand what a tensor actually is, especially from the perspective of someone used to working with data frames and matrices in R. Deep learning frameworks operate almost exclusively on tensors, but this terminology can feel foreign when you first encounter it. The underlying idea, however, is not new: tensors simply extend the familiar notion of tables of numbers into additional dimensions. The jump from a data frame to a tensor is more of a gentle generalization than a conceptual leap.</p>
<p>Most students are already comfortable thinking about vectors and matrices. A vector is just an ordered list of numbers—R calls it a numeric vector—and a matrix is a rectangular table with rows and columns. Both of these objects are examples of tensors: a vector is a tensor of rank 1 and a matrix is a tensor of rank 2. Once this connection is made, the rest follows naturally. A tensor is simply an array that can have any number of dimensions. If you add one more dimension to a matrix, you get a rank-3 tensor; one more after that yields rank-4, and so on. Every time you add another axis, you gain the ability to represent structure that cannot be captured in a flat table—for example, stacks of images, sequences of individual patient records, or volumetric scans such as MRI or CT.</p>
<p>You can explore this directly in R. A vector behaves exactly like a one-dimensional tensor:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Vectors: rank 1</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>v <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>v</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1 2 3</code></pre>
</div>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(v)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3</code></pre>
</div>
</div>
<p>Likewise, a matrix is nothing more than a two-dimensional tensor:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Matrices: rank 2</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>M <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>, <span class="at">nrow =</span> <span class="dv">3</span>, <span class="at">ncol =</span> <span class="dv">3</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>M</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3]
[1,]    1    4    7
[2,]    2    5    8
[3,]    3    6    9</code></pre>
</div>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(M)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3 3</code></pre>
</div>
</div>
<p>And by simply adding a third dimension, R constructs a true tensor:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 3D arrays: rank 3 tensors</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>A <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">24</span>, <span class="at">dim =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>))</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>A</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>, , 1

     [,1] [,2] [,3] [,4]
[1,]    1    4    7   10
[2,]    2    5    8   11
[3,]    3    6    9   12

, , 2

     [,1] [,2] [,3] [,4]
[1,]   13   16   19   22
[2,]   14   17   20   23
[3,]   15   18   21   24</code></pre>
</div>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(A)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3 4 2</code></pre>
</div>
</div>
<p>This small example is enough to demystify the term. Tensors are not strange mathematical objects reserved for physicists or machine-learning specialists; they are the everyday data structures we already manipulate, extended into additional dimensions so that neural networks can operate on them efficiently.</p>
<p>A helpful way to build intuition for tensors is to start not from patient tables, but from the digital images themselves. An image, no matter the modality—X-ray, dermoscopy, retinal fundus, MRI slice—is fundamentally a collection of numbers arranged in a grid. In R, the simplest representation of a grayscale image is just a matrix, where each entry corresponds to a pixel intensity. When we load a picture into R and convert it to grayscale, we obtain a two-dimensional numerical array: height × width. This makes a grayscale image a rank-2 tensor, directly analogous to a matrix you are already familiar with.</p>
<p>For example, let’s simulate a tiny 5×4 “toy image” so the structure is easy to see:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># A tiny grayscale “image” (5 × 4 matrix)</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>img <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>, <span class="dv">40</span>,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  <span class="dv">15</span>, <span class="dv">25</span>, <span class="dv">35</span>, <span class="dv">45</span>,</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="dv">18</span>, <span class="dv">28</span>, <span class="dv">38</span>, <span class="dv">48</span>,</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  <span class="dv">22</span>, <span class="dv">32</span>, <span class="dv">42</span>, <span class="dv">52</span>,</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>  <span class="dv">25</span>, <span class="dv">35</span>, <span class="dv">45</span>, <span class="dv">55</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>), <span class="at">nrow =</span> <span class="dv">5</span>, <span class="at">ncol =</span> <span class="dv">4</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>img</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3] [,4]
[1,]   10   20   30   40
[2,]   15   25   35   45
[3,]   18   28   38   48
[4,]   22   32   42   52
[5,]   25   35   45   55</code></pre>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(img)   <span class="co"># height × width (rank 2)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5 4</code></pre>
</div>
</div>
<p>This is exactly the same as the numerical grid underlying a real chest X-ray—just vastly smaller. If we were working with a standard medical image of size 512×512, the structure would be identical, simply larger:</p>
<p><code>(512, 512)  → rank-2 tensor</code></p>
<p>When an image has color channels, such as RGB dermoscopy or retinal photos, we simply add one more dimension. R represents these as an array where the third axis stores the channels, producing a rank-3 tensor:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate a tiny RGB image (5 × 4 × 3)</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>rgb_img <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="fu">runif</span>(<span class="dv">5</span><span class="sc">*</span><span class="dv">4</span><span class="sc">*</span><span class="dv">3</span>), <span class="at">dim =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">3</span>))</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(rgb_img)   <span class="co"># height × width × channels (rank 3)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5 4 3</code></pre>
</div>
</div>
<p>Once you have this perspective, the next step for deep learning becomes natural. A neural network never trains on a single image at a time. Instead, images are fed in batches, which introduces yet another dimension. Stacking several images together produces a rank-4 tensor:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a batch of 3 small grayscale images (5 × 4 × 1)</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>batch <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="fu">rep</span>(img, <span class="dv">3</span>), <span class="at">dim =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(batch)   <span class="co"># height × width × channels × batch_size</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5 4 1 3</code></pre>
</div>
</div>
<p>This four-dimensional structure <code>(batch, height, width, channels)</code> is the exact format expected by TensorFlow and Keras when training a CNN.</p>
<p>The same logic extends effortlessly to 3D medical data. A CT or MRI scan is simply a stack of slices, so instead of a height × width matrix, you have depth × height × width. Add channels (such as multiple MRI sequences), and then add batching, and a full preprocessing pipeline produces tensors with shapes such as:</p>
<p><code>(depth, height, width, channels)</code> <code>(batch, depth, height, width, channels)</code></p>
<p>This is why the term “tensor” appears so often in deep learning. It provides a flexible way to represent data of any dimensionality—2D images, 3D volumes, time sequences, or entire batches of radiological studies. Neural networks take these tensors as input and transform them step by step into new tensors, each layer manipulating the shape to distill increasingly abstract information: edges become patterns, patterns become structures, structures become predictions.</p>
<p>Once you see tensors as nothing more than structured extensions of matrices, the workflow in image analysis becomes much easier to understand. A grayscale image is a matrix; a colored image is a matrix with channels; a CT scan is a stack of matrices; a batch of CT scans is a stack of stacks. Deep-learning frameworks operate on these tensors seamlessly, and with a bit of practice, the tensor shapes start feeling just as natural as ordinary tables in R.</p>
</section>
<section id="images-as-numerical-data-across-medical-modalities" class="level2" data-number="4.16">
<h2 data-number="4.16" class="anchored" data-anchor-id="images-as-numerical-data-across-medical-modalities"><span class="header-section-number">4.16</span> Images as Numerical Data Across Medical Modalities</h2>
<p>Although medical images appear to us as structured visual objects,chest radiographs, dermoscopy photos, histopathology slides, CT volumes, or MRI scans,deep learning systems treat all of them as nothing more than numerical arrays. Regardless of the imaging modality, every visual element ultimately resolves into grids of values representing either pixel intensities in two dimensions or voxel intensities in three dimensions. Neural networks do not “see” lungs, tumors, organs or textures; they process long, multidimensional tensors.</p>
<p>This unifying perspective is key because modern medical imaging spans a wide range of technologies. At the simplest end, we find classical two-dimensional modalities such as chest X-rays, ultrasound, dermoscopy, and retinal fundus photographs. These images are already familiar from everyday clinical practice: X-rays and ultrasound are usually stored as grayscale images with a single intensity channel, while dermoscopic and retinal images are acquired in colour using three channels. In all of these cases, once loaded into a deep learning library, an image becomes a rank-three tensor of shape (height, width, channels). A 512×512 chest radiograph is therefore nothing more than a 512×512×1 cube of numbers whose values range from dark to bright depending on the local tissue density.</p>
<p>Histopathology slides and fluorescence microscopy introduce additional complexity because they frequently contain multiple biochemical stains or multi-channel fluorescence signals. Even though the images can be extremely large,gigapixel whole-slide images are common,they still resolve into two-dimensional grids, often split into smaller patches for analysis. Each patch is represented numerically by arrays such as (224, 224, 3) for standard H&amp;E staining or (224, 224, 5) for multi-spectral microscopy. Deep learning models can thus treat microscopy and pathology in the same numerical framework as chest X-rays, differing only in the number of channels.</p>
<p>More advanced imaging modalities bring depth into the picture. CT, MRI, and PET scanners generate full three-dimensional volumes composed of stacked slices. A CT scan might contain sixty or more axial slices, each 512×512 pixels, producing a volumetric array with shape (depth, height, width). Multi-contrast MRI extends this further by including several sequences,T1, T2, FLAIR, DWI,each acting as a distinct channel. These become rank-four tensors, such as (depth, height, width, channels), which are analysed using 3D convolutional networks or hybrid architectures.</p>
<p>Certain modalities even add a temporal dimension, such as ultrasound cine loops or cardiac MRI sequences. These datasets are represented as tensors like (time, height, width, channels), effectively creating four- or five-dimensional numerical structures. Deep learning architectures built for video analysis,ConvLSTMs, temporal CNNs, or vision transformers,operate naturally on these higher-rank tensors.</p>
<p>The unifying thread across all modalities is that pixel or voxel values serve as the raw features. A neural network does not need explicit annotations describing edges, shapes, textures, or pathological patterns because convolutional filters extract these representations automatically. The data themselves, expressed as tensors, contain everything the model needs to discover hierarchical structure: from local gradients and edges, to regional consolidation patterns, to whole-organ abnormalities.</p>
<p>This is one reason why the MedMNIST project <span class="citation" data-cites="medmnistv2">Yang et al. (<a href="references.html#ref-medmnistv2" role="doc-biblioref">2023</a>)</span> is so pedagogically useful. MedMNIST provides a collection of small, preprocessed medical imaging datasets that represent many of these modalities,X-rays, retinal images, dermoscopy photographs, histopathology tiles, and even 3D volumetric scans,while standardizing them to uniform tensor shapes. ChestMNIST, for instance, offers downsampled chest radiographs as grayscale arrays. PathMNIST provides histopathology tiles as color images. OrganMNIST3D and NoduleMNIST3D present small volumetric CT-like cubes as rank-three tensors. Despite covering different anatomical regions, acquisition methods, and clinical purposes, the datasets are interchangeable at the tensor level, which makes them ideal for teaching.</p>
<p>Understanding that all medical images ultimately become tensors prepares us to move into model construction. When we load a chest X-ray for the pneumonia example in this chapter, we are simply converting pixel intensities into a tensor of shape (128, 128, 1). When we feed a batch of images to a convolutional neural network, we are stacking these tensors into a rank-four structure. As the image flows through the layers of the network, it is repeatedly transformed,convolved, pooled, flattened,into new tensors whose shapes reflect the abstraction level of the learned representations. This tensor-centric perspective allows us to navigate seamlessly from radiographs to MRI volumes and from single images to complex medical datasets.</p>
</section>
<section id="using-pretrained-architectures-for-medical-imaging" class="level2" data-number="4.17">
<h2 data-number="4.17" class="anchored" data-anchor-id="using-pretrained-architectures-for-medical-imaging"><span class="header-section-number">4.17</span> Using Pretrained Architectures for Medical Imaging</h2>
<p>In many practical situations, we do not need to design a convolutional neural network from scratch. The computer-vision community has spent more than a decade refining deep architectures capable of extracting hierarchical features from images—from edges and textures in early layers to objects and high-level semantics in deeper layers. These models, many of them trained on ImageNet, learn general-purpose visual representations that transfer surprisingly well to medical imaging tasks, even when the target domain differs substantially from the original training data.</p>
<p>When working with chest radiographs, histopathology tiles, dermoscopy photos or retinal fundus images, pretrained networks often dramatically improve performance relative to small, hand-crafted architectures—especially in small datasets where training a large network from scratch would lead to overfitting. A pretrained CNN already “knows” how to detect edges, textures, gradients, and shape patterns. Fine-tuning such a model therefore requires fewer labelled medical images, converges faster, and typically yields higher accuracy.</p>
<p>In this chapter, after introducing the basic building blocks of CNNs, we compare four models of increasing complexity:</p>
<p>TinyCNN – our handcrafted, minimal architecture operating directly on grey-scale tensors.</p>
<p>ResNet-18 – a classical backbone using residual skip connections <span class="citation" data-cites="he2016resnet">He et al. (<a href="references.html#ref-he2016resnet" role="doc-biblioref">2016</a>)</span>.</p>
<p>ResNet-50 – a deeper and more expressive residual network, also defined in <span class="citation" data-cites="he2016resnet">He et al. (<a href="references.html#ref-he2016resnet" role="doc-biblioref">2016</a>)</span>.</p>
<p>EfficientNet-B0 – a more modern architecture that systematically scales depth, width, and resolution <span class="citation" data-cites="tan2019efficientnet">Tan and Le (<a href="references.html#ref-tan2019efficientnet" role="doc-biblioref">2019</a>)</span>.</p>
<p>Although TinyCNN is intentionally simple, the remaining models reflect decades of architectural development and are widely used across radiology, dermatology, ophthalmology, and digital pathology. Their success in medical tasks demonstrates how transferable large-scale visual representations can be.</p>
<p>To illustrate this, we evaluate each architecture on PneumoniaMNIST, a lightweight version of the pediatric chest X-ray dataset originally curated by Paul Mooney <span class="citation" data-cites="mooney2018chestxray">Mooney (<a href="references.html#ref-mooney2018chestxray" role="doc-biblioref">2018</a>)</span> and standardized in the MedMNIST benchmark suite <span class="citation" data-cites="yang2021medmnist">Yang et al. (<a href="references.html#ref-yang2021medmnist" role="doc-biblioref">2021</a>)</span>; <span class="citation" data-cites="medmnistv2">Yang et al. (<a href="references.html#ref-medmnistv2" role="doc-biblioref">2023</a>)</span>. For ResNet and EfficientNet, we convert the grayscale images to RGB to match the pretrained input format, replace the final classification layer with a single output neuron, and compute accuracy and confusion matrices.</p>
</section>
<section id="toy-data-for-the-chapter" class="level2" data-number="4.18">
<h2 data-number="4.18" class="anchored" data-anchor-id="toy-data-for-the-chapter"><span class="header-section-number">4.18</span> Toy Data for the chapter</h2>
<p>The first datasert we will use this chapter we will is a curated subset of the <em>Chest X-Ray Pneumonia</em> dataset, originally released on Kaggle by <span class="citation" data-cites="mooney2018chestxray">Mooney (<a href="references.html#ref-mooney2018chestxray" role="doc-biblioref">2018</a>)</span>. The full dataset contains more than 5,000 radiographs with resolutions up to 1024×1024 pixels, distributed across <em>normal</em> and <em>pneumonia</em> classes. While this dataset is ideal for clinical–motivated deep learning, its size makes it challenging for users running models on standard laptops.</p>
<p>To address this, we prepared a <strong>toy version of the dataset</strong>, containing a balanced and substantially smaller sample of images (250 per class). The toy dataset keeps two copies of each selected image:</p>
<ul>
<li><p><strong>Original image:</strong> stored exactly as released (high resolution, variable size).</p></li>
<li><p><strong>Compressed image:</strong> resized to a fixed resolution (e.g., 512×512), suitable for CNN training on typical laptops.</p></li>
</ul>
<section id="image-compression" class="level3" data-number="4.18.1">
<h3 data-number="4.18.1" class="anchored" data-anchor-id="image-compression"><span class="header-section-number">4.18.1</span> Image compression</h3>
<p>Raw medical images particularly chest X-rays, CT slices, and MRI scans are often large (1–5 MB per image). Processing them directly can make training:<br>
</p>
<ul>
<li><p><strong>slow</strong>, due to large tensor operations,</p></li>
<li><p><strong>memory-intensive</strong>, particularly on laptops without GPUs,</p></li>
<li><p><strong>computationally expensive</strong>, since convolution scales with image size.</p></li>
</ul>
<p>A 1024×1024 radiograph contains <strong>four times more pixels</strong> than a 512×512 version and <strong>sixteen times more</strong> than 256×256. Convolutional filters must process each pixel, so reducing resolution leads to substantial gains in training speed with minimal loss of diagnostic signal for tasks like pneumonia detection. For these reasons, the toy dataset includes paired images: the untouched originals and the pre-processed, standardized 512×512 versions. Students can explore the visual differences and appreciate that, although details are reduced, the core diagnostic structures (e.g., opacities, texture patterns) remain visible.</p>
<p>The following code allow us to read the data and plot some images to have a glimpse of what the data look like</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magick)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(grid)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tools)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Paths</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>toy_base    <span class="ot">&lt;-</span> <span class="st">"data/chest_toy_250"</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>orig_dir    <span class="ot">&lt;-</span> <span class="fu">file.path</span>(toy_base, <span class="st">"original"</span>)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>resized_dir <span class="ot">&lt;-</span> <span class="fu">file.path</span>(toy_base, <span class="st">"resized"</span>)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper: extract class from filename</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="co"># ORIGINAL files look like:  NORMAL_xxx.jpeg  or  PNEUMONIA_xxx.jpeg</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>get_class <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">toupper</span>(<span class="fu">strsplit</span>(<span class="fu">basename</span>(x), <span class="st">"_"</span>)[[<span class="dv">1</span>]][<span class="dv">1</span>])</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a><span class="co"># List and classify ORIGINAL images</span></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>orig_files <span class="ot">&lt;-</span> <span class="fu">list.files</span>(</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>  orig_dir, <span class="at">full.names =</span> <span class="cn">TRUE</span>,</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>  <span class="at">pattern =</span> <span class="st">"</span><span class="sc">\\</span><span class="st">.(jpg|jpeg|png)$"</span></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>orig_classes <span class="ot">&lt;-</span> <span class="fu">sapply</span>(orig_files, get_class)</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample exactly 2 NORMAL and 2 PNEUMONIA</span></span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>orig_norm <span class="ot">&lt;-</span> orig_files[orig_classes <span class="sc">==</span> <span class="st">"NORMAL"</span>]</span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a>orig_pneu <span class="ot">&lt;-</span> orig_files[orig_classes <span class="sc">==</span> <span class="st">"PNEUMONIA"</span>]</span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>orig_selected <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">sample</span>(orig_norm, <span class="dv">2</span>), <span class="fu">sample</span>(orig_pneu, <span class="dv">2</span>))</span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Match each selected ORIGINAL to its resized version</span></span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Resized names look like: NORMAL_xxx_resized.png</span></span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a>res_selected <span class="ot">&lt;-</span> <span class="fu">sapply</span>(orig_selected, <span class="cf">function</span>(f) {</span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a>  stem <span class="ot">&lt;-</span> <span class="fu">file_path_sans_ext</span>(<span class="fu">basename</span>(f))</span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a>  <span class="fu">file.path</span>(resized_dir, <span class="fu">paste0</span>(stem, <span class="st">"_resized.png"</span>))</span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Load images</span></span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb22-53"><a href="#cb22-53" aria-hidden="true" tabindex="-1"></a>orig_imgs <span class="ot">&lt;-</span> <span class="fu">lapply</span>(orig_selected, image_read)</span>
<span id="cb22-54"><a href="#cb22-54" aria-hidden="true" tabindex="-1"></a>res_imgs  <span class="ot">&lt;-</span> <span class="fu">lapply</span>(res_selected, image_read)</span>
<span id="cb22-55"><a href="#cb22-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-56"><a href="#cb22-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Build titles based on class</span></span>
<span id="cb22-57"><a href="#cb22-57" aria-hidden="true" tabindex="-1"></a>titles_orig <span class="ot">&lt;-</span> <span class="fu">sapply</span>(orig_selected, <span class="cf">function</span>(f) <span class="fu">paste0</span>(<span class="fu">get_class</span>(f), <span class="st">" (Original)"</span>))</span>
<span id="cb22-58"><a href="#cb22-58" aria-hidden="true" tabindex="-1"></a>titles_res  <span class="ot">&lt;-</span> <span class="fu">sapply</span>(orig_selected, <span class="cf">function</span>(f) <span class="fu">paste0</span>(<span class="fu">get_class</span>(f), <span class="st">" (Resized 512×512)"</span>))</span>
<span id="cb22-59"><a href="#cb22-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-60"><a href="#cb22-60" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb22-61"><a href="#cb22-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to ggplot grobs</span></span>
<span id="cb22-62"><a href="#cb22-62" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb22-63"><a href="#cb22-63" aria-hidden="true" tabindex="-1"></a>make_plot <span class="ot">&lt;-</span> <span class="cf">function</span>(img, title) {</span>
<span id="cb22-64"><a href="#cb22-64" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb22-65"><a href="#cb22-65" aria-hidden="true" tabindex="-1"></a>    <span class="fu">annotation_custom</span>(<span class="fu">rasterGrob</span>(img)) <span class="sc">+</span></span>
<span id="cb22-66"><a href="#cb22-66" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(title) <span class="sc">+</span></span>
<span id="cb22-67"><a href="#cb22-67" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_void</span>()</span>
<span id="cb22-68"><a href="#cb22-68" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb22-69"><a href="#cb22-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-70"><a href="#cb22-70" aria-hidden="true" tabindex="-1"></a>plot_list <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb22-71"><a href="#cb22-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-72"><a href="#cb22-72" aria-hidden="true" tabindex="-1"></a><span class="co"># First row: originals</span></span>
<span id="cb22-73"><a href="#cb22-73" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_along</span>(orig_imgs)) {</span>
<span id="cb22-74"><a href="#cb22-74" aria-hidden="true" tabindex="-1"></a>  plot_list[[<span class="fu">length</span>(plot_list)<span class="sc">+</span><span class="dv">1</span>]] <span class="ot">&lt;-</span> <span class="fu">make_plot</span>(orig_imgs[[i]], titles_orig[i])</span>
<span id="cb22-75"><a href="#cb22-75" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb22-76"><a href="#cb22-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-77"><a href="#cb22-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Second row: resized</span></span>
<span id="cb22-78"><a href="#cb22-78" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_along</span>(res_imgs)) {</span>
<span id="cb22-79"><a href="#cb22-79" aria-hidden="true" tabindex="-1"></a>  plot_list[[<span class="fu">length</span>(plot_list)<span class="sc">+</span><span class="dv">1</span>]] <span class="ot">&lt;-</span> <span class="fu">make_plot</span>(res_imgs[[i]], titles_res[i])</span>
<span id="cb22-80"><a href="#cb22-80" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb22-81"><a href="#cb22-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-82"><a href="#cb22-82" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb22-83"><a href="#cb22-83" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot: 2 rows × 4 columns</span></span>
<span id="cb22-84"><a href="#cb22-84" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb22-85"><a href="#cb22-85" aria-hidden="true" tabindex="-1"></a>p<span class="ot">=</span><span class="fu">grid.arrange</span>(<span class="at">grobs =</span> plot_list, <span class="at">ncol =</span> <span class="dv">4</span>)</span>
<span id="cb22-86"><a href="#cb22-86" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsave</span>(<span class="st">"figures/toy_chest_comparison.png"</span>,</span>
<span id="cb22-87"><a href="#cb22-87" aria-hidden="true" tabindex="-1"></a>       <span class="at">plot =</span> p,</span>
<span id="cb22-88"><a href="#cb22-88" aria-hidden="true" tabindex="-1"></a>       <span class="at">width =</span> <span class="dv">12</span>, <span class="at">height =</span> <span class="dv">7</span>,</span>
<span id="cb22-89"><a href="#cb22-89" aria-hidden="true" tabindex="-1"></a>       <span class="at">dpi =</span> <span class="dv">300</span>,</span>
<span id="cb22-90"><a href="#cb22-90" aria-hidden="true" tabindex="-1"></a>       <span class="at">bg =</span> <span class="st">"white"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br>
<br>
The code shown above selects a balanced subset of chest radiographs and prepares two parallel versions of each image. The first retains the original resolution of the dataset, while the second produces a standardized 512×512 pixel version. This allows us to examine the effect of image compression while keeping the resized images computationally manageable for downstream modeling. The script identifies matching pairs of images for both NORMAL and PNEUMONIA categories loads them with the <em>magick</em> library, and arranges them in a grid where the original images appear in the first row and their compressed counterparts appear directly beneath them.</p>
<p>Because the resized images preserve lung structure and overall radiological patterns, we can directly assess the trade-off between image fidelity and computational efficiency. Even after downsampling, the essential visual features remain recognizable, which is a central motivation for preprocessing high-resolution medical images before training predictive models. We will no understand this with <a href="#fig-pneumonia_comprees" class="quarto-xref">Figure&nbsp;<span>4.3</span></a>.</p>
<div id="fig-pneumonia_comprees" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pneumonia_comprees-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/toy_chest_comparison.png" id="fig-pneumonia_comprees" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-pneumonia_comprees-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.3
</figcaption>
</figure>
</div>
</section>
<section id="what-the-figures-show" class="level3" data-number="4.18.2">
<h3 data-number="4.18.2" class="anchored" data-anchor-id="what-the-figures-show"><span class="header-section-number">4.18.2</span> What the figures show</h3>
<p>When examining <a href="#fig-pneumonia_comprees" class="quarto-xref">Figure&nbsp;<span>4.3</span></a>, we can see that normal pediatric chest radiographs have relatively uniform, darker lung fields, reflecting the low density of air-filled alveoli. The pulmonary vessels appear as fine branching structures, the diaphragmatic borders remain sharp, and the cardiac silhouette stands out clearly against the surrounding aerated lung. There is a sense of symmetry and well-defined anatomical boundaries.</p>
<p>In contrast, the pneumonia images display areas of increased opacity regions that appear whiter or denser corresponding to alveoli filled with inflammatory material rather than air. We can see patchy or segmental consolidations that disrupt the uniform darkness of the lungs, obscure normal vascular markings, or blur the heart borders. These opacities may also distort the expected symmetry between the left and right lung fields.</p>
<p>When comparing the original and resized images, we can see that the downscaled versions still retain the broad radiographic patterns that distinguish normal lungs from those affected by pneumonia. The fine-grained textures are somewhat softened, but the structural changes associated with consolidation remain visible. This illustrates why compressed images often remain adequate for classification tasks: the key diagnostic features are large-scale density patterns, which are preserved even after substantial reduction in image resolution. The paired display therefore highlights both the radiological differences between normal and pneumonia cases and the practical effect of image compression within a machine-learning workflow.</p>
</section>
</section>
<section id="fitting-a-naive-neural-network-for-prediction-of-pneumonia" class="level2" data-number="4.19">
<h2 data-number="4.19" class="anchored" data-anchor-id="fitting-a-naive-neural-network-for-prediction-of-pneumonia"><span class="header-section-number">4.19</span> Fitting a naive neural network for prediction of pneumonia</h2>
<p>To demonstrate the mechanics of training a convolutional neural network (CNN), we now walk through a complete example using a toy subset of chest X-ray images. The objective is deliberately modest: the network is not intended to achieve clinical performance, but rather to illustrate the full computational workflow that takes us from pixel data to probability predictions.</p>
<p>At a high level, the modelling pipeline follows four steps: loading and labelling the images, converting each image into a numerical tensor, defining a minimal CNN architecture, and training the network using gradient-based optimisation. Even a very small model reveals the essential building blocks of deep learning for image analysis.</p>
<p>Data preparation All images in the pre-processed folder are listed and labelled according to their filenames, which contain either NORMAL or PNEUMONIA. The dataset is then shuffled and partitioned into training <span class="math inline">\((70 \%)\)</span>, validation <span class="math inline">\((15 \%)\)</span>, and test <span class="math inline">\((15 \%)\)</span>. Because neural networks operate on numerical arrays, each image is loaded from disk, converted to grayscale, resized to <span class="math inline">\(128 \times 128\)</span> pixels, and normalised to the <span class="math inline">\([0,1]\)</span> range. The resulting tensor has the shape</p>
<p><span class="math display">\[
(128,128,1),
\]</span></p>
<p>corresponding to height, width, and channel count. These arrays form the inputs for Keras/TensorFlow.</p>
<p>Model architecture The CNN itself is intentionally small. It begins with an explicit input layer</p>
<p><span class="math display">\[
X \in \mathbb{R}^{128 \times 128 \times 1},
\]</span></p>
<p>followed by two convolution-ReLU-pooling blocks. Convolutional layers learn spatial filters that respond to edges, textures, and coarse structures in the X-ray images, while max-pooling progressively reduces spatial resolution:</p>
<p><span class="math display">\[
\text { image → conv } \text { → ReLU } \text { → pool. }
\]</span></p>
<p>After two rounds of convolution and pooling, the resulting activation maps are flattened and passed into dense layers:</p>
<p><span class="math display">\[
\text { Flatten → Dense(32) } \rightarrow \text { Dense(1). }
\]</span></p>
<p>The final layer uses a sigmoid activation, producing an estimated probability</p>
<p><span class="math display">\[
\hat{p}=P(\text { pneumonia } \mid X) .
\]</span></p>
<p>Although compact, this network captures all core components of modern CNNs: convolution, nonlinearity, down-sampling, and fully connected classification.</p>
<p>Training the network</p>
<p>The model is trained using the Adam optimiser with a learning rate of <span class="math inline">\(5 \times 10^{-4}\)</span>. We use binary crossentropy as the loss function:</p>
<p><span class="math display">\[
\mathcal{L}=-[y \log (\hat{p})+(1-y) \log (1-\hat{p})] .
\]</span></p>
<p>During training, the network repeatedly performs forward passes to compute predictions, evaluates the loss, and uses backpropagation to update its filter weights. Validation accuracy and loss are monitored after each epoch to gauge generalisation.</p>
<p>Even with this very small architecture and a tiny dataset, the training loop performs thousands of tensor operations. Students should be aware that deep learning workloads scale quickly and can become computationally heavy without GPU acceleration.</p>
<p>Model performance After ten epochs, the model reaches good performance on both the training and test sets:</p>
<ul>
<li>Training accuracy: 0.924</li>
<li>Training loss: 0.219</li>
<li>Test accuracy: 0.908</li>
<li>Test loss: 0.226</li>
</ul>
<p>The confusion matrix on the held-out test set is:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>truth &nbsp;predicted</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0 (NORMAL)</td>
<td>59</td>
<td>10</td>
</tr>
<tr class="even">
<td>1 (PNEUMONIA)</td>
<td>3</td>
<td>69</td>
</tr>
</tbody>
</table>
<p>The model detects pneumonia well (few false negatives), while still misclassifying a moderate number of NORMAL images as pneumonia (false positives). This behaviour is typical for small CNNs trained on imbalanced or limited datasets, and it highlights an essential lesson: even when accuracy seems high, practical clinical reliability requires much more data, better preprocessing, stronger architectures, and rigorous evaluation.</p>
<p>Saving the model</p>
<p>Once training is complete, the model and all diagnostics (training history, predictions, metrics) are saved to disk. Saving models is a crucial habit in any deep-learning workflow, as training may take considerable time and should not be repeated unnecessarily. Stored models can be reloaded instantly for future experiments, teaching demonstrations, or interpretability analyses.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">use_condaenv</span>(<span class="st">"r-keras"</span>, <span class="at">required =</span> <span class="cn">TRUE</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magick)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>img_dir <span class="ot">&lt;-</span> <span class="st">"data/chest_toy_250/resized"</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>files <span class="ot">&lt;-</span> <span class="fu">list.files</span>(img_dir, <span class="at">full.names =</span> <span class="cn">TRUE</span>, <span class="at">pattern =</span> <span class="st">"png$"</span>)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>get_label <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">grepl</span>(<span class="st">"PNEUMONIA"</span>, <span class="fu">basename</span>(x), <span class="at">ignore.case =</span> <span class="cn">TRUE</span>)) <span class="dv">1</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">file =</span> files,</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">label =</span> <span class="fu">sapply</span>(files, get_label)</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> df[<span class="fu">sample</span>(<span class="fu">nrow</span>(df)), ]</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(df)</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>train_df <span class="ot">&lt;-</span> df[<span class="dv">1</span><span class="sc">:</span><span class="fu">floor</span>(<span class="fl">0.7</span><span class="sc">*</span>n), ]</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>val_df   <span class="ot">&lt;-</span> df[(<span class="fu">floor</span>(<span class="fl">0.7</span><span class="sc">*</span>n)<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span><span class="fu">floor</span>(<span class="fl">0.85</span><span class="sc">*</span>n), ]</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>test_df  <span class="ot">&lt;-</span> df[(<span class="fu">floor</span>(<span class="fl">0.85</span><span class="sc">*</span>n)<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>n, ]</span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>load_array <span class="ot">&lt;-</span> <span class="cf">function</span>(path) {</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>  img <span class="ot">&lt;-</span> <span class="fu">image_read</span>(path)</span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>  img <span class="ot">&lt;-</span> <span class="fu">image_convert</span>(img, <span class="at">colorspace =</span> <span class="st">"gray"</span>)</span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>  img <span class="ot">&lt;-</span> <span class="fu">image_resize</span>(img, <span class="st">"128x128!"</span>)</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>  arr <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(img[[<span class="dv">1</span>]]) <span class="sc">/</span> <span class="dv">255</span></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">array</span>(arr, <span class="at">dim =</span> <span class="fu">c</span>(<span class="dv">128</span>, <span class="dv">128</span>, <span class="dv">1</span>))</span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>x_train <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim =</span> <span class="fu">c</span>(<span class="fu">nrow</span>(train_df), <span class="dv">128</span>, <span class="dv">128</span>, <span class="dv">1</span>))</span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>x_val   <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim =</span> <span class="fu">c</span>(<span class="fu">nrow</span>(val_df),   <span class="dv">128</span>, <span class="dv">128</span>, <span class="dv">1</span>))</span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>x_test  <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>, <span class="at">dim =</span> <span class="fu">c</span>(<span class="fu">nrow</span>(test_df),  <span class="dv">128</span>, <span class="dv">128</span>, <span class="dv">1</span>))</span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(<span class="fu">nrow</span>(train_df))) x_train[i,,,] <span class="ot">&lt;-</span> <span class="fu">load_array</span>(train_df<span class="sc">$</span>file[i])</span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(<span class="fu">nrow</span>(val_df)))   x_val[i,,,]   <span class="ot">&lt;-</span> <span class="fu">load_array</span>(val_df<span class="sc">$</span>file[i])</span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(<span class="fu">nrow</span>(test_df)))  x_test[i,,,]  <span class="ot">&lt;-</span> <span class="fu">load_array</span>(test_df<span class="sc">$</span>file[i])</span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> train_df<span class="sc">$</span>label</span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a>y_val   <span class="ot">&lt;-</span> val_df<span class="sc">$</span>label</span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>y_test  <span class="ot">&lt;-</span> test_df<span class="sc">$</span>label</span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>build_model <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>  inputs <span class="ot">&lt;-</span> <span class="fu">layer_input</span>(<span class="at">shape =</span> <span class="fu">c</span>(<span class="dv">128</span>L,<span class="dv">128</span>L,<span class="dv">1</span>L))</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> inputs <span class="sc">%&gt;%</span></span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">8</span>, <span class="at">kernel_size =</span> <span class="dv">3</span>, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">padding =</span> <span class="st">"same"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">16</span>, <span class="at">kernel_size =</span> <span class="dv">3</span>, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">padding =</span> <span class="st">"same"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">32</span>, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">1</span>, <span class="at">activation =</span> <span class="st">"sigmoid"</span>)</span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a>  model <span class="ot">&lt;-</span> <span class="fu">keras_model</span>(<span class="at">inputs =</span> inputs, <span class="at">outputs =</span> x)</span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="fu">optimizer_adam</span>(<span class="at">learning_rate =</span> <span class="fl">0.0005</span>),</span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> <span class="st">"binary_crossentropy"</span>,</span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a>    <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">"accuracy"</span>)</span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a>  model</span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">build_model</span>()</span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a>history <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span></span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a>    x_train, y_train,</span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_data =</span> <span class="fu">list</span>(x_val, y_val),</span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> <span class="dv">10</span>,</span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size =</span> <span class="dv">8</span></span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a>metrics_train <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> <span class="fu">evaluate</span>(x_train, y_train)</span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(metrics_train)</span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-82"><a href="#cb23-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-83"><a href="#cb23-83" aria-hidden="true" tabindex="-1"></a>metrics_test <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> <span class="fu">evaluate</span>(x_test, y_test)</span>
<span id="cb23-84"><a href="#cb23-84" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(metrics_test)</span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a>pred_test <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> <span class="fu">predict</span>(x_test)</span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a>pred_class <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(pred_test <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb23-88"><a href="#cb23-88" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">table</span>(<span class="at">truth =</span> y_test, <span class="at">predicted =</span> pred_class))</span>
<span id="cb23-89"><a href="#cb23-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-90"><a href="#cb23-90" aria-hidden="true" tabindex="-1"></a><span class="fu">saveRDS</span>(history, <span class="st">"cnn_history.rds"</span>)</span>
<span id="cb23-91"><a href="#cb23-91" aria-hidden="true" tabindex="-1"></a><span class="fu">saveRDS</span>(metrics_test, <span class="st">"cnn_metrics_test.rds"</span>)</span>
<span id="cb23-92"><a href="#cb23-92" aria-hidden="true" tabindex="-1"></a><span class="fu">saveRDS</span>(pred_test, <span class="st">"cnn_predictions_test.rds"</span>)</span>
<span id="cb23-93"><a href="#cb23-93" aria-hidden="true" tabindex="-1"></a><span class="fu">saveRDS</span>(metrics_train, <span class="st">"cnn_metrics_train.rds"</span>)</span>
<span id="cb23-94"><a href="#cb23-94" aria-hidden="true" tabindex="-1"></a>model<span class="sc">$</span><span class="fu">save</span>(<span class="st">"cnn_pneumonia.keras"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="by-with-a-little-from-python" class="level3" data-number="4.19.1">
<h3 data-number="4.19.1" class="anchored" data-anchor-id="by-with-a-little-from-python"><span class="header-section-number">4.19.1</span> By with a little from Python</h3>
<p>Alongside the R-based workflow, it is useful to illustrate how the same modeling pipeline can be implemented in Python using PyTorch. The script below trains several neural-network architectures on the PneumoniaMNIST dataset and evaluates their performance under a unified interface. While the code is not executed inside the textbook, it provides a complete and reproducible reference for readers who want to explore the models in Python.</p>
<p>The workflow begins by loading the dataset through MedMNIST, a lightweight benchmark collection for medical image classification. Images are provided as 28×28 grayscale tensors with binary labels (normal vs pneumonia). Because different neural-network architectures expect different input shapes, the script includes dataset wrappers that optionally convert grayscale images to RGB and resize them when required (e.g., for ResNet-50 and EfficientNet-B0).</p>
<p>Model specification relies on PyTorch and torchvision. Four architectures are included:</p>
<ul>
<li><p>TinyCNN – a simple two-layer convolutional network designed to illustrate baseline performance.</p></li>
<li><p>ResNet-18 – a residual architecture that uses skip connections to stabilise training in deeper models.</p></li>
<li><p>ResNet-50 – a larger residual network with bottleneck blocks and substantially more capacity.</p></li>
<li><p>EfficientNet-B0 – a modern architecture that applies compound scaling to depth, width, and resolution.</p></li>
</ul>
<p>Each model is adapted to binary classification by replacing the final fully-connected layer with a single output neuron. All models are trained with binary cross-entropy (via BCEWithLogitsLoss) and optimised with Adam. The training loops share the same structure: enable training mode, iterate through mini-batches, compute forward and backward passes, and update the parameters. After training, model weights are saved to disk to ensure that the evaluation script can reload them later without retraining.</p>
<p>Evaluation uses a common helper function that computes predictions, applies a sigmoid threshold at 0.5, and returns both accuracy and a confusion matrix. These metrics allow a like-for-like comparison across architectures. A small utility function based on matplotlib and seaborn visualises the confusion matrices.</p>
<p>Structurally, the script demonstrates a full supervised-learning pipeline:</p>
<ul>
<li><p>dataset loading and preprocessing</p></li>
<li><p>model definition and customisation</p></li>
<li><p>training using stochastic gradient descent methods</p></li>
<li><p>inference and metric computation</p></li>
<li><p>persistence of trained weights</p></li>
<li><p>visualisation of performance diagnostics</p></li>
</ul>
<p>The Python implementation complements the R material by showing how deep-learning models are typically organised in PyTorch workflows, how pretrained architectures can be fine-tuned for medical imaging tasks, and how performance varies across models of different capacities.</p>
</section>
<section id="a-short-note-on-pytorch" class="level3" data-number="4.19.2">
<h3 data-number="4.19.2" class="anchored" data-anchor-id="a-short-note-on-pytorch"><span class="header-section-number">4.19.2</span> A short note on PyTorch</h3>
<p>Throughout the examples in this chapter we rely on PyTorch, one of the most widely used open-source frameworks for deep learning. PyTorch is built around a simple idea: treat tensors as first-class numerical objects and allow models to be expressed as ordinary Python code. This makes experimentation fast and transparent—layers, losses, and optimizers behave like regular Python objects that can be inspected, modified, or replaced.</p>
<p>PyTorch offers:</p>
<p>Dynamic computation graphs (“define-by-run”), which evaluate operations as they are executed. This style is particularly intuitive when building or debugging neural networks.</p>
<p>A rich library of modules for convolutional layers, normalization, pooling, activation functions, and loss functions. Most architectures used in modern computer vision can be reproduced with a handful of lines.</p>
<p>GPU acceleration through CUDA integration, allowing models to scale from small educational datasets (like PneumoniaMNIST) to clinical-grade imaging repositories.</p>
<p>TorchVision, a companion package providing pretrained models (ResNet, EfficientNet, DenseNet, ViT), image transformations, and standardized evaluation pipelines.</p>
<p>DataLoader abstractions, which handle batching, shuffling, and parallel data fetching. For image-based pipelines this is essential: models rarely process images one at a time, and appropriately designed loaders ensure smooth throughput.</p>
<p>In the comparison code above, PyTorch orchestrates every step: loading and batching images, defining lightweight (TinyCNN) and heavyweight (ResNet, EfficientNet) networks, applying loss functions, optimizing parameters, and finally evaluating predictive performance. Even when the architecture becomes complex, the overall workflow remains the same: tensors in, tensors out, gradients computed automatically, and model weights updated by optimizers.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms, models</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, Dataset</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> medmnist</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> medmnist <span class="im">import</span> INFO</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------------------</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Load PneumoniaMNIST (binary labels)</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------------------</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>data_flag <span class="op">=</span> <span class="st">"pneumoniamnist"</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>info <span class="op">=</span> INFO[data_flag]</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>DataClass <span class="op">=</span> <span class="bu">getattr</span>(medmnist, info[<span class="st">'python_class'</span>])</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor()</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> DataClass(split<span class="op">=</span><span class="st">"train"</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>test_ds  <span class="op">=</span> DataClass(split<span class="op">=</span><span class="st">"test"</span>,  download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------------------</span></span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Safe label extraction (no deprecation warnings)</span></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------------------</span></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_scalar(lbl):</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># lbl may be array([0]) or array([1])</span></span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This safely extracts the single value no matter the dtype</span></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">float</span>(lbl.squeeze().item())</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>train_x <span class="op">=</span> torch.stack([img <span class="cf">for</span> img, lbl <span class="kw">in</span> train_ds])</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>train_y <span class="op">=</span> torch.tensor([extract_scalar(lbl) <span class="cf">for</span> _, lbl <span class="kw">in</span> train_ds])</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>test_x <span class="op">=</span> torch.stack([img <span class="cf">for</span> img, lbl <span class="kw">in</span> test_ds])</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>test_y <span class="op">=</span> torch.tensor([extract_scalar(lbl) <span class="cf">for</span> _, lbl <span class="kw">in</span> test_ds])</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PneumoniaBinary(Dataset):</span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X, y):</span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X <span class="op">=</span> X</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> y</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.X)</span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.X[idx], <span class="va">self</span>.y[idx]</span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(PneumoniaBinary(train_x, train_y), batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a>test_loader  <span class="op">=</span> DataLoader(PneumoniaBinary(test_x, test_y), batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms, models</span>
<span id="cb24-59"><a href="#cb24-59" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb24-60"><a href="#cb24-60" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb24-61"><a href="#cb24-61" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> medmnist</span>
<span id="cb24-62"><a href="#cb24-62" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> medmnist <span class="im">import</span> INFO</span>
<span id="cb24-63"><a href="#cb24-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-64"><a href="#cb24-64" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb24-65"><a href="#cb24-65" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb24-66"><a href="#cb24-66" aria-hidden="true" tabindex="-1"></a>data_flag <span class="op">=</span> <span class="st">"pneumoniamnist"</span></span>
<span id="cb24-67"><a href="#cb24-67" aria-hidden="true" tabindex="-1"></a>info <span class="op">=</span> INFO[data_flag]</span>
<span id="cb24-68"><a href="#cb24-68" aria-hidden="true" tabindex="-1"></a>DataClass <span class="op">=</span> <span class="bu">getattr</span>(medmnist, info[<span class="st">'python_class'</span>])</span>
<span id="cb24-69"><a href="#cb24-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-70"><a href="#cb24-70" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb24-71"><a href="#cb24-71" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor()</span>
<span id="cb24-72"><a href="#cb24-72" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb24-73"><a href="#cb24-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-74"><a href="#cb24-74" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> DataClass(split<span class="op">=</span><span class="st">"train"</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb24-75"><a href="#cb24-75" aria-hidden="true" tabindex="-1"></a>test_ds  <span class="op">=</span> DataClass(split<span class="op">=</span><span class="st">"test"</span>,  download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb24-76"><a href="#cb24-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-77"><a href="#cb24-77" aria-hidden="true" tabindex="-1"></a><span class="co"># FIX LABELS: PneumoniaMNIST returns a dict-like label, we extract scalar</span></span>
<span id="cb24-78"><a href="#cb24-78" aria-hidden="true" tabindex="-1"></a>train_x <span class="op">=</span> torch.stack([img <span class="cf">for</span> img, lbl <span class="kw">in</span> train_ds])</span>
<span id="cb24-79"><a href="#cb24-79" aria-hidden="true" tabindex="-1"></a>train_y <span class="op">=</span> torch.tensor([<span class="bu">int</span>(lbl) <span class="cf">for</span> _, lbl <span class="kw">in</span> train_ds]).<span class="bu">float</span>()</span>
<span id="cb24-80"><a href="#cb24-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-81"><a href="#cb24-81" aria-hidden="true" tabindex="-1"></a>test_x <span class="op">=</span> torch.stack([img <span class="cf">for</span> img, lbl <span class="kw">in</span> test_ds])</span>
<span id="cb24-82"><a href="#cb24-82" aria-hidden="true" tabindex="-1"></a>test_y <span class="op">=</span> torch.tensor([<span class="bu">int</span>(lbl) <span class="cf">for</span> _, lbl <span class="kw">in</span> test_ds]).<span class="bu">float</span>()</span>
<span id="cb24-83"><a href="#cb24-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-84"><a href="#cb24-84" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PneumoniaBinary(Dataset):</span>
<span id="cb24-85"><a href="#cb24-85" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X, y):</span>
<span id="cb24-86"><a href="#cb24-86" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X <span class="op">=</span> X</span>
<span id="cb24-87"><a href="#cb24-87" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> y</span>
<span id="cb24-88"><a href="#cb24-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-89"><a href="#cb24-89" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb24-90"><a href="#cb24-90" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.X)</span>
<span id="cb24-91"><a href="#cb24-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-92"><a href="#cb24-92" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb24-93"><a href="#cb24-93" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.X[idx], <span class="va">self</span>.y[idx]</span>
<span id="cb24-94"><a href="#cb24-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-95"><a href="#cb24-95" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(PneumoniaBinary(train_x, train_y), batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-96"><a href="#cb24-96" aria-hidden="true" tabindex="-1"></a>test_loader  <span class="op">=</span> DataLoader(PneumoniaBinary(test_x, test_y), batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb24-97"><a href="#cb24-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-98"><a href="#cb24-98" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train:"</span>, <span class="bu">len</span>(train_loader.dataset))</span>
<span id="cb24-99"><a href="#cb24-99" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test:"</span>, <span class="bu">len</span>(test_loader.dataset))</span>
<span id="cb24-100"><a href="#cb24-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-101"><a href="#cb24-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-102"><a href="#cb24-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-103"><a href="#cb24-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-104"><a href="#cb24-104" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TinyCNN(nn.Module):</span>
<span id="cb24-105"><a href="#cb24-105" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb24-106"><a href="#cb24-106" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb24-107"><a href="#cb24-107" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">1</span>, <span class="dv">16</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb24-108"><a href="#cb24-108" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(<span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb24-109"><a href="#cb24-109" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool <span class="op">=</span> nn.MaxPool2d(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb24-110"><a href="#cb24-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-111"><a href="#cb24-111" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 28→14→7 (MedMNIST images are 28x28)</span></span>
<span id="cb24-112"><a href="#cb24-112" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">32</span> <span class="op">*</span> <span class="dv">7</span> <span class="op">*</span> <span class="dv">7</span>, <span class="dv">64</span>)</span>
<span id="cb24-113"><a href="#cb24-113" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">64</span>, <span class="dv">1</span>)</span>
<span id="cb24-114"><a href="#cb24-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-115"><a href="#cb24-115" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb24-116"><a href="#cb24-116" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(torch.relu(<span class="va">self</span>.conv1(x)))</span>
<span id="cb24-117"><a href="#cb24-117" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(torch.relu(<span class="va">self</span>.conv2(x)))</span>
<span id="cb24-118"><a href="#cb24-118" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">32</span> <span class="op">*</span> <span class="dv">7</span> <span class="op">*</span> <span class="dv">7</span>)</span>
<span id="cb24-119"><a href="#cb24-119" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.relu(<span class="va">self</span>.fc1(x))</span>
<span id="cb24-120"><a href="#cb24-120" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.fc2(x))</span>
<span id="cb24-121"><a href="#cb24-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-122"><a href="#cb24-122" aria-hidden="true" tabindex="-1"></a>tiny <span class="op">=</span> TinyCNN()</span>
<span id="cb24-123"><a href="#cb24-123" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.BCELoss()</span>
<span id="cb24-124"><a href="#cb24-124" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(tiny.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb24-125"><a href="#cb24-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-126"><a href="#cb24-126" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb24-127"><a href="#cb24-127" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training Tiny CNN...</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb24-128"><a href="#cb24-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-129"><a href="#cb24-129" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb24-130"><a href="#cb24-130" aria-hidden="true" tabindex="-1"></a>    tiny.train()</span>
<span id="cb24-131"><a href="#cb24-131" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb24-132"><a href="#cb24-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-133"><a href="#cb24-133" aria-hidden="true" tabindex="-1"></a>    loop <span class="op">=</span> tqdm(train_loader, desc<span class="op">=</span><span class="ss">f"TinyCNN Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss">"</span>, ncols<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb24-134"><a href="#cb24-134" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, labels <span class="kw">in</span> loop:</span>
<span id="cb24-135"><a href="#cb24-135" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> labels.unsqueeze(<span class="dv">1</span>)</span>
<span id="cb24-136"><a href="#cb24-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-137"><a href="#cb24-137" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb24-138"><a href="#cb24-138" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> tiny(images)</span>
<span id="cb24-139"><a href="#cb24-139" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(preds, labels)</span>
<span id="cb24-140"><a href="#cb24-140" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb24-141"><a href="#cb24-141" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb24-142"><a href="#cb24-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-143"><a href="#cb24-143" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb24-144"><a href="#cb24-144" aria-hidden="true" tabindex="-1"></a>        loop.set_postfix(loss<span class="op">=</span>loss.item())</span>
<span id="cb24-145"><a href="#cb24-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-146"><a href="#cb24-146" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Mean Loss: </span><span class="sc">{</span>total_loss<span class="op">/</span><span class="bu">len</span>(train_loader)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb24-147"><a href="#cb24-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-148"><a href="#cb24-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-149"><a href="#cb24-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-150"><a href="#cb24-150" aria-hidden="true" tabindex="-1"></a>tiny.<span class="bu">eval</span>()</span>
<span id="cb24-151"><a href="#cb24-151" aria-hidden="true" tabindex="-1"></a>correct, total <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb24-152"><a href="#cb24-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-153"><a href="#cb24-153" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb24-154"><a href="#cb24-154" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, labels <span class="kw">in</span> test_loader:</span>
<span id="cb24-155"><a href="#cb24-155" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> labels.unsqueeze(<span class="dv">1</span>)</span>
<span id="cb24-156"><a href="#cb24-156" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> (tiny(images) <span class="op">&gt;</span> <span class="fl">0.5</span>).<span class="bu">float</span>()</span>
<span id="cb24-157"><a href="#cb24-157" aria-hidden="true" tabindex="-1"></a>        correct <span class="op">+=</span> (preds <span class="op">==</span> labels).<span class="bu">sum</span>().item()</span>
<span id="cb24-158"><a href="#cb24-158" aria-hidden="true" tabindex="-1"></a>        total <span class="op">+=</span> labels.size(<span class="dv">0</span>)</span>
<span id="cb24-159"><a href="#cb24-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-160"><a href="#cb24-160" aria-hidden="true" tabindex="-1"></a>tiny_acc <span class="op">=</span> correct <span class="op">/</span> total</span>
<span id="cb24-161"><a href="#cb24-161" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tiny CNN Test Accuracy: </span><span class="sc">{</span>tiny_acc<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb24-162"><a href="#cb24-162" aria-hidden="true" tabindex="-1"></a>torch.save(tiny.state_dict(), <span class="st">"tinycnn_pneumonia.pt"</span>)</span>
<span id="cb24-163"><a href="#cb24-163" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TinyCNN saved!"</span>)</span>
<span id="cb24-164"><a href="#cb24-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-165"><a href="#cb24-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-166"><a href="#cb24-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-167"><a href="#cb24-167" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb24-168"><a href="#cb24-168" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb24-169"><a href="#cb24-169" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb24-170"><a href="#cb24-170" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> models</span>
<span id="cb24-171"><a href="#cb24-171" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb24-172"><a href="#cb24-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-173"><a href="#cb24-173" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------</span></span>
<span id="cb24-174"><a href="#cb24-174" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert grayscale → RGB</span></span>
<span id="cb24-175"><a href="#cb24-175" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------</span></span>
<span id="cb24-176"><a href="#cb24-176" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rgb_transform(x):</span>
<span id="cb24-177"><a href="#cb24-177" aria-hidden="true" tabindex="-1"></a>    <span class="co"># x = (batch, 1, 28, 28)</span></span>
<span id="cb24-178"><a href="#cb24-178" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x.repeat(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb24-179"><a href="#cb24-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-180"><a href="#cb24-180" aria-hidden="true" tabindex="-1"></a><span class="co"># Wrap loaders</span></span>
<span id="cb24-181"><a href="#cb24-181" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> convert_to_rgb(loader):</span>
<span id="cb24-182"><a href="#cb24-182" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> imgs, lbls <span class="kw">in</span> loader:</span>
<span id="cb24-183"><a href="#cb24-183" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> rgb_transform(imgs), lbls.unsqueeze(<span class="dv">1</span>)</span>
<span id="cb24-184"><a href="#cb24-184" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb24-185"><a href="#cb24-185" aria-hidden="true" tabindex="-1"></a>train_rgb <span class="op">=</span> convert_to_rgb(train_loader)</span>
<span id="cb24-186"><a href="#cb24-186" aria-hidden="true" tabindex="-1"></a>test_rgb  <span class="op">=</span> convert_to_rgb(test_loader)</span>
<span id="cb24-187"><a href="#cb24-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-188"><a href="#cb24-188" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------</span></span>
<span id="cb24-189"><a href="#cb24-189" aria-hidden="true" tabindex="-1"></a><span class="co"># Load ResNet-18 pretrained</span></span>
<span id="cb24-190"><a href="#cb24-190" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------</span></span>
<span id="cb24-191"><a href="#cb24-191" aria-hidden="true" tabindex="-1"></a>resnet18 <span class="op">=</span> models.resnet18(weights<span class="op">=</span><span class="st">"DEFAULT"</span>)</span>
<span id="cb24-192"><a href="#cb24-192" aria-hidden="true" tabindex="-1"></a>resnet18.fc <span class="op">=</span> nn.Linear(resnet18.fc.in_features, <span class="dv">1</span>)</span>
<span id="cb24-193"><a href="#cb24-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-194"><a href="#cb24-194" aria-hidden="true" tabindex="-1"></a>criterion_res <span class="op">=</span> nn.BCEWithLogitsLoss()</span>
<span id="cb24-195"><a href="#cb24-195" aria-hidden="true" tabindex="-1"></a>optimizer_res <span class="op">=</span> optim.Adam(resnet18.parameters(), lr<span class="op">=</span><span class="fl">0.0005</span>)</span>
<span id="cb24-196"><a href="#cb24-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-197"><a href="#cb24-197" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------</span></span>
<span id="cb24-198"><a href="#cb24-198" aria-hidden="true" tabindex="-1"></a><span class="co"># Train ResNet-18</span></span>
<span id="cb24-199"><a href="#cb24-199" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------</span></span>
<span id="cb24-200"><a href="#cb24-200" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">3</span>  <span class="co"># use fewer epochs to keep fast</span></span>
<span id="cb24-201"><a href="#cb24-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-202"><a href="#cb24-202" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Training ResNet-18...</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb24-203"><a href="#cb24-203" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb24-204"><a href="#cb24-204" aria-hidden="true" tabindex="-1"></a>    resnet18.train()</span>
<span id="cb24-205"><a href="#cb24-205" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb24-206"><a href="#cb24-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-207"><a href="#cb24-207" aria-hidden="true" tabindex="-1"></a>    loop <span class="op">=</span> tqdm(train_rgb, desc<span class="op">=</span><span class="ss">f"ResNet18 Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss">"</span>, ncols<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb24-208"><a href="#cb24-208" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, labels <span class="kw">in</span> loop:</span>
<span id="cb24-209"><a href="#cb24-209" aria-hidden="true" tabindex="-1"></a>        optimizer_res.zero_grad()</span>
<span id="cb24-210"><a href="#cb24-210" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> resnet18(images)</span>
<span id="cb24-211"><a href="#cb24-211" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion_res(preds, labels)</span>
<span id="cb24-212"><a href="#cb24-212" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb24-213"><a href="#cb24-213" aria-hidden="true" tabindex="-1"></a>        optimizer_res.step()</span>
<span id="cb24-214"><a href="#cb24-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-215"><a href="#cb24-215" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb24-216"><a href="#cb24-216" aria-hidden="true" tabindex="-1"></a>        loop.set_postfix(loss<span class="op">=</span><span class="bu">float</span>(loss))</span>
<span id="cb24-217"><a href="#cb24-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-218"><a href="#cb24-218" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Mean Loss: </span><span class="sc">{</span>total_loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb24-219"><a href="#cb24-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-220"><a href="#cb24-220" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------</span></span>
<span id="cb24-221"><a href="#cb24-221" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate ResNet-18</span></span>
<span id="cb24-222"><a href="#cb24-222" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------</span></span>
<span id="cb24-223"><a href="#cb24-223" aria-hidden="true" tabindex="-1"></a>resnet18.<span class="bu">eval</span>()</span>
<span id="cb24-224"><a href="#cb24-224" aria-hidden="true" tabindex="-1"></a>correct, total <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb24-225"><a href="#cb24-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-226"><a href="#cb24-226" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb24-227"><a href="#cb24-227" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, labels <span class="kw">in</span> test_rgb:</span>
<span id="cb24-228"><a href="#cb24-228" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> (torch.sigmoid(resnet18(images)) <span class="op">&gt;</span> <span class="fl">0.5</span>).<span class="bu">float</span>()</span>
<span id="cb24-229"><a href="#cb24-229" aria-hidden="true" tabindex="-1"></a>        correct <span class="op">+=</span> (preds <span class="op">==</span> labels).<span class="bu">sum</span>().item()</span>
<span id="cb24-230"><a href="#cb24-230" aria-hidden="true" tabindex="-1"></a>        total <span class="op">+=</span> labels.size(<span class="dv">0</span>)</span>
<span id="cb24-231"><a href="#cb24-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-232"><a href="#cb24-232" aria-hidden="true" tabindex="-1"></a>resnet18_acc <span class="op">=</span> correct <span class="op">/</span> total</span>
<span id="cb24-233"><a href="#cb24-233" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">ResNet-18 Test Accuracy: </span><span class="sc">{</span>resnet18_acc<span class="sc">:.4f}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb24-234"><a href="#cb24-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-235"><a href="#cb24-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-236"><a href="#cb24-236" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------</span></span>
<span id="cb24-237"><a href="#cb24-237" aria-hidden="true" tabindex="-1"></a><span class="co"># Save model</span></span>
<span id="cb24-238"><a href="#cb24-238" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------</span></span>
<span id="cb24-239"><a href="#cb24-239" aria-hidden="true" tabindex="-1"></a>torch.save(resnet18.state_dict(), <span class="st">"resnet18_pneumonia.pt"</span>)</span>
<span id="cb24-240"><a href="#cb24-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-241"><a href="#cb24-241" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb24-242"><a href="#cb24-242" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb24-243"><a href="#cb24-243" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb24-244"><a href="#cb24-244" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms, models</span>
<span id="cb24-245"><a href="#cb24-245" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb24-246"><a href="#cb24-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-247"><a href="#cb24-247" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb24-248"><a href="#cb24-248" aria-hidden="true" tabindex="-1"></a><span class="co"># 0. Fix: Resize + convert grayscale → RGB for ResNet-50</span></span>
<span id="cb24-249"><a href="#cb24-249" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb24-250"><a href="#cb24-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-251"><a href="#cb24-251" aria-hidden="true" tabindex="-1"></a>resize_to_224 <span class="op">=</span> transforms.Resize((<span class="dv">224</span>, <span class="dv">224</span>))</span>
<span id="cb24-252"><a href="#cb24-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-253"><a href="#cb24-253" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rgb_transform(batch):</span>
<span id="cb24-254"><a href="#cb24-254" aria-hidden="true" tabindex="-1"></a>    <span class="co"># batch: [B, 1, 28, 28]</span></span>
<span id="cb24-255"><a href="#cb24-255" aria-hidden="true" tabindex="-1"></a>    batch <span class="op">=</span> resize_to_224(batch)          <span class="co"># -&gt; [B, 1, 224, 224]</span></span>
<span id="cb24-256"><a href="#cb24-256" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> batch.repeat(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">1</span>)       <span class="co"># -&gt; [B, 3, 224, 224]</span></span>
<span id="cb24-257"><a href="#cb24-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-258"><a href="#cb24-258" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RGBLoader:</span>
<span id="cb24-259"><a href="#cb24-259" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Wraps an existing DataLoader and yields resized RGB tensors"""</span></span>
<span id="cb24-260"><a href="#cb24-260" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, loader):</span>
<span id="cb24-261"><a href="#cb24-261" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.loader <span class="op">=</span> loader</span>
<span id="cb24-262"><a href="#cb24-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-263"><a href="#cb24-263" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__iter__</span>(<span class="va">self</span>):</span>
<span id="cb24-264"><a href="#cb24-264" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> imgs, lbls <span class="kw">in</span> <span class="va">self</span>.loader:</span>
<span id="cb24-265"><a href="#cb24-265" aria-hidden="true" tabindex="-1"></a>            rgb_imgs <span class="op">=</span> rgb_transform(imgs)</span>
<span id="cb24-266"><a href="#cb24-266" aria-hidden="true" tabindex="-1"></a>            <span class="cf">yield</span> rgb_imgs, lbls.unsqueeze(<span class="dv">1</span>)</span>
<span id="cb24-267"><a href="#cb24-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-268"><a href="#cb24-268" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb24-269"><a href="#cb24-269" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.loader)</span>
<span id="cb24-270"><a href="#cb24-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-271"><a href="#cb24-271" aria-hidden="true" tabindex="-1"></a><span class="co"># Create RGB loaders</span></span>
<span id="cb24-272"><a href="#cb24-272" aria-hidden="true" tabindex="-1"></a>train_rgb <span class="op">=</span> RGBLoader(train_loader)</span>
<span id="cb24-273"><a href="#cb24-273" aria-hidden="true" tabindex="-1"></a>test_rgb  <span class="op">=</span> RGBLoader(test_loader)</span>
<span id="cb24-274"><a href="#cb24-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-275"><a href="#cb24-275" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb24-276"><a href="#cb24-276" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Build ResNet-50 binary classifier</span></span>
<span id="cb24-277"><a href="#cb24-277" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb24-278"><a href="#cb24-278" aria-hidden="true" tabindex="-1"></a>resnet50 <span class="op">=</span> models.resnet50(weights<span class="op">=</span><span class="st">"DEFAULT"</span>)</span>
<span id="cb24-279"><a href="#cb24-279" aria-hidden="true" tabindex="-1"></a>resnet50.fc <span class="op">=</span> nn.Linear(resnet50.fc.in_features, <span class="dv">1</span>)</span>
<span id="cb24-280"><a href="#cb24-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-281"><a href="#cb24-281" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.BCEWithLogitsLoss()</span>
<span id="cb24-282"><a href="#cb24-282" aria-hidden="true" tabindex="-1"></a>optimizer_res50 <span class="op">=</span> optim.Adam(resnet50.parameters(), lr<span class="op">=</span><span class="fl">5e-4</span>)</span>
<span id="cb24-283"><a href="#cb24-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-284"><a href="#cb24-284" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb24-285"><a href="#cb24-285" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Train ResNet-50</span></span>
<span id="cb24-286"><a href="#cb24-286" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb24-287"><a href="#cb24-287" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb24-288"><a href="#cb24-288" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Training ResNet-50...</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb24-289"><a href="#cb24-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-290"><a href="#cb24-290" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb24-291"><a href="#cb24-291" aria-hidden="true" tabindex="-1"></a>    resnet50.train()</span>
<span id="cb24-292"><a href="#cb24-292" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb24-293"><a href="#cb24-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-294"><a href="#cb24-294" aria-hidden="true" tabindex="-1"></a>    loop <span class="op">=</span> tqdm(train_rgb, desc<span class="op">=</span><span class="ss">f"ResNet-50 Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss">"</span>, ncols<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb24-295"><a href="#cb24-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-296"><a href="#cb24-296" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, labels <span class="kw">in</span> loop:</span>
<span id="cb24-297"><a href="#cb24-297" aria-hidden="true" tabindex="-1"></a>        optimizer_res50.zero_grad()</span>
<span id="cb24-298"><a href="#cb24-298" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> resnet50(images)</span>
<span id="cb24-299"><a href="#cb24-299" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(preds, labels)</span>
<span id="cb24-300"><a href="#cb24-300" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb24-301"><a href="#cb24-301" aria-hidden="true" tabindex="-1"></a>        optimizer_res50.step()</span>
<span id="cb24-302"><a href="#cb24-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-303"><a href="#cb24-303" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb24-304"><a href="#cb24-304" aria-hidden="true" tabindex="-1"></a>        loop.set_postfix(loss<span class="op">=</span>loss.item())</span>
<span id="cb24-305"><a href="#cb24-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-306"><a href="#cb24-306" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Loss: </span><span class="sc">{</span>total_loss<span class="op">/</span><span class="bu">len</span>(train_rgb)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb24-307"><a href="#cb24-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-308"><a href="#cb24-308" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb24-309"><a href="#cb24-309" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Evaluate ResNet-50</span></span>
<span id="cb24-310"><a href="#cb24-310" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb24-311"><a href="#cb24-311" aria-hidden="true" tabindex="-1"></a>resnet50.<span class="bu">eval</span>()</span>
<span id="cb24-312"><a href="#cb24-312" aria-hidden="true" tabindex="-1"></a>correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb24-313"><a href="#cb24-313" aria-hidden="true" tabindex="-1"></a>total <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb24-314"><a href="#cb24-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-315"><a href="#cb24-315" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb24-316"><a href="#cb24-316" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, labels <span class="kw">in</span> test_rgb:</span>
<span id="cb24-317"><a href="#cb24-317" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> resnet50(images)</span>
<span id="cb24-318"><a href="#cb24-318" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> (torch.sigmoid(logits) <span class="op">&gt;</span> <span class="fl">0.5</span>).<span class="bu">float</span>()</span>
<span id="cb24-319"><a href="#cb24-319" aria-hidden="true" tabindex="-1"></a>        correct <span class="op">+=</span> (preds <span class="op">==</span> labels).<span class="bu">sum</span>().item()</span>
<span id="cb24-320"><a href="#cb24-320" aria-hidden="true" tabindex="-1"></a>        total <span class="op">+=</span> labels.size(<span class="dv">0</span>)</span>
<span id="cb24-321"><a href="#cb24-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-322"><a href="#cb24-322" aria-hidden="true" tabindex="-1"></a>resnet50_acc <span class="op">=</span> correct <span class="op">/</span> total</span>
<span id="cb24-323"><a href="#cb24-323" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">ResNet-50 Accuracy: </span><span class="sc">{</span>resnet50_acc<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb24-324"><a href="#cb24-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-325"><a href="#cb24-325" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb24-326"><a href="#cb24-326" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Save model</span></span>
<span id="cb24-327"><a href="#cb24-327" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb24-328"><a href="#cb24-328" aria-hidden="true" tabindex="-1"></a>torch.save(resnet50.state_dict(), <span class="st">"resnet50_pneumonia.pt"</span>)</span>
<span id="cb24-329"><a href="#cb24-329" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Saved: resnet50_pneumonia.pt"</span>)</span>
<span id="cb24-330"><a href="#cb24-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-331"><a href="#cb24-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-332"><a href="#cb24-332" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------------------</span></span>
<span id="cb24-333"><a href="#cb24-333" aria-hidden="true" tabindex="-1"></a><span class="co"># EfficientNet-B0 for PneumoniaMNIST</span></span>
<span id="cb24-334"><a href="#cb24-334" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------------------</span></span>
<span id="cb24-335"><a href="#cb24-335" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.models <span class="im">import</span> efficientnet_b0, EfficientNet_B0_Weights</span>
<span id="cb24-336"><a href="#cb24-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-337"><a href="#cb24-337" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Loading EfficientNet-B0..."</span>)</span>
<span id="cb24-338"><a href="#cb24-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-339"><a href="#cb24-339" aria-hidden="true" tabindex="-1"></a><span class="co"># Load pretrained model</span></span>
<span id="cb24-340"><a href="#cb24-340" aria-hidden="true" tabindex="-1"></a>efficientnet <span class="op">=</span> efficientnet_b0(weights<span class="op">=</span>EfficientNet_B0_Weights.DEFAULT)</span>
<span id="cb24-341"><a href="#cb24-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-342"><a href="#cb24-342" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace classifier for binary output</span></span>
<span id="cb24-343"><a href="#cb24-343" aria-hidden="true" tabindex="-1"></a>efficientnet.classifier[<span class="dv">1</span>] <span class="op">=</span> nn.Linear(</span>
<span id="cb24-344"><a href="#cb24-344" aria-hidden="true" tabindex="-1"></a>    efficientnet.classifier[<span class="dv">1</span>].in_features, <span class="dv">1</span></span>
<span id="cb24-345"><a href="#cb24-345" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-346"><a href="#cb24-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-347"><a href="#cb24-347" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.BCEWithLogitsLoss()</span>
<span id="cb24-348"><a href="#cb24-348" aria-hidden="true" tabindex="-1"></a>optimizer_eff <span class="op">=</span> optim.Adam(efficientnet.parameters(), lr<span class="op">=</span><span class="fl">5e-4</span>)</span>
<span id="cb24-349"><a href="#cb24-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-350"><a href="#cb24-350" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb24-351"><a href="#cb24-351" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Training EfficientNet-B0...</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb24-352"><a href="#cb24-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-353"><a href="#cb24-353" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb24-354"><a href="#cb24-354" aria-hidden="true" tabindex="-1"></a>    efficientnet.train()</span>
<span id="cb24-355"><a href="#cb24-355" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb24-356"><a href="#cb24-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-357"><a href="#cb24-357" aria-hidden="true" tabindex="-1"></a>    loop <span class="op">=</span> tqdm(train_rgb, desc<span class="op">=</span><span class="ss">f"EfficientNet-B0 Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss">"</span>, ncols<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb24-358"><a href="#cb24-358" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-359"><a href="#cb24-359" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, labels <span class="kw">in</span> loop:</span>
<span id="cb24-360"><a href="#cb24-360" aria-hidden="true" tabindex="-1"></a>        optimizer_eff.zero_grad()</span>
<span id="cb24-361"><a href="#cb24-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-362"><a href="#cb24-362" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> efficientnet(images)</span>
<span id="cb24-363"><a href="#cb24-363" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(preds, labels)</span>
<span id="cb24-364"><a href="#cb24-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-365"><a href="#cb24-365" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb24-366"><a href="#cb24-366" aria-hidden="true" tabindex="-1"></a>        optimizer_eff.step()</span>
<span id="cb24-367"><a href="#cb24-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-368"><a href="#cb24-368" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb24-369"><a href="#cb24-369" aria-hidden="true" tabindex="-1"></a>        loop.set_postfix(loss<span class="op">=</span>loss.item())</span>
<span id="cb24-370"><a href="#cb24-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-371"><a href="#cb24-371" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Mean Loss: </span><span class="sc">{</span>total_loss<span class="op">/</span><span class="bu">len</span>(train_rgb)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb24-372"><a href="#cb24-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-373"><a href="#cb24-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-374"><a href="#cb24-374" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------------------</span></span>
<span id="cb24-375"><a href="#cb24-375" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation</span></span>
<span id="cb24-376"><a href="#cb24-376" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------------------</span></span>
<span id="cb24-377"><a href="#cb24-377" aria-hidden="true" tabindex="-1"></a>efficientnet.<span class="bu">eval</span>()</span>
<span id="cb24-378"><a href="#cb24-378" aria-hidden="true" tabindex="-1"></a>correct, total <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb24-379"><a href="#cb24-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-380"><a href="#cb24-380" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb24-381"><a href="#cb24-381" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, labels <span class="kw">in</span> test_rgb:</span>
<span id="cb24-382"><a href="#cb24-382" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> torch.sigmoid(efficientnet(images))</span>
<span id="cb24-383"><a href="#cb24-383" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> (preds <span class="op">&gt;</span> <span class="fl">0.5</span>).<span class="bu">float</span>()</span>
<span id="cb24-384"><a href="#cb24-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-385"><a href="#cb24-385" aria-hidden="true" tabindex="-1"></a>        correct <span class="op">+=</span> (preds <span class="op">==</span> labels).<span class="bu">sum</span>().item()</span>
<span id="cb24-386"><a href="#cb24-386" aria-hidden="true" tabindex="-1"></a>        total <span class="op">+=</span> labels.size(<span class="dv">0</span>)</span>
<span id="cb24-387"><a href="#cb24-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-388"><a href="#cb24-388" aria-hidden="true" tabindex="-1"></a>eff_acc <span class="op">=</span> correct <span class="op">/</span> total</span>
<span id="cb24-389"><a href="#cb24-389" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">EfficientNet-B0 Test Accuracy: </span><span class="sc">{</span>eff_acc<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb24-390"><a href="#cb24-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-391"><a href="#cb24-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-392"><a href="#cb24-392" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------------------</span></span>
<span id="cb24-393"><a href="#cb24-393" aria-hidden="true" tabindex="-1"></a><span class="co"># Save model</span></span>
<span id="cb24-394"><a href="#cb24-394" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------------------</span></span>
<span id="cb24-395"><a href="#cb24-395" aria-hidden="true" tabindex="-1"></a>torch.save(efficientnet.state_dict(), <span class="st">"efficientnet_pneumonia.pt"</span>)</span>
<span id="cb24-396"><a href="#cb24-396" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Model saved as efficientnet_pneumonia.pt"</span>)</span>
<span id="cb24-397"><a href="#cb24-397" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb24-398"><a href="#cb24-398" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb24-399"><a href="#cb24-399" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb24-400"><a href="#cb24-400" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, Dataset</span>
<span id="cb24-401"><a href="#cb24-401" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, accuracy_score</span>
<span id="cb24-402"><a href="#cb24-402" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb24-403"><a href="#cb24-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-404"><a href="#cb24-404" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------</span></span>
<span id="cb24-405"><a href="#cb24-405" aria-hidden="true" tabindex="-1"></a><span class="co"># Reload dataset (same as before)</span></span>
<span id="cb24-406"><a href="#cb24-406" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------</span></span>
<span id="cb24-407"><a href="#cb24-407" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_pneumonia_mnist():</span>
<span id="cb24-408"><a href="#cb24-408" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> medmnist</span>
<span id="cb24-409"><a href="#cb24-409" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> medmnist <span class="im">import</span> INFO</span>
<span id="cb24-410"><a href="#cb24-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-411"><a href="#cb24-411" aria-hidden="true" tabindex="-1"></a>    data_flag <span class="op">=</span> <span class="st">"pneumoniamnist"</span></span>
<span id="cb24-412"><a href="#cb24-412" aria-hidden="true" tabindex="-1"></a>    info <span class="op">=</span> INFO[data_flag]</span>
<span id="cb24-413"><a href="#cb24-413" aria-hidden="true" tabindex="-1"></a>    DataClass <span class="op">=</span> <span class="bu">getattr</span>(medmnist, info[<span class="st">'python_class'</span>])</span>
<span id="cb24-414"><a href="#cb24-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-415"><a href="#cb24-415" aria-hidden="true" tabindex="-1"></a>    transform <span class="op">=</span> transforms.Compose([transforms.ToTensor()])</span>
<span id="cb24-416"><a href="#cb24-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-417"><a href="#cb24-417" aria-hidden="true" tabindex="-1"></a>    train_ds <span class="op">=</span> DataClass(split<span class="op">=</span><span class="st">"train"</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb24-418"><a href="#cb24-418" aria-hidden="true" tabindex="-1"></a>    test_ds  <span class="op">=</span> DataClass(split<span class="op">=</span><span class="st">"test"</span>,  download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb24-419"><a href="#cb24-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-420"><a href="#cb24-420" aria-hidden="true" tabindex="-1"></a>    X_train <span class="op">=</span> torch.stack([img <span class="cf">for</span> img, lbl <span class="kw">in</span> train_ds])</span>
<span id="cb24-421"><a href="#cb24-421" aria-hidden="true" tabindex="-1"></a>    y_train <span class="op">=</span> torch.tensor([<span class="bu">int</span>(lbl) <span class="cf">for</span> _, lbl <span class="kw">in</span> train_ds]).<span class="bu">float</span>()</span>
<span id="cb24-422"><a href="#cb24-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-423"><a href="#cb24-423" aria-hidden="true" tabindex="-1"></a>    X_test  <span class="op">=</span> torch.stack([img <span class="cf">for</span> img, lbl <span class="kw">in</span> test_ds])</span>
<span id="cb24-424"><a href="#cb24-424" aria-hidden="true" tabindex="-1"></a>    y_test  <span class="op">=</span> torch.tensor([<span class="bu">int</span>(lbl) <span class="cf">for</span> _, lbl <span class="kw">in</span> test_ds]).<span class="bu">float</span>()</span>
<span id="cb24-425"><a href="#cb24-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-426"><a href="#cb24-426" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X_train, y_train, X_test, y_test</span>
<span id="cb24-427"><a href="#cb24-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-428"><a href="#cb24-428" aria-hidden="true" tabindex="-1"></a>X_train, y_train, X_test, y_test <span class="op">=</span> load_pneumonia_mnist()</span>
<span id="cb24-429"><a href="#cb24-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-430"><a href="#cb24-430" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PneumoniaDataset(Dataset):</span>
<span id="cb24-431"><a href="#cb24-431" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X, y):</span>
<span id="cb24-432"><a href="#cb24-432" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X <span class="op">=</span> X</span>
<span id="cb24-433"><a href="#cb24-433" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> y</span>
<span id="cb24-434"><a href="#cb24-434" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb24-435"><a href="#cb24-435" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.X)</span>
<span id="cb24-436"><a href="#cb24-436" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb24-437"><a href="#cb24-437" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.X[idx], <span class="va">self</span>.y[idx]</span>
<span id="cb24-438"><a href="#cb24-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-439"><a href="#cb24-439" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> DataLoader(PneumoniaDataset(X_test, y_test), batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb24-440"><a href="#cb24-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-441"><a href="#cb24-441" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------</span></span>
<span id="cb24-442"><a href="#cb24-442" aria-hidden="true" tabindex="-1"></a><span class="co"># TinyCNN model definition</span></span>
<span id="cb24-443"><a href="#cb24-443" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------</span></span>
<span id="cb24-444"><a href="#cb24-444" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TinyCNN(nn.Module):</span>
<span id="cb24-445"><a href="#cb24-445" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb24-446"><a href="#cb24-446" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb24-447"><a href="#cb24-447" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">1</span>, <span class="dv">16</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb24-448"><a href="#cb24-448" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(<span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb24-449"><a href="#cb24-449" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool <span class="op">=</span> nn.MaxPool2d(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb24-450"><a href="#cb24-450" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">32</span> <span class="op">*</span> <span class="dv">7</span> <span class="op">*</span> <span class="dv">7</span>, <span class="dv">64</span>)</span>
<span id="cb24-451"><a href="#cb24-451" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">64</span>, <span class="dv">1</span>)</span>
<span id="cb24-452"><a href="#cb24-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-453"><a href="#cb24-453" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb24-454"><a href="#cb24-454" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(torch.relu(<span class="va">self</span>.conv1(x)))</span>
<span id="cb24-455"><a href="#cb24-455" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(torch.relu(<span class="va">self</span>.conv2(x)))</span>
<span id="cb24-456"><a href="#cb24-456" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">32</span><span class="op">*</span><span class="dv">7</span><span class="op">*</span><span class="dv">7</span>)</span>
<span id="cb24-457"><a href="#cb24-457" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.relu(<span class="va">self</span>.fc1(x))</span>
<span id="cb24-458"><a href="#cb24-458" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.fc2(x))</span>
<span id="cb24-459"><a href="#cb24-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-460"><a href="#cb24-460" aria-hidden="true" tabindex="-1"></a>tiny <span class="op">=</span> TinyCNN()</span>
<span id="cb24-461"><a href="#cb24-461" aria-hidden="true" tabindex="-1"></a>tiny.load_state_dict(torch.load(<span class="st">"tinycnn_pneumonia.pt"</span>, map_location<span class="op">=</span><span class="st">"cpu"</span>))</span>
<span id="cb24-462"><a href="#cb24-462" aria-hidden="true" tabindex="-1"></a>tiny.<span class="bu">eval</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="evaluating-all-models-fitted-in-python" class="level3" data-number="4.19.3">
<h3 data-number="4.19.3" class="anchored" data-anchor-id="evaluating-all-models-fitted-in-python"><span class="header-section-number">4.19.3</span> Evaluating all models fitted in Python</h3>
<p>We use the following code to evaluate the models.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 0. Imports</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> models, transforms</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> medmnist</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> medmnist <span class="im">import</span> INFO</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, accuracy_score</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Load PneumoniaMNIST</span></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_pneumonia_mnist():</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>    data_flag <span class="op">=</span> <span class="st">"pneumoniamnist"</span></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>    info <span class="op">=</span> INFO[data_flag]</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>    DataClass <span class="op">=</span> <span class="bu">getattr</span>(medmnist, info[<span class="st">'python_class'</span>])</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>    transform <span class="op">=</span> transforms.Compose([transforms.ToTensor()])</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>    test_ds <span class="op">=</span> DataClass(split<span class="op">=</span><span class="st">"test"</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>    X_test  <span class="op">=</span> torch.stack([img <span class="cf">for</span> img, lbl <span class="kw">in</span> test_ds])</span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>    y_test  <span class="op">=</span> torch.tensor([<span class="bu">int</span>(lbl) <span class="cf">for</span> _, lbl <span class="kw">in</span> test_ds]).<span class="bu">float</span>()</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Loaded PneumoniaMNIST test set:"</span>, <span class="bu">len</span>(X_test))</span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X_test, y_test</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>X_test, y_test <span class="op">=</span> load_pneumonia_mnist()</span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PneumoniaDataset(Dataset):</span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X, y):</span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X <span class="op">=</span> X</span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> y</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.X)</span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.X[idx], <span class="va">self</span>.y[idx]</span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>test_loader_gray <span class="op">=</span> DataLoader(</span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>    PneumoniaDataset(X_test, y_test),</span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">False</span></span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Convert to RGB (for ResNet and EfficientNet) ---</span></span>
<span id="cb25-53"><a href="#cb25-53" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> to_rgb(batch):</span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> batch.repeat(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PneumoniaRGB(Dataset):</span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X, y):</span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X <span class="op">=</span> to_rgb(X)</span>
<span id="cb25-59"><a href="#cb25-59" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> y</span>
<span id="cb25-60"><a href="#cb25-60" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb25-61"><a href="#cb25-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.X)</span>
<span id="cb25-62"><a href="#cb25-62" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb25-63"><a href="#cb25-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.X[idx], <span class="va">self</span>.y[idx]</span>
<span id="cb25-64"><a href="#cb25-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-65"><a href="#cb25-65" aria-hidden="true" tabindex="-1"></a>test_loader_rgb <span class="op">=</span> DataLoader(</span>
<span id="cb25-66"><a href="#cb25-66" aria-hidden="true" tabindex="-1"></a>    PneumoniaRGB(X_test, y_test),</span>
<span id="cb25-67"><a href="#cb25-67" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">False</span></span>
<span id="cb25-68"><a href="#cb25-68" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-69"><a href="#cb25-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-70"><a href="#cb25-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-71"><a href="#cb25-71" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb25-72"><a href="#cb25-72" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Evaluate model + confusion matrix</span></span>
<span id="cb25-73"><a href="#cb25-73" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb25-74"><a href="#cb25-74" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_binary_model(model, loader):</span>
<span id="cb25-75"><a href="#cb25-75" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb25-76"><a href="#cb25-76" aria-hidden="true" tabindex="-1"></a>    preds_all <span class="op">=</span> []</span>
<span id="cb25-77"><a href="#cb25-77" aria-hidden="true" tabindex="-1"></a>    labels_all <span class="op">=</span> []</span>
<span id="cb25-78"><a href="#cb25-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-79"><a href="#cb25-79" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb25-80"><a href="#cb25-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> images, labels <span class="kw">in</span> loader:</span>
<span id="cb25-81"><a href="#cb25-81" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> model(images)</span>
<span id="cb25-82"><a href="#cb25-82" aria-hidden="true" tabindex="-1"></a>            probs <span class="op">=</span> torch.sigmoid(logits)</span>
<span id="cb25-83"><a href="#cb25-83" aria-hidden="true" tabindex="-1"></a>            preds <span class="op">=</span> (probs <span class="op">&gt;</span> <span class="fl">0.5</span>).<span class="bu">float</span>()</span>
<span id="cb25-84"><a href="#cb25-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-85"><a href="#cb25-85" aria-hidden="true" tabindex="-1"></a>            preds_all.extend(preds.squeeze().cpu().numpy())</span>
<span id="cb25-86"><a href="#cb25-86" aria-hidden="true" tabindex="-1"></a>            labels_all.extend(labels.cpu().numpy())</span>
<span id="cb25-87"><a href="#cb25-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-88"><a href="#cb25-88" aria-hidden="true" tabindex="-1"></a>    preds_all <span class="op">=</span> np.array(preds_all).astype(<span class="bu">int</span>)</span>
<span id="cb25-89"><a href="#cb25-89" aria-hidden="true" tabindex="-1"></a>    labels_all <span class="op">=</span> np.array(labels_all).astype(<span class="bu">int</span>)</span>
<span id="cb25-90"><a href="#cb25-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-91"><a href="#cb25-91" aria-hidden="true" tabindex="-1"></a>    acc <span class="op">=</span> accuracy_score(labels_all, preds_all)</span>
<span id="cb25-92"><a href="#cb25-92" aria-hidden="true" tabindex="-1"></a>    cm  <span class="op">=</span> confusion_matrix(labels_all, preds_all)</span>
<span id="cb25-93"><a href="#cb25-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-94"><a href="#cb25-94" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> acc, cm</span>
<span id="cb25-95"><a href="#cb25-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-96"><a href="#cb25-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-97"><a href="#cb25-97" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cm(cm, title):</span>
<span id="cb25-98"><a href="#cb25-98" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>,<span class="dv">4</span>))</span>
<span id="cb25-99"><a href="#cb25-99" aria-hidden="true" tabindex="-1"></a>    sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">"d"</span>, cmap<span class="op">=</span><span class="st">"Blues"</span>,</span>
<span id="cb25-100"><a href="#cb25-100" aria-hidden="true" tabindex="-1"></a>                xticklabels<span class="op">=</span>[<span class="st">"Normal"</span>, <span class="st">"Pneumonia"</span>],</span>
<span id="cb25-101"><a href="#cb25-101" aria-hidden="true" tabindex="-1"></a>                yticklabels<span class="op">=</span>[<span class="st">"Normal"</span>, <span class="st">"Pneumonia"</span>])</span>
<span id="cb25-102"><a href="#cb25-102" aria-hidden="true" tabindex="-1"></a>    plt.title(title)</span>
<span id="cb25-103"><a href="#cb25-103" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"True Label"</span>)</span>
<span id="cb25-104"><a href="#cb25-104" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Predicted Label"</span>)</span>
<span id="cb25-105"><a href="#cb25-105" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb25-106"><a href="#cb25-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-107"><a href="#cb25-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-108"><a href="#cb25-108" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb25-109"><a href="#cb25-109" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. TinyCNN (GRAY images)</span></span>
<span id="cb25-110"><a href="#cb25-110" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb25-111"><a href="#cb25-111" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Evaluating TinyCNN ==="</span>)</span>
<span id="cb25-112"><a href="#cb25-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-113"><a href="#cb25-113" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TinyCNN(nn.Module):</span>
<span id="cb25-114"><a href="#cb25-114" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb25-115"><a href="#cb25-115" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-116"><a href="#cb25-116" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">1</span>, <span class="dv">16</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb25-117"><a href="#cb25-117" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(<span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb25-118"><a href="#cb25-118" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool <span class="op">=</span> nn.MaxPool2d(<span class="dv">2</span>,<span class="dv">2</span>)</span>
<span id="cb25-119"><a href="#cb25-119" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">32</span><span class="op">*</span><span class="dv">7</span><span class="op">*</span><span class="dv">7</span>, <span class="dv">64</span>)</span>
<span id="cb25-120"><a href="#cb25-120" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">64</span>, <span class="dv">1</span>)</span>
<span id="cb25-121"><a href="#cb25-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-122"><a href="#cb25-122" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb25-123"><a href="#cb25-123" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(torch.relu(<span class="va">self</span>.conv1(x)))</span>
<span id="cb25-124"><a href="#cb25-124" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(torch.relu(<span class="va">self</span>.conv2(x)))</span>
<span id="cb25-125"><a href="#cb25-125" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">32</span><span class="op">*</span><span class="dv">7</span><span class="op">*</span><span class="dv">7</span>)</span>
<span id="cb25-126"><a href="#cb25-126" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.relu(<span class="va">self</span>.fc1(x))</span>
<span id="cb25-127"><a href="#cb25-127" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.fc2(x)</span>
<span id="cb25-128"><a href="#cb25-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-129"><a href="#cb25-129" aria-hidden="true" tabindex="-1"></a>tiny <span class="op">=</span> TinyCNN()</span>
<span id="cb25-130"><a href="#cb25-130" aria-hidden="true" tabindex="-1"></a>tiny.load_state_dict(torch.load(<span class="st">"tinycnn_pneumonia.pt"</span>, map_location<span class="op">=</span><span class="st">"cpu"</span>))</span>
<span id="cb25-131"><a href="#cb25-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-132"><a href="#cb25-132" aria-hidden="true" tabindex="-1"></a>acc_tiny, cm_tiny <span class="op">=</span> evaluate_binary_model(tiny, test_loader_gray)</span>
<span id="cb25-133"><a href="#cb25-133" aria-hidden="true" tabindex="-1"></a>plot_cm(cm_tiny, <span class="ss">f"TinyCNN – Accuracy </span><span class="sc">{</span>acc_tiny<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb25-134"><a href="#cb25-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-135"><a href="#cb25-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-136"><a href="#cb25-136" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb25-137"><a href="#cb25-137" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. ResNet-18 (RGB images)</span></span>
<span id="cb25-138"><a href="#cb25-138" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb25-139"><a href="#cb25-139" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Evaluating ResNet-18 ==="</span>)</span>
<span id="cb25-140"><a href="#cb25-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-141"><a href="#cb25-141" aria-hidden="true" tabindex="-1"></a>res18 <span class="op">=</span> models.resnet18(weights<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb25-142"><a href="#cb25-142" aria-hidden="true" tabindex="-1"></a>res18.fc <span class="op">=</span> nn.Linear(res18.fc.in_features, <span class="dv">1</span>)</span>
<span id="cb25-143"><a href="#cb25-143" aria-hidden="true" tabindex="-1"></a>res18.load_state_dict(torch.load(<span class="st">"resnet18_pneumonia.pt"</span>, map_location<span class="op">=</span><span class="st">"cpu"</span>))</span>
<span id="cb25-144"><a href="#cb25-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-145"><a href="#cb25-145" aria-hidden="true" tabindex="-1"></a>acc_r18, cm_r18 <span class="op">=</span> evaluate_binary_model(res18, test_loader_rgb)</span>
<span id="cb25-146"><a href="#cb25-146" aria-hidden="true" tabindex="-1"></a>plot_cm(cm_r18, <span class="ss">f"ResNet-18 – Accuracy </span><span class="sc">{</span>acc_r18<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb25-147"><a href="#cb25-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-148"><a href="#cb25-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-149"><a href="#cb25-149" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb25-150"><a href="#cb25-150" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. ResNet-50 (RGB images)</span></span>
<span id="cb25-151"><a href="#cb25-151" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb25-152"><a href="#cb25-152" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Evaluating ResNet-50 ==="</span>)</span>
<span id="cb25-153"><a href="#cb25-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-154"><a href="#cb25-154" aria-hidden="true" tabindex="-1"></a>res50 <span class="op">=</span> models.resnet50(weights<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb25-155"><a href="#cb25-155" aria-hidden="true" tabindex="-1"></a>res50.fc <span class="op">=</span> nn.Linear(res50.fc.in_features, <span class="dv">1</span>)</span>
<span id="cb25-156"><a href="#cb25-156" aria-hidden="true" tabindex="-1"></a>res50.load_state_dict(torch.load(<span class="st">"resnet50_pneumonia.pt"</span>, map_location<span class="op">=</span><span class="st">"cpu"</span>))</span>
<span id="cb25-157"><a href="#cb25-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-158"><a href="#cb25-158" aria-hidden="true" tabindex="-1"></a>acc_r50, cm_r50 <span class="op">=</span> evaluate_binary_model(res50, test_loader_rgb)</span>
<span id="cb25-159"><a href="#cb25-159" aria-hidden="true" tabindex="-1"></a>plot_cm(cm_r50, <span class="ss">f"ResNet-50 – Accuracy </span><span class="sc">{</span>acc_r50<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb25-160"><a href="#cb25-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-161"><a href="#cb25-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-162"><a href="#cb25-162" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb25-163"><a href="#cb25-163" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. EfficientNet-B0 (RGB images)</span></span>
<span id="cb25-164"><a href="#cb25-164" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb25-165"><a href="#cb25-165" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== Evaluating EfficientNet-B0 ==="</span>)</span>
<span id="cb25-166"><a href="#cb25-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-167"><a href="#cb25-167" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.models <span class="im">import</span> efficientnet_b0</span>
<span id="cb25-168"><a href="#cb25-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-169"><a href="#cb25-169" aria-hidden="true" tabindex="-1"></a>effnet <span class="op">=</span> efficientnet_b0(weights<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb25-170"><a href="#cb25-170" aria-hidden="true" tabindex="-1"></a>effnet.classifier[<span class="dv">1</span>] <span class="op">=</span> nn.Linear(effnet.classifier[<span class="dv">1</span>].in_features, <span class="dv">1</span>)</span>
<span id="cb25-171"><a href="#cb25-171" aria-hidden="true" tabindex="-1"></a>effnet.load_state_dict(torch.load(<span class="st">"efficientnet_pneumonia.pt"</span>, map_location<span class="op">=</span><span class="st">"cpu"</span>))</span>
<span id="cb25-172"><a href="#cb25-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-173"><a href="#cb25-173" aria-hidden="true" tabindex="-1"></a>acc_eff, cm_eff <span class="op">=</span> evaluate_binary_model(effnet, test_loader_rgb)</span>
<span id="cb25-174"><a href="#cb25-174" aria-hidden="true" tabindex="-1"></a>plot_cm(cm_eff, <span class="ss">f"EfficientNet-B0 – Accuracy </span><span class="sc">{</span>acc_eff<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb25-175"><a href="#cb25-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-176"><a href="#cb25-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-177"><a href="#cb25-177" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb25-178"><a href="#cb25-178" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. Summary</span></span>
<span id="cb25-179"><a href="#cb25-179" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb25-180"><a href="#cb25-180" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== FINAL ACCURACY COMPARISON ==="</span>)</span>
<span id="cb25-181"><a href="#cb25-181" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"TinyCNN         : </span><span class="sc">{</span>acc_tiny<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb25-182"><a href="#cb25-182" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ResNet-18       : </span><span class="sc">{</span>acc_r18<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb25-183"><a href="#cb25-183" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ResNet-50       : </span><span class="sc">{</span>acc_r50<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb25-184"><a href="#cb25-184" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"EfficientNet-B0 : </span><span class="sc">{</span>acc_eff<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="comparing-naive-approach-and-other-methods-fitted-in-python" class="level2" data-number="4.20">
<h2 data-number="4.20" class="anchored" data-anchor-id="comparing-naive-approach-and-other-methods-fitted-in-python"><span class="header-section-number">4.20</span> Comparing naive approach and other methods fitted in Python</h2>
<p>The evaluation on the PneumoniaMNIST test set (624 images) highlights how architectural choices shape performance, even when all models are trained on the same data and evaluated under identical conditions.</p>
<p>The TinyCNN, our minimal baseline, reaches an accuracy of 0.625. This is a reasonable result for a handcrafted network with only a few convolutional filters and no pretraining. Its errors tend to reflect exactly what we expect from a shallow architecture: limited ability to capture higher-order texture patterns and susceptibility to overfitting or underfitting depending on the training regime.</p>
<p>Performance improves dramatically once we step into pretrained architectures. ResNet-18 achieves 0.870, showing how even a moderately deep residual network can extract richer features from the grayscale radiographs after conversion to RGB. Residual blocks help optimization, and the pretrained ImageNet weights provide a strong initialization that transfers surprisingly well to medical images.</p>
<p>The anomaly in the comparison is ResNet-50, with an accuracy of 0.389. Under normal circumstances, ResNet-50 should outperform ResNet-18 or at least match it. When it does not, this usually indicates a training or preprocessing issue: an incompatible input size, an unbalanced learning rate, insufficient convergence time, or a mismatch between grayscale data and the expected RGB distribution. This makes the ResNet-50 result a useful teaching moment: deeper models are not automatically better, and heavier architectures can become extremely sensitive to input formatting and optimization choices.</p>
<p>EfficientNet-B0, which applies compound scaling rules to balance depth, width, and resolution, lands at 0.556. Its lower performance compared with ResNet-18 likely stems from the same preprocessing limitations: EfficientNet architectures expect standardized ImageNet-like color statistics, and medical images—even when converted to RGB—do not naturally match this distribution. Without extensive fine-tuning and augmentation, EfficientNet’s representational power is under-used.</p>
<p>Taken together, these results illustrate a core theme in applied deep learning: model architecture matters, but data handling and preprocessing matter just as much. Residual networks tend to be robust to imperfect input pipelines, while more complex or more delicately scaled models can fail quietly if the inputs are not fully aligned with their design assumptions.</p>
</section>
<section id="economic-and-regulatory-considerations-in-deploying-deep-learning-for-medical-imaging" class="level2" data-number="4.21">
<h2 data-number="4.21" class="anchored" data-anchor-id="economic-and-regulatory-considerations-in-deploying-deep-learning-for-medical-imaging"><span class="header-section-number">4.21</span> Economic and Regulatory Considerations in Deploying Deep Learning for Medical Imaging</h2>
<p>Although deep learning has become a central technique in medical image analysis, its practical adoption is shaped just as much by economic and regulatory forces as by algorithmic performance. Hospitals do not deploy models simply because they achieve high accuracy on a benchmark dataset; they adopt them only when the overall system is economically viable, clinically trustworthy, auditable, and aligned with health-care regulatory frameworks. Understanding these dimensions is essential when discussing real-world applications.</p>
<p>A major economic driver is the cost of image annotation. Deep learning models, particularly convolutional neural networks trained for classification, segmentation, or detection, require large volumes of labelled data. In medical imaging, each annotation is typically generated by a trained radiologist whose time is scarce and expensive. Complex tasks such as delineating tumour margins or identifying subtle patterns in chest radiographs may require multiple annotators for consensus or adjudication. As a result, the annotation pipeline itself can dominate the total cost of developing a clinically deployable model. Institutions often underestimate this aspect: acquiring the images is straightforward, but transforming them into structured training data is a slow, expertise-intensive process whose cost scales nonlinearly with task complexity.</p>
<p>Another economic element concerns computational resources. Even relatively small convolutional networks can require hundreds of thousands of parameters and many epochs of optimisation, and deeper architectures depend on access to modern GPUs or cloud-based accelerators. For research settings, training time is merely an inconvenience; for clinical deployment, however, the cost becomes recurrent. Models must often be retrained or recalibrated when imaging protocols change, when scanners are replaced, or when the patient population shifts. Maintaining the computational infrastructure for continuous validation and retraining can represent a substantial and ongoing operational expense.</p>
<p>These economic considerations intertwine with regulatory expectations. Medical AI systems, especially those intended for diagnostic support, are expected to meet standards of robustness, interpretability, and traceability comparable to traditional medical devices. Regulatory agencies increasingly require evidence that models perform consistently across demographic groups, imaging devices, and clinical sites. This often necessitates access to heterogeneous datasets, increasing the demand,and cost,for curated multi-centre image collections. Moreover, regulators expect manufacturers to document how training data were collected, labelled, and quality-controlled. Annotation protocols therefore become part of the regulatory dossier, not just an internal research artefact.</p>
<p>Another regulatory challenge is model drift. A deep learning system that performs well at launch may degrade over time as clinical practice evolves or as hospital equipment changes. The burden falls on developers and clinical sites to monitor model performance using well-designed post-market surveillance plans. This has both economic consequences, due to the need for ongoing data collection and evaluation, and ethical implications, since undetected drift could lead to harm.</p>
<p>On the ethical side, transparency remains central. Even though modern deep learning models can achieve impressive predictive accuracy, they are often criticised for their opacity. Hospitals and regulators increasingly expect mechanisms that help clinicians understand why a model reached a particular conclusion. Methods such as saliency maps or integrated gradients provide partial visibility into the model’s behaviour, but they also introduce their own uncertainties. Ethical deployment requires not only producing explanations but also communicating their limitations so that clinicians do not over-trust or misinterpret them.</p>
<p>Finally, any deployment in a clinical environment must address responsibility and liability. If an automated system misses a diagnosis or generates an incorrect recommendation, determining accountability is complex. Most regulatory frameworks emphasise that AI systems should remain assistive rather than autonomous, keeping the clinician in the decision loop. This human-in-the-loop model reduces liability risks but places additional demands on interface design, workflow integration, and training for clinical staff,all of which carry economic implications.</p>
<p>Taken together, these considerations illustrate why high accuracy alone does not guarantee real-world adoption of deep learning systems in medical imaging. The true cost of deploying such models extends far beyond the compute cycles used during training; it includes annotation labour, infrastructure maintenance, compliance with regulatory standards, and the ethical expectation that automated systems must enhance rather than undermine clinical safety and trust.</p>
</section>
<section id="another-example-of-usage-of-neural-networks-in-large-datasets" class="level2" data-number="4.22">
<h2 data-number="4.22" class="anchored" data-anchor-id="another-example-of-usage-of-neural-networks-in-large-datasets"><span class="header-section-number">4.22</span> Another example of usage of neural networks in large datasets</h2>
<p>Multi-response neural networks for simultaneous prediction of continuous and binary outcomes</p>
<p>As a final neural-network example in this book, we take advantage of the fact that these models are naturally suited for problems involving more than one outcome. In many biomedical datasets, it is common to encounter situations where different types of responses are recorded for the same individuals: a continuous biological measurement, a binary clinical event, a score, a biomarker panel. Instead of fitting separate predictive models for each target, neural networks allow us to build a single architecture that learns shared patterns across predictors and produces multiple outputs in parallel.</p>
<p>In our chemotherapy dataset we previously modelled the tumour-shrinkage percentage as a continuous response, and the “high response” indicator (defined as at least 30 percent reduction) as a binary response. Until now, these tasks were handled using two different models—one regression and one classification. However, both outcomes describe the same underlying clinical phenomenon, and both are shaped by the same set of explanatory variables such as patient demographics, baseline tumour size, treatment allocation, dose intensity, and the large gene-expression input space. Treating these tasks independently ignores the fact that they are statistically related. A multi-response neural network captures these connections directly.</p>
<p>The basic idea is to construct a shared backbone of dense layers that extracts a joint representation from all predictors. This backbone learns how the gene features interact with tumour characteristics, how treatment and dose influence response, and how patient-level covariates modulate these effects. From this common representation, the network branches into two specialised output heads: one with a sigmoid activation to estimate the probability of high response, and another with a linear activation to predict the continuous shrinkage percentage. The architecture is simple, but the learning dynamics are richer than in the single-task case. Gradients from both outcomes flow through the shared layers, guiding the representation toward features that are useful for both tasks, while the task-specific layers refine the predictions according to their respective loss functions.</p>
<p>The model can be trained in the familiar way, using the same train/validation/test split adopted in earlier chapters. Losses for the binary and continuous components are optimised jointly, and early-stopping or checkpointing behave exactly as in the single-output setting. After training, the model yields two predictions for each patient: a probability of high response and a continuous tumour-reduction estimate. These can be evaluated separately—using accuracy or AUC for the binary output, and RMSE or MAE for the continuous output—while being produced by a single, unified model.</p>
<p>Multi-response networks offer several benefits. Because they learn a single shared representation, they tend to generalise better when tasks are related, especially in moderate sample sizes. They also produce predictions that are more internally consistent: the binary head learns a natural thresholding of the continuous shrinkage prediction, and the continuous output benefits from the stabilising influence of the binary signal. Most importantly, they simplify the analytical pipeline. Instead of managing two models with different preprocessing steps, different hyperparameters, and different sets of saved files, we maintain a single coherent architecture.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 0. Configure Python environment (MUST BE FIRST!)</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the clean environment you created</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="fu">use_condaenv</span>(<span class="st">"r-keras-clean"</span>, <span class="at">required =</span> <span class="cn">TRUE</span>)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Disable RStudio’s buggy callback</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="fu">Sys.setenv</span>(<span class="at">KERAS_VIEW_METRICS =</span> <span class="st">"0"</span>)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Keras/TensorFlow AFTER selecting env</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Create models directory if needed</span></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">dir.exists</span>(<span class="st">"models"</span>)) <span class="fu">dir.create</span>(<span class="st">"models"</span>)</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Load dataset</span></span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>trial_ct <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"~/att_ai_ml/data/trial_ct_chemo_cont.rds"</span>)</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Select features (same as AULA 02 + AULA 03)</span></span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> trial_ct <span class="sc">%&gt;%</span> </span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>    high_response,</span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a>    response_percent,</span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a>    patient_age,</span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a>    tumor_grade,</span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a>    performance_score,</span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a>    baseline_tumor_mm,</span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a>    treatment,</span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a>    dose_intensity,</span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a>    <span class="fu">starts_with</span>(<span class="st">"gene_"</span>)</span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Prepare data</span></span>
<span id="cb26-49"><a href="#cb26-49" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-50"><a href="#cb26-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>treatment   <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">as.factor</span>(df<span class="sc">$</span>treatment))</span>
<span id="cb26-52"><a href="#cb26-52" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>tumor_grade <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">as.factor</span>(df<span class="sc">$</span>tumor_grade))</span>
<span id="cb26-53"><a href="#cb26-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-54"><a href="#cb26-54" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb26-55"><a href="#cb26-55" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(df)</span>
<span id="cb26-56"><a href="#cb26-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-57"><a href="#cb26-57" aria-hidden="true" tabindex="-1"></a>train_idx <span class="ot">&lt;-</span> <span class="fu">sample</span>(n, <span class="at">size =</span> <span class="fl">0.7</span> <span class="sc">*</span> n)</span>
<span id="cb26-58"><a href="#cb26-58" aria-hidden="true" tabindex="-1"></a>val_idx   <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">setdiff</span>(<span class="dv">1</span><span class="sc">:</span>n, train_idx), <span class="at">size =</span> <span class="fl">0.15</span> <span class="sc">*</span> n)</span>
<span id="cb26-59"><a href="#cb26-59" aria-hidden="true" tabindex="-1"></a>test_idx  <span class="ot">&lt;-</span> <span class="fu">setdiff</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="fu">c</span>(train_idx, val_idx))</span>
<span id="cb26-60"><a href="#cb26-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-61"><a href="#cb26-61" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> df[train_idx, ]</span>
<span id="cb26-62"><a href="#cb26-62" aria-hidden="true" tabindex="-1"></a>val   <span class="ot">&lt;-</span> df[val_idx, ]</span>
<span id="cb26-63"><a href="#cb26-63" aria-hidden="true" tabindex="-1"></a>test  <span class="ot">&lt;-</span> df[test_idx, ]</span>
<span id="cb26-64"><a href="#cb26-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-65"><a href="#cb26-65" aria-hidden="true" tabindex="-1"></a>x_train <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">select</span>(train, <span class="sc">-</span>high_response, <span class="sc">-</span>response_percent))</span>
<span id="cb26-66"><a href="#cb26-66" aria-hidden="true" tabindex="-1"></a>x_val   <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">select</span>(val,   <span class="sc">-</span>high_response, <span class="sc">-</span>response_percent))</span>
<span id="cb26-67"><a href="#cb26-67" aria-hidden="true" tabindex="-1"></a>x_test  <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">select</span>(test,  <span class="sc">-</span>high_response, <span class="sc">-</span>response_percent))</span>
<span id="cb26-68"><a href="#cb26-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-69"><a href="#cb26-69" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb26-70"><a href="#cb26-70" aria-hidden="true" tabindex="-1"></a>  <span class="at">high =</span> <span class="fu">as.matrix</span>(train<span class="sc">$</span>high_response),</span>
<span id="cb26-71"><a href="#cb26-71" aria-hidden="true" tabindex="-1"></a>  <span class="at">cont =</span> <span class="fu">as.matrix</span>(train<span class="sc">$</span>response_percent)</span>
<span id="cb26-72"><a href="#cb26-72" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-73"><a href="#cb26-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-74"><a href="#cb26-74" aria-hidden="true" tabindex="-1"></a>y_val <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb26-75"><a href="#cb26-75" aria-hidden="true" tabindex="-1"></a>  <span class="at">high =</span> <span class="fu">as.matrix</span>(val<span class="sc">$</span>high_response),</span>
<span id="cb26-76"><a href="#cb26-76" aria-hidden="true" tabindex="-1"></a>  <span class="at">cont =</span> <span class="fu">as.matrix</span>(val<span class="sc">$</span>response_percent)</span>
<span id="cb26-77"><a href="#cb26-77" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-78"><a href="#cb26-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-79"><a href="#cb26-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-80"><a href="#cb26-80" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-81"><a href="#cb26-81" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Build Multi-Output Neural Network</span></span>
<span id="cb26-82"><a href="#cb26-82" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-83"><a href="#cb26-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-84"><a href="#cb26-84" aria-hidden="true" tabindex="-1"></a>input_dim <span class="ot">&lt;-</span> <span class="fu">ncol</span>(x_train)</span>
<span id="cb26-85"><a href="#cb26-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-86"><a href="#cb26-86" aria-hidden="true" tabindex="-1"></a>input <span class="ot">&lt;-</span> <span class="fu">layer_input</span>(<span class="at">shape =</span> input_dim)</span>
<span id="cb26-87"><a href="#cb26-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-88"><a href="#cb26-88" aria-hidden="true" tabindex="-1"></a>shared <span class="ot">&lt;-</span> input <span class="sc">%&gt;%</span></span>
<span id="cb26-89"><a href="#cb26-89" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="dv">128</span>, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb26-90"><a href="#cb26-90" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb26-91"><a href="#cb26-91" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="dv">64</span>, <span class="at">activation =</span> <span class="st">"relu"</span>)</span>
<span id="cb26-92"><a href="#cb26-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-93"><a href="#cb26-93" aria-hidden="true" tabindex="-1"></a>out_high <span class="ot">&lt;-</span> shared <span class="sc">%&gt;%</span></span>
<span id="cb26-94"><a href="#cb26-94" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="dv">1</span>, <span class="at">activation =</span> <span class="st">"sigmoid"</span>, <span class="at">name =</span> <span class="st">"high"</span>)</span>
<span id="cb26-95"><a href="#cb26-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-96"><a href="#cb26-96" aria-hidden="true" tabindex="-1"></a>out_cont <span class="ot">&lt;-</span> shared <span class="sc">%&gt;%</span></span>
<span id="cb26-97"><a href="#cb26-97" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="dv">1</span>, <span class="at">activation =</span> <span class="st">"linear"</span>, <span class="at">name =</span> <span class="st">"cont"</span>)</span>
<span id="cb26-98"><a href="#cb26-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-99"><a href="#cb26-99" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model</span>(</span>
<span id="cb26-100"><a href="#cb26-100" aria-hidden="true" tabindex="-1"></a>  <span class="at">inputs  =</span> input,</span>
<span id="cb26-101"><a href="#cb26-101" aria-hidden="true" tabindex="-1"></a>  <span class="at">outputs =</span> <span class="fu">list</span>(<span class="at">high =</span> out_high, <span class="at">cont =</span> out_cont)</span>
<span id="cb26-102"><a href="#cb26-102" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-103"><a href="#cb26-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-104"><a href="#cb26-104" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span>
<span id="cb26-105"><a href="#cb26-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-106"><a href="#cb26-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-107"><a href="#cb26-107" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-108"><a href="#cb26-108" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Compile</span></span>
<span id="cb26-109"><a href="#cb26-109" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-110"><a href="#cb26-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-111"><a href="#cb26-111" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb26-112"><a href="#cb26-112" aria-hidden="true" tabindex="-1"></a>  <span class="at">optimizer =</span> <span class="st">"adam"</span>,</span>
<span id="cb26-113"><a href="#cb26-113" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss =</span> <span class="fu">list</span>(</span>
<span id="cb26-114"><a href="#cb26-114" aria-hidden="true" tabindex="-1"></a>    <span class="at">high =</span> <span class="st">"binary_crossentropy"</span>,</span>
<span id="cb26-115"><a href="#cb26-115" aria-hidden="true" tabindex="-1"></a>    <span class="at">cont =</span> <span class="st">"mse"</span></span>
<span id="cb26-116"><a href="#cb26-116" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb26-117"><a href="#cb26-117" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">list</span>(</span>
<span id="cb26-118"><a href="#cb26-118" aria-hidden="true" tabindex="-1"></a>    <span class="at">high =</span> <span class="fu">c</span>(<span class="st">"accuracy"</span>, <span class="st">"AUC"</span>),</span>
<span id="cb26-119"><a href="#cb26-119" aria-hidden="true" tabindex="-1"></a>    <span class="at">cont =</span> <span class="fu">c</span>(<span class="st">"mae"</span>, <span class="st">"mse"</span>)</span>
<span id="cb26-120"><a href="#cb26-120" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb26-121"><a href="#cb26-121" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-122"><a href="#cb26-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-123"><a href="#cb26-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-124"><a href="#cb26-124" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-125"><a href="#cb26-125" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Callbacks (save best model)</span></span>
<span id="cb26-126"><a href="#cb26-126" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-127"><a href="#cb26-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-128"><a href="#cb26-128" aria-hidden="true" tabindex="-1"></a>checkpoint_path <span class="ot">&lt;-</span> <span class="st">"models/multioutput_best.keras"</span></span>
<span id="cb26-129"><a href="#cb26-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-130"><a href="#cb26-130" aria-hidden="true" tabindex="-1"></a>callbacks_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb26-131"><a href="#cb26-131" aria-hidden="true" tabindex="-1"></a>  <span class="fu">callback_model_checkpoint</span>(</span>
<span id="cb26-132"><a href="#cb26-132" aria-hidden="true" tabindex="-1"></a>    <span class="at">filepath =</span> checkpoint_path,</span>
<span id="cb26-133"><a href="#cb26-133" aria-hidden="true" tabindex="-1"></a>    <span class="at">monitor =</span> <span class="st">"val_loss"</span>,</span>
<span id="cb26-134"><a href="#cb26-134" aria-hidden="true" tabindex="-1"></a>    <span class="at">save_best_only =</span> <span class="cn">TRUE</span>,</span>
<span id="cb26-135"><a href="#cb26-135" aria-hidden="true" tabindex="-1"></a>    <span class="at">mode =</span> <span class="st">"min"</span>,</span>
<span id="cb26-136"><a href="#cb26-136" aria-hidden="true" tabindex="-1"></a>    <span class="at">verbose =</span> <span class="dv">1</span></span>
<span id="cb26-137"><a href="#cb26-137" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb26-138"><a href="#cb26-138" aria-hidden="true" tabindex="-1"></a>  <span class="fu">callback_early_stopping</span>(</span>
<span id="cb26-139"><a href="#cb26-139" aria-hidden="true" tabindex="-1"></a>    <span class="at">monitor =</span> <span class="st">"val_loss"</span>,</span>
<span id="cb26-140"><a href="#cb26-140" aria-hidden="true" tabindex="-1"></a>    <span class="at">patience =</span> <span class="dv">6</span>,</span>
<span id="cb26-141"><a href="#cb26-141" aria-hidden="true" tabindex="-1"></a>    <span class="at">restore_best_weights =</span> <span class="cn">TRUE</span></span>
<span id="cb26-142"><a href="#cb26-142" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb26-143"><a href="#cb26-143" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-144"><a href="#cb26-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-145"><a href="#cb26-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-146"><a href="#cb26-146" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-147"><a href="#cb26-147" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. Train model</span></span>
<span id="cb26-148"><a href="#cb26-148" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-149"><a href="#cb26-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-150"><a href="#cb26-150" aria-hidden="true" tabindex="-1"></a>history <span class="ot">&lt;-</span> keras<span class="sc">::</span><span class="fu">fit</span>(</span>
<span id="cb26-151"><a href="#cb26-151" aria-hidden="true" tabindex="-1"></a>  <span class="at">object =</span> model,</span>
<span id="cb26-152"><a href="#cb26-152" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> x_train,</span>
<span id="cb26-153"><a href="#cb26-153" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> y_train,</span>
<span id="cb26-154"><a href="#cb26-154" aria-hidden="true" tabindex="-1"></a>  <span class="at">validation_data =</span> <span class="fu">list</span>(x_val, y_val),</span>
<span id="cb26-155"><a href="#cb26-155" aria-hidden="true" tabindex="-1"></a>  <span class="at">epochs =</span> <span class="dv">30</span>,</span>
<span id="cb26-156"><a href="#cb26-156" aria-hidden="true" tabindex="-1"></a>  <span class="at">batch_size =</span> <span class="dv">32</span>,</span>
<span id="cb26-157"><a href="#cb26-157" aria-hidden="true" tabindex="-1"></a>  <span class="at">callbacks =</span> callbacks_list,</span>
<span id="cb26-158"><a href="#cb26-158" aria-hidden="true" tabindex="-1"></a>  <span class="at">view_metrics =</span> <span class="cn">FALSE</span></span>
<span id="cb26-159"><a href="#cb26-159" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-160"><a href="#cb26-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-161"><a href="#cb26-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-162"><a href="#cb26-162" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(history)</span>
<span id="cb26-163"><a href="#cb26-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-164"><a href="#cb26-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-165"><a href="#cb26-165" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-166"><a href="#cb26-166" aria-hidden="true" tabindex="-1"></a><span class="co"># 8. Save final model (optional)</span></span>
<span id="cb26-167"><a href="#cb26-167" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-168"><a href="#cb26-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-169"><a href="#cb26-169" aria-hidden="true" tabindex="-1"></a><span class="fu">save_model_hdf5</span>(model, <span class="st">"models/multioutput_final.h5"</span>)</span>
<span id="cb26-170"><a href="#cb26-170" aria-hidden="true" tabindex="-1"></a><span class="fu">save_model_tf</span>(model, <span class="st">"models/multioutput_tf"</span>)</span>
<span id="cb26-171"><a href="#cb26-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-172"><a href="#cb26-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-173"><a href="#cb26-173" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-174"><a href="#cb26-174" aria-hidden="true" tabindex="-1"></a><span class="co"># 9. Evaluate</span></span>
<span id="cb26-175"><a href="#cb26-175" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-176"><a href="#cb26-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-177"><a href="#cb26-177" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">evaluate</span>(</span>
<span id="cb26-178"><a href="#cb26-178" aria-hidden="true" tabindex="-1"></a>  x_test,</span>
<span id="cb26-179"><a href="#cb26-179" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(</span>
<span id="cb26-180"><a href="#cb26-180" aria-hidden="true" tabindex="-1"></a>    <span class="at">high =</span> <span class="fu">as.matrix</span>(test<span class="sc">$</span>high_response),</span>
<span id="cb26-181"><a href="#cb26-181" aria-hidden="true" tabindex="-1"></a>    <span class="at">cont =</span> <span class="fu">as.matrix</span>(test<span class="sc">$</span>response_percent)</span>
<span id="cb26-182"><a href="#cb26-182" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb26-183"><a href="#cb26-183" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-184"><a href="#cb26-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-185"><a href="#cb26-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-186"><a href="#cb26-186" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-187"><a href="#cb26-187" aria-hidden="true" tabindex="-1"></a><span class="co"># 10. Predict</span></span>
<span id="cb26-188"><a href="#cb26-188" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb26-189"><a href="#cb26-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-190"><a href="#cb26-190" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> <span class="fu">predict</span>(x_test)</span>
<span id="cb26-191"><a href="#cb26-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-192"><a href="#cb26-192" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(pred<span class="sc">$</span>high)</span>
<span id="cb26-193"><a href="#cb26-193" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(pred<span class="sc">$</span>cont)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 11. Evaluation metrics (RMSE, Accuracy, AUC)</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ===================================================================</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)      <span class="co"># AUC</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(yardstick) <span class="co"># opcional (não será usado diretamente)</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract predictions (ensure numeric vectors)</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>pred_high <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(pred<span class="sc">$</span>high)      <span class="co"># probabilities (0-1)</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>pred_cont <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(pred<span class="sc">$</span>cont)      <span class="co"># continuous predictions</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="co"># True labels (ensure numeric)</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>true_high <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(test<span class="sc">$</span>high_response)</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>true_cont <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(test<span class="sc">$</span>response_percent)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="co"># RMSE (continuous response)</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>rmse_value <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((true_cont <span class="sc">-</span> pred_cont)<span class="sc">^</span><span class="dv">2</span>, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>rmse_value</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="co"># MAE (optional)</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>mae_value <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">abs</span>(true_cont <span class="sc">-</span> pred_cont), <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>mae_value</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------</span></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Accuracy (binary)</span></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------</span></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a><span class="co"># choose threshold = 0.5</span></span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>pred_class <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(pred_high <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>accuracy_value <span class="ot">&lt;-</span> <span class="fu">mean</span>(pred_class <span class="sc">==</span> true_high)</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>accuracy_value</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------</span></span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a><span class="co"># AUC (binary)</span></span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------</span></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>auc_value <span class="ot">&lt;-</span> pROC<span class="sc">::</span><span class="fu">auc</span>(true_high, pred_high)</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>auc_value</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="comparing-multi-response-neural-networks-with-single-response-models" class="level3" data-number="4.22.1">
<h3 data-number="4.22.1" class="anchored" data-anchor-id="comparing-multi-response-neural-networks-with-single-response-models"><span class="header-section-number">4.22.1</span> Comparing multi-response neural networks with single-response models</h3>
<p>The multi-output neural network fitted above marks a natural progression from the uni-response models developed earlier in this chapter. In the regression setting, models such as OLS, Ridge, Lasso, Elastic Net, Random Forest and XGBoost were trained to predict tumour-shrinkage percentage using the same clinical and gene-expression features. Each of these approaches captured different aspects of the structure in the data. OLS provided a transparent baseline but struggled in the presence of thousands of correlated gene predictors, producing relatively high test error. Ridge improved stability through L2 shrinkage but preserved all features, while Lasso and Elastic Net selectively removed irrelevant genes and delivered substantial gains in prediction accuracy. XGBoost ultimately provided the strongest performance for the continuous outcome, combining nonlinearity, structured regularisation, and residual fitting to recover predictive signal that linear methods could not capture.</p>
<p>A similar pattern appeared in the classification task. Logistic regression established a reasonably strong linear baseline, while tree-based models—especially pruned CART—captured nonlinear interactions. Random forest improved further by aggregating decorrelated trees, and XGBoost again achieved the highest accuracy and AUC among single-task models. These models, however, treat the two outcomes independently. The binary “high response” is simply a discretisation of the continuous shrinkage percentage, yet in the uni-response framework the models do not share information; each model is optimised separately, and any relationship between the two tasks is implicitly ignored.</p>
<p>The multi-response neural network addresses this limitation directly. Instead of decomposing the problem into two unrelated predictive tasks, the network learns a single shared representation across all features and uses that representation to drive both the continuous and binary outputs simultaneously. This coupling alters the learning dynamics in meaningful ways. Gradients from the binary classification head influence how the shared layers evolve, nudging the model toward features that sharpen the separation between responders and non-responders. At the same time, the continuous head contributes a richer and more fine-grained signal, capturing subtleties that cannot be conveyed by a binary indicator alone. During training, both objectives pull on the same backbone, and this shared pressure typically produces a more stable and more expressive set of learned features.</p>
<p>The performance metrics reflect this complementary structure. The multi-output network achieves an RMSE of roughly 3.40 and an MAE near 2.8 for the continuous task—a level of accuracy that is competitive with the linear baselines but below the performance of XGBoost, which remains the strongest single-task method for tumour-shrinkage prediction. The classification head, however, performs exceptionally well, reaching accuracy around 0.81 and an AUC close to 0.997, surpassing even the high-performing single-task XGBoost classifier. This combination is noteworthy: although the continuous prediction is not as precise as the best regression model, the classifier benefits substantially from the additional structure encoded in the shared representation, leading to superior discrimination.</p>
<p>This divergence in performance illustrates an important aspect of multi-task learning. The network does not aim to dominate each individual task when measured in isolation. Instead, it seeks a representation that jointly supports both tasks, balancing the signals coming from each output. The continuous regression task encourages nuanced modelling of the underlying biological variability, whereas the classification task emphasises separation between clinically defined responder groups. The network integrates both perspectives, and the resulting representation improves tasks that rely on relative distinctions, such as classification, sometimes at a modest cost to tasks requiring precise absolute prediction.</p>
<p>More broadly, the contrast between the single-task models and the multi-response network highlights the flexibility of neural architectures in settings with related outcomes. In the uni-response framework, each model operates within its own objective function, without awareness of the other task. In the multi-response framework, the network learns to reconcile multiple predictive goals at once, discovering common structure that traditional models cannot exploit. The result is a model that is not only compact—because the feature extraction occurs once rather than twice—but also more aligned with the biological reality of the data, where multiple outcomes arise from shared mechanisms.</p>
<p>From a teaching perspective, this example demonstrates how neural networks extend naturally from single-output prediction to richer forms of multi-task learning. Students can observe how performance changes across different modelling paradigms, how shared backbones redistribute predictive strength across tasks, and why multi-output strategies may outperform or underperform single-output methods depending on the metric considered. In practical biomedical applications, where continuous biomarkers, categorical endpoints, toxicity grades, and longitudinal measurements often coexist, these architectures become increasingly valuable. The multi-response network presented here offers a first glimpse into that broader modelling philosophy.</p>
</section>
<section id="summary" class="level3" data-number="4.22.2">
<h3 data-number="4.22.2" class="anchored" data-anchor-id="summary"><span class="header-section-number">4.22.2</span> Summary</h3>
<section id="continuous-outcome-tumour-shrinkage-percentage" class="level4" data-number="4.22.2.1">
<h4 data-number="4.22.2.1" class="anchored" data-anchor-id="continuous-outcome-tumour-shrinkage-percentage"><span class="header-section-number">4.22.2.1</span> Continuous outcome — tumour shrinkage percentage</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 29%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 56%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>MAE</th>
<th>RMSE</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>OLS</td>
<td>1.83</td>
<td>2.28</td>
<td>Linear baseline; unstable with high-dim gene features</td>
</tr>
<tr class="even">
<td>Ridge</td>
<td>1.78</td>
<td>2.22</td>
<td>L2 stabilisation; keeps all genes; moderate improvement</td>
</tr>
<tr class="odd">
<td>Lasso</td>
<td>1.53</td>
<td>1.92</td>
<td>Sparse model; selects informative genes; interpretable</td>
</tr>
<tr class="even">
<td>Elastic Net</td>
<td>1.53</td>
<td>1.92</td>
<td>Balanced L1/L2 shrinkage; good for correlated genes</td>
</tr>
<tr class="odd">
<td>Random Forest</td>
<td>5.54</td>
<td>6.80</td>
<td>Poor performance in ultra-high-dimensional settings</td>
</tr>
<tr class="even">
<td>XGBoost</td>
<td>1.34</td>
<td>1.79</td>
<td>Best single-task performance; captures nonlinearities</td>
</tr>
<tr class="odd">
<td>Multi-output Neural Network</td>
<td>2.80</td>
<td>3.40</td>
<td>Shared representation; regression head less precise</td>
</tr>
</tbody>
</table>
</section>
<section id="b-binary-outcome-high-response-30" class="level4" data-number="4.22.2.2">
<h4 data-number="4.22.2.2" class="anchored" data-anchor-id="b-binary-outcome-high-response-30"><span class="header-section-number">4.22.2.2</span> B) Binary outcome — high response (≥30%)</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 22%">
<col style="width: 8%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 6%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Accuracy</th>
<th>Sensitivity</th>
<th>Specificity</th>
<th>AUC</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Logistic Regression</td>
<td>0.907</td>
<td>0.897</td>
<td>0.913</td>
<td>0.939</td>
<td>Linear baseline; interpretable</td>
</tr>
<tr class="even">
<td>Pruned CART Tree</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>0.984</td>
<td>Simple nonlinear rules; moderate variance</td>
</tr>
<tr class="odd">
<td>Random Forest</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>0.996</td>
<td>Strong ensemble; robust low-variance learner</td>
</tr>
<tr class="even">
<td>XGBoost</td>
<td>—</td>
<td>—</td>
<td>—</td>
<td>0.998</td>
<td>Best single-task classifier; high accuracy</td>
</tr>
<tr class="odd">
<td>Multi-output Neural Network</td>
<td>0.807</td>
<td>—</td>
<td>—</td>
<td>0.997</td>
<td>Shared backbone; classification greatly benefits</td>
</tr>
</tbody>
</table>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-he2016resnet" class="csl-entry" role="listitem">
He, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. <span>“Deep Residual Learning for Image Recognition.”</span> In <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 770–78. <a href="https://arxiv.org/abs/1512.03385">https://arxiv.org/abs/1512.03385</a>.
</div>
<div id="ref-mooney2018chestxray" class="csl-entry" role="listitem">
Mooney, Paul Timothy. 2018. <span>“Chest x-Ray Images (Pneumonia).”</span> <a href="https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia" class="uri">https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia</a>.
</div>
<div id="ref-tan2019efficientnet" class="csl-entry" role="listitem">
Tan, Mingxing, and Quoc V. Le. 2019. <span>“EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.”</span> In <em>International Conference on Machine Learning (ICML)</em>, 6105–14. <a href="https://arxiv.org/abs/1905.11946">https://arxiv.org/abs/1905.11946</a>.
</div>
<div id="ref-medmnistv2" class="csl-entry" role="listitem">
Yang, Jiancheng, Rui Shi, Donglai Wei, Zequan Liu, Lin Zhao, Bilian Ke, Hanspeter Pfister, and Bingbing Ni. 2023. <span>“MedMNIST V2-a Large-Scale Lightweight Benchmark for 2D and 3D Biomedical Image Classification.”</span> <em>Scientific Data</em> 10 (1): 41.
</div>
<div id="ref-yang2021medmnist" class="csl-entry" role="listitem">
Yang, Jiancheng, Rui Shi, Donglai Wei, Lequan Yu, Zaiyi Zhang, Liwei Wang, Dong Ni, and Pheng-Ann Heng. 2021. <span>“MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for Medical Image Analysis.”</span> <em>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 14817–28. <a href="https://doi.org/10.1109/ICCV48922.2021.01454">https://doi.org/10.1109/ICCV48922.2021.01454</a>.
</div>
</div>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/danilosarti\.github\.io\/att_ml_ai_book");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./three_methods.html" class="pagination-link" aria-label="Supervised Learning: Tree Methods">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Supervised Learning: Tree Methods</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./introd_bayesian.html" class="pagination-link" aria-label="Introduction to Bayesian methods">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introduction to Bayesian methods</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>