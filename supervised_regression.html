<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Supervised Learning: Regression tasks – Introduction to Machine Learning and AI for Health and Sciences</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./three_methods.html" rel="next">
<link href="./introduction_AI.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="site_libs/quarto-diagram/mermaid.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./supervised_regression.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Supervised Learning: Regression tasks</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Machine Learning and AI for Health and Sciences</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction_AI.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to AI and Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./supervised_regression.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Supervised Learning: Regression tasks</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./three_methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Supervised Learning: Tree Methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./neural_networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Neural networks and deep learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introd_bayesian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introduction to Bayesian methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro_missing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Introduction to missing data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./high_dims.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">High Dimension Data Strategies</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpretable.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Interpretable AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./genai_foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">GenAI: Foundations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./genai_app.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">GenAI: Applications</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#setting-up-r" id="toc-setting-up-r" class="nav-link active" data-scroll-target="#setting-up-r"><span class="header-section-number">2.1</span> Setting up R</a></li>
  <li><a href="#recall" id="toc-recall" class="nav-link" data-scroll-target="#recall"><span class="header-section-number">2.2</span> Recall</a></li>
  <li><a href="#motivational-context-chemotherapy-clinical-trial-focus-on-variables-and-practical-interpretation" id="toc-motivational-context-chemotherapy-clinical-trial-focus-on-variables-and-practical-interpretation" class="nav-link" data-scroll-target="#motivational-context-chemotherapy-clinical-trial-focus-on-variables-and-practical-interpretation"><span class="header-section-number">2.3</span> Motivational context : chemotherapy clinical trial (focus on variables and practical interpretation)</a>
  <ul class="collapse">
  <li><a href="#what-is-measured-and-how-to-interpret-each-variable" id="toc-what-is-measured-and-how-to-interpret-each-variable" class="nav-link" data-scroll-target="#what-is-measured-and-how-to-interpret-each-variable"><span class="header-section-number">2.3.1</span> What is measured (and how to interpret each variable)</a></li>
  <li><a href="#experimental-objectives-and-practical-questions" id="toc-experimental-objectives-and-practical-questions" class="nav-link" data-scroll-target="#experimental-objectives-and-practical-questions"><span class="header-section-number">2.3.2</span> Experimental objectives and practical questions</a></li>
  </ul></li>
  <li><a href="#reading-the-dataset-into-our-environment" id="toc-reading-the-dataset-into-our-environment" class="nav-link" data-scroll-target="#reading-the-dataset-into-our-environment"><span class="header-section-number">2.4</span> Reading the dataset into our environment</a>
  <ul class="collapse">
  <li><a href="#notes-for-analysis" id="toc-notes-for-analysis" class="nav-link" data-scroll-target="#notes-for-analysis"><span class="header-section-number">2.4.1</span> Notes for analysis</a></li>
  </ul></li>
  <li><a href="#metrics-for-model-comparison" id="toc-metrics-for-model-comparison" class="nav-link" data-scroll-target="#metrics-for-model-comparison"><span class="header-section-number">2.5</span> Metrics for model comparison</a>
  <ul class="collapse">
  <li><a href="#error" id="toc-error" class="nav-link" data-scroll-target="#error"><span class="header-section-number">2.5.1</span> Error</a></li>
  <li><a href="#mean-absolute-error-mae" id="toc-mean-absolute-error-mae" class="nav-link" data-scroll-target="#mean-absolute-error-mae"><span class="header-section-number">2.5.2</span> Mean Absolute Error (MAE)</a></li>
  <li><a href="#mean-square-error-mse" id="toc-mean-square-error-mse" class="nav-link" data-scroll-target="#mean-square-error-mse"><span class="header-section-number">2.5.3</span> Mean Square Error (MSE)</a></li>
  <li><a href="#root-mean-square-error-rmse" id="toc-root-mean-square-error-rmse" class="nav-link" data-scroll-target="#root-mean-square-error-rmse"><span class="header-section-number">2.5.4</span> Root Mean Square Error (RMSE)</a></li>
  <li><a href="#compact-comparison" id="toc-compact-comparison" class="nav-link" data-scroll-target="#compact-comparison"><span class="header-section-number">2.5.5</span> Compact comparison</a></li>
  <li><a href="#visual-comparison-how-metrics-respond-to-error-size" id="toc-visual-comparison-how-metrics-respond-to-error-size" class="nav-link" data-scroll-target="#visual-comparison-how-metrics-respond-to-error-size"><span class="header-section-number">2.5.6</span> Visual comparison (how metrics respond to error size)</a></li>
  <li><a href="#worked-numeric-example-to-illustrate-how-to-calculate-errors-mae-mse-and-rmse-and-to-show-them-in-a-dataframe." id="toc-worked-numeric-example-to-illustrate-how-to-calculate-errors-mae-mse-and-rmse-and-to-show-them-in-a-dataframe." class="nav-link" data-scroll-target="#worked-numeric-example-to-illustrate-how-to-calculate-errors-mae-mse-and-rmse-and-to-show-them-in-a-dataframe."><span class="header-section-number">2.5.7</span> Worked numeric example to illustrate how to calculate errors, mae, mse and rmse and to show them in a dataframe.</a></li>
  <li><a href="#notes-for-analysis-1" id="toc-notes-for-analysis-1" class="nav-link" data-scroll-target="#notes-for-analysis-1"><span class="header-section-number">2.5.8</span> Notes for analysis</a></li>
  </ul></li>
  <li><a href="#fitting-simple-linear-regression-to-our-data" id="toc-fitting-simple-linear-regression-to-our-data" class="nav-link" data-scroll-target="#fitting-simple-linear-regression-to-our-data"><span class="header-section-number">2.6</span> Fitting simple linear regression to our data</a>
  <ul class="collapse">
  <li><a href="#model-assumptions-for-linear-regression" id="toc-model-assumptions-for-linear-regression" class="nav-link" data-scroll-target="#model-assumptions-for-linear-regression"><span class="header-section-number">2.6.1</span> Model assumptions for linear regression</a></li>
  </ul></li>
  <li><a href="#some-words-on-regularization" id="toc-some-words-on-regularization" class="nav-link" data-scroll-target="#some-words-on-regularization"><span class="header-section-number">2.7</span> Some words on regularization</a>
  <ul class="collapse">
  <li><a href="#ordinary-least-squares-sum-of-squares" id="toc-ordinary-least-squares-sum-of-squares" class="nav-link" data-scroll-target="#ordinary-least-squares-sum-of-squares"><span class="header-section-number">2.7.1</span> Ordinary Least Squares Sum of Squares</a></li>
  <li><a href="#ridge-regression-l2-regularization" id="toc-ridge-regression-l2-regularization" class="nav-link" data-scroll-target="#ridge-regression-l2-regularization"><span class="header-section-number">2.7.2</span> Ridge Regression (L2 regularization)</a></li>
  <li><a href="#lasso-regression-l1-regularization" id="toc-lasso-regression-l1-regularization" class="nav-link" data-scroll-target="#lasso-regression-l1-regularization"><span class="header-section-number">2.7.3</span> Lasso Regression (L1 regularization)</a></li>
  <li><a href="#elastic-net-combination-of-l1-and-l2" id="toc-elastic-net-combination-of-l1-and-l2" class="nav-link" data-scroll-target="#elastic-net-combination-of-l1-and-l2"><span class="header-section-number">2.7.4</span> Elastic Net (Combination of L1 and L2)</a></li>
  </ul></li>
  <li><a href="#hyperparameters" id="toc-hyperparameters" class="nav-link" data-scroll-target="#hyperparameters"><span class="header-section-number">2.8</span> Hyperparameters</a></li>
  <li><a href="#fitting-lasso-regression" id="toc-fitting-lasso-regression" class="nav-link" data-scroll-target="#fitting-lasso-regression"><span class="header-section-number">2.9</span> Fitting LASSO Regression</a></li>
  <li><a href="#fitting-ridge-regression" id="toc-fitting-ridge-regression" class="nav-link" data-scroll-target="#fitting-ridge-regression"><span class="header-section-number">2.10</span> Fitting Ridge Regression</a></li>
  <li><a href="#elastic-net" id="toc-elastic-net" class="nav-link" data-scroll-target="#elastic-net"><span class="header-section-number">2.11</span> Elastic Net</a></li>
  <li><a href="#comparing-ols-lasso-ridge-and-elastic-net-regression" id="toc-comparing-ols-lasso-ridge-and-elastic-net-regression" class="nav-link" data-scroll-target="#comparing-ols-lasso-ridge-and-elastic-net-regression"><span class="header-section-number">2.12</span> Comparing OLS, LASSO, Ridge and Elastic Net Regression</a></li>
  <li><a href="#organizing-our-study-questions" id="toc-organizing-our-study-questions" class="nav-link" data-scroll-target="#organizing-our-study-questions"><span class="header-section-number">2.13</span> Organizing our study questions</a>
  <ul class="collapse">
  <li><a href="#main-treatment-effect" id="toc-main-treatment-effect" class="nav-link" data-scroll-target="#main-treatment-effect"><span class="header-section-number">2.13.1</span> Main treatment effect</a></li>
  <li><a href="#clinical-covariates" id="toc-clinical-covariates" class="nav-link" data-scroll-target="#clinical-covariates"><span class="header-section-number">2.13.2</span> Clinical covariates:</a></li>
  <li><a href="#predictive-modeling" id="toc-predictive-modeling" class="nav-link" data-scroll-target="#predictive-modeling"><span class="header-section-number">2.13.3</span> Predictive modeling:</a></li>
  </ul></li>
  <li><a href="#logistic-regression" id="toc-logistic-regression" class="nav-link" data-scroll-target="#logistic-regression"><span class="header-section-number">2.14</span> Logistic Regression</a>
  <ul class="collapse">
  <li><a href="#understanding-roc-and-auc-through-examples" id="toc-understanding-roc-and-auc-through-examples" class="nav-link" data-scroll-target="#understanding-roc-and-auc-through-examples"><span class="header-section-number">2.14.1</span> Understanding ROC and AUC through examples</a></li>
  <li><a href="#logistic-regression-in-our-motivating-example" id="toc-logistic-regression-in-our-motivating-example" class="nav-link" data-scroll-target="#logistic-regression-in-our-motivating-example"><span class="header-section-number">2.14.2</span> Logistic Regression in our motivating example</a></li>
  <li><a href="#roc-and-auc" id="toc-roc-and-auc" class="nav-link" data-scroll-target="#roc-and-auc"><span class="header-section-number">2.14.3</span> ROC and AUC</a></li>
  <li><a href="#penalized-logistic-models-lasso-ridge-and-elastic-net" id="toc-penalized-logistic-models-lasso-ridge-and-elastic-net" class="nav-link" data-scroll-target="#penalized-logistic-models-lasso-ridge-and-elastic-net"><span class="header-section-number">2.14.4</span> Penalized logistic models: LASSO, Ridge, and Elastic Net</a></li>
  <li><a href="#fitting-logistic-regression-and-equivalent-lasso-ridgeand-elastic-net-approaches" id="toc-fitting-logistic-regression-and-equivalent-lasso-ridgeand-elastic-net-approaches" class="nav-link" data-scroll-target="#fitting-logistic-regression-and-equivalent-lasso-ridgeand-elastic-net-approaches"><span class="header-section-number">2.14.5</span> Fitting Logistic Regression and equivalent LASSO, RIDGE,and Elastic Net Approaches</a></li>
  <li><a href="#fitting-logistic-regression" id="toc-fitting-logistic-regression" class="nav-link" data-scroll-target="#fitting-logistic-regression"><span class="header-section-number">2.14.6</span> Fitting logistic regression</a></li>
  <li><a href="#understanding-log-odds-and-coefficient-interpretation-in-logistic-regression" id="toc-understanding-log-odds-and-coefficient-interpretation-in-logistic-regression" class="nav-link" data-scroll-target="#understanding-log-odds-and-coefficient-interpretation-in-logistic-regression"><span class="header-section-number">2.14.7</span> Understanding Log-Odds and Coefficient Interpretation in Logistic Regression</a></li>
  <li><a href="#compute-odds-ratios-from-the-fitted-model" id="toc-compute-odds-ratios-from-the-fitted-model" class="nav-link" data-scroll-target="#compute-odds-ratios-from-the-fitted-model"><span class="header-section-number">2.14.8</span> Compute Odds Ratios from the Fitted Model</a></li>
  <li><a href="#benchmarking-logistic-regression-with-lasso-ridge-and-elastic-net-counterparts" id="toc-benchmarking-logistic-regression-with-lasso-ridge-and-elastic-net-counterparts" class="nav-link" data-scroll-target="#benchmarking-logistic-regression-with-lasso-ridge-and-elastic-net-counterparts"><span class="header-section-number">2.14.9</span> Benchmarking Logistic regression with LASSO, RIDGE and ELASTIC NET counterparts</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Supervised Learning: Regression tasks</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="setting-up-r" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="setting-up-r"><span class="header-section-number">2.1</span> Setting up R</h2>
<p>Run this code in your R studio to make sure you have all the packages required installed!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Packages needed in this section</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>req_pkgs <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">"dplyr"</span>,      <span class="co"># data wrangling</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">"ggplot2"</span>,    <span class="co"># plotting</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">"tidyr"</span>,      <span class="co"># tidying</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">"readr"</span>,      <span class="co"># read/write csv</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">"tibble"</span>,     <span class="co"># tibbles/printing</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">"gridExtra"</span>,  <span class="co"># simple plot grids</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="st">"emmeans"</span>,    <span class="co"># adjusted means / contrasts</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="st">"effsize"</span>,     <span class="co"># effect sizes (Cohen's d, Cliff's delta)</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a> <span class="st">"DataExplorer"</span> ,<span class="co">#for missingness</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="st">"glmnet"</span>,</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a> <span class="st">"lmtest"</span> ,<span class="co"># for checking the </span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a> <span class="st">"pROC"</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a> )</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Install any that are missing</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>to_install <span class="ot">&lt;-</span> <span class="fu">setdiff</span>(req_pkgs, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>()))</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">length</span>(to_install) <span class="sc">&gt;</span> <span class="dv">0</span>) {</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">install.packages</span>(to_install, <span class="at">dependencies =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Load all (silently)</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="fu">invisible</span>(<span class="fu">lapply</span>(req_pkgs, require, <span class="at">character.only =</span> <span class="cn">TRUE</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="recall" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="recall"><span class="header-section-number">2.2</span> Recall</h2>
<p>In the introduction to AI section we learnt that models are representations that provide information for evidence based decisions. We also learnt that for each machine learning task we may have different models that use different learning algorithms, their performance needs to be evaluated. Comparison between such models is better performed via metrics. We also learnt the importance of cross validation to avoid variance, bias and over-fitting.</p>
<p>In this chapter with a motivational example we will start with the first kind of supervised learning technique, in which the models will learn from the relation between <strong>continuous or binary labels</strong> and explanatory features, this kind of task is named <code>regression</code>.</p>
<p>The introductory chapter defined a generic representation of a model using an equation:</p>
<p><span class="math display">\[Y=f(x1,x2,...,xn)+error\]</span> Where Y is attribute considered as label or response and x’s are the explanatory features and error is due to random process os measure errors usually notate as <span class="math inline">\(\epsilon\)</span></p>
<p>In this chapter we will give attention to a series of models in which this mathematical function f can be defined as:</p>
<p><span id="eq-linear"><span class="math display">\[Y= \mu + w1 * x1 +.... wn *xn+ \epsilon \tag{2.1}\]</span></span> Once all <span class="math inline">\(w_i\)</span>s are raised to the power of 1 we say this model is linear on the parameters or simply linear. <span class="math inline">\(\mu\)</span> and <span class="math inline">\(w_i\)</span>s are named parameters which we can estimate using different algorithms. The <span class="math inline">\(w_is\)</span> will be weighting the importance of feature <span class="math inline">\(x_i\)</span> when explaining Y.</p>
<p>In this chapter we will cover three main classes of models and respective algorithms to determine the parameters as follows:</p>
<ul>
<li>linear regression which parameters are estimated by least squares (which use the great idea of minimizing the errors between the real values and the predicted values)</li>
</ul>
<p>and two models that consider the notion of regularization for avoiding model complexity (using an idea of shrinkage - defined later)</p>
<ul>
<li>lasso regression, estimated via Least Absolute Shrinkage and Selection Operator (LASSO) and L1 regularization</li>
<li>Ridge regresion estimated via L2 norm.</li>
</ul>
<p>The idea of Lasso and Ridge regression is making the values of <span class="math inline">\(w_i\)</span>s smaller as possible (ridge) or zero (lasso) for the least important features.</p>
<p>Once we will be covering regression tasks we will also address the logistic regression model that is useful when we want to model a binary response variable Y= 0 or 1 using explanatory features.</p>
<p>After running a machine learning method and estimating the parameters, also named weights, we can rewrite it as:</p>
<p><span class="math display">\[\hat{Y}= \hat{\mu} + \hat{w_1}* x1 +....+\hat{w_n} *xn\]</span> The values with a hat are the estimatives for each parameter an assume values depending on the model fitted. The <span class="math inline">\(\hat{Y}\)</span> is named predicted value. It is the value returned by the modell fitted for a given set of explanatory features multiplied by the parameters estimated. We will further see the importance of this value for estimating measures of error and model performance.</p>
<p>Before seeing the details about regression models we will start by describing a particular case in which they will be applied.</p>
</section>
<section id="motivational-context-chemotherapy-clinical-trial-focus-on-variables-and-practical-interpretation" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="motivational-context-chemotherapy-clinical-trial-focus-on-variables-and-practical-interpretation"><span class="header-section-number">2.3</span> Motivational context : chemotherapy clinical trial (focus on variables and practical interpretation)</h2>
<p>As a motivational example we will use a <strong>simulated randomized clinical trial</strong> (1:1) ,a typical kind of experiment conducted to determine efficacy of drugs, in our case a chemoterapeutic one, including only <strong>patients with tumors</strong>.<br>
Half of the patients receive <strong>chemotherapy</strong> (<code>chemo</code>), and the other half do not (<code>no_chemo</code>). The practical goal is to evaluate whether patients treated with chemotherapy show <strong>greater tumor reduction</strong>, and to understand how <strong>gene expression</strong> and <strong>clinical characteristics</strong> influence this response.</p>
<section id="what-is-measured-and-how-to-interpret-each-variable" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="what-is-measured-and-how-to-interpret-each-variable"><span class="header-section-number">2.3.1</span> What is measured (and how to interpret each variable)</h3>
<p><strong>Unit of analysis:</strong> patients. We have 10000 thousand patients.</p>
<p><strong>Treatment</strong> - <code>treatment</code> (factor: <code>no_chemo</code>, <code>chemo</code>)<br>
Represents whether the patient received the chemotherapy.<br>
In regression models, the coefficient for <code>chemo</code> directly quantifies the <strong>average difference in tumor reduction</strong> compared with <code>no_chemo</code>.</p>
<p><strong>Dose</strong> - <code>dose_intensity</code> (continuous, ~0 for <code>no_chemo</code> and 0.8–1.1 for <code>chemo</code>)<br>
Measures how strong the chemotherapy was for treated patients.<br>
A positive regression coefficient means that <strong>higher dose intensity</strong> is associated with <strong>greater tumor shrinkage</strong>.</p>
<p><strong>Outcomes</strong> - <code>baseline_tumor_mm</code> (continuous, mm): tumor size before treatment<br>
- <code>post_tumor_mm</code> (continuous, mm): tumor size after treatment<br>
- <code>response_percent</code> (continuous, 0–100): percentage of tumor shrinkage,<br>
calculated as <code>100 × (baseline − post) / baseline</code><br>
→ Higher values mean <strong>better therapeutic response</strong>.<br>
- <code>high_response</code> (binary, 0/1): equal to 1 if <code>response_percent ≥ 30</code> (similar to RECIST clinical criteria) <span class="citation" data-cites="eisenhauer2009recist">Eisenhauer et al. (<a href="references.html#ref-eisenhauer2009recist" role="doc-biblioref">2009</a>)</span>.<br>
→ Used in logistic regression to model the <strong>probability of a strong response</strong>.</p>
<p>The RECIST (Response Evaluation Criteria in Solid Tumors) <span class="citation" data-cites="eisenhauer2009recist">Eisenhauer et al. (<a href="references.html#ref-eisenhauer2009recist" role="doc-biblioref">2009</a>)</span> are standardized, internationally accepted criteria used to assess tumor response to treatment in clinical trials. Developed by an international collaboration between the EORTC, NCI (U.S.), and NCIC (Canada), RECIST provides quantitative guidelines for measuring changes in tumor size using imaging (typically CT or MRI). Under RECIST version 1.1 (2009), tumor response is classified as: Complete Response (CR): Disappearance of all target lesions. Partial Response (PR): ≥30% decrease in the sum of the diameters of target lesions (relative to baseline). Progressive Disease (PD): ≥20% increase in the sum of diameters (plus an absolute increase of ≥5 mm) or appearance of new lesions. Stable Disease (SD): Neither sufficient shrinkage nor sufficient increase to qualify as PR or PD.</p>
<p><strong>Clinical profile</strong> - <code>patient_age</code> (continuous, years): older age may slightly reduce treatment effect.<br>
- <code>tumor_grade</code> (factor: <code>G1</code>, <code>G2</code>, <code>G3</code>): aggressiveness of the tumor.<br>
More aggressive tumors may respond more strongly because of higher proliferation rates.<br>
- <code>performance_score</code> (ordinal, 0–2): functional status (ECOG-like scale).<br>
Higher scores indicate poorer condition and typically <strong>lower treatment benefit</strong> due to toxicity or fragility.</p>
<p><strong>Gene expression (omics)</strong> - <code>gene_01</code> … <code>gene_20000</code> (continuous, log2-CPM normalized)<br>
Represent quantitative gene expression levels.<br>
Some genes were simulated as <strong>causal</strong> (directly affecting response),<br>
others as <strong>correlated</strong> (co-expressed with causal ones),<br>
and the rest as <strong>noise</strong>.</p>
<p>The above example will be considered the reality for which we want to create a model representation. In penalized models (LASSO or Ridge), we expect the <strong>causal and correlated genes</strong> to receive higher weights (non-zero coefficients), while noisy ones will shrink toward zero.</p>
</section>
<section id="experimental-objectives-and-practical-questions" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="experimental-objectives-and-practical-questions"><span class="header-section-number">2.3.2</span> Experimental objectives and practical questions</h3>
<ul>
<li><strong>Main question:</strong> Do patients treated with chemotherapy (<code>chemo</code>) show higher average tumor shrinkage than those who do not (<code>no_chemo</code>)?<br>
</li>
<li><strong>Clinical modulators:</strong> Do age, tumor grade, or performance score modify this effect?<br>
</li>
<li><strong>Molecular biomarkers:</strong> Which genes are associated with treatment response?<br>
</li>
<li><strong>Predictive modeling:</strong> Given a patient’s clinical and molecular profile, how well can we predict their tumor reduction and probability of high response?</li>
</ul>
</section>
</section>
<section id="reading-the-dataset-into-our-environment" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="reading-the-dataset-into-our-environment"><span class="header-section-number">2.4</span> Reading the dataset into our environment</h2>
<p>Lets read the dataset in our R studio and check its structure of the first 15 columns</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>trial_ct <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"~/att_ai_ml/data/trial_ct_chemo_cont.rds"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(trial_ct[, <span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>])   <span class="co"># peek</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   10000 obs. of  15 variables:
 $ patient_id       : chr  "P001" "P002" "P003" "P004" ...
 $ treatment        : Factor w/ 2 levels "no_chemo","chemo": 2 1 1 1 2 2 1 2 1 2 ...
 $ dose_intensity   : num  1.08 0 0 0 1.01 ...
 $ patient_age      : num  81 61 81 74 41 74 22 61 26 22 ...
 $ tumor_grade      : Factor w/ 3 levels "G1","G2","G3": 2 2 3 2 2 2 1 2 3 2 ...
 $ performance_score: int  1 1 1 0 1 1 2 0 1 0 ...
 $ baseline_tumor_mm: num  52.2 43.3 43.2 63.8 54.2 44.9 51.5 95.1 69.5 54.7 ...
 $ post_tumor_mm    : num  25.8 43.3 43.2 61.2 33.6 37 51.5 60.4 69.5 29.8 ...
 $ response_percent : num  50.6 0 0 4.2 38 17.5 0 36.5 0 45.6 ...
 $ high_response    : int  1 0 0 0 1 0 0 1 0 1 ...
 $ gene_01          : num  11.01 9.26 10.09 8.99 9.01 ...
 $ gene_02          : num  9.31 7.79 8.95 7.8 8.33 ...
 $ gene_03          : num  9.51 8.02 9.45 7.78 8.23 ...
 $ gene_04          : num  10.27 9.16 9.42 8.87 9.03 ...
 $ gene_05          : num  7.31 8.14 7.83 7.49 7.23 ...</code></pre>
</div>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(trial_ct)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   10000 obs. of  2010 variables:
 $ patient_id       : chr  "P001" "P002" "P003" "P004" ...
 $ treatment        : Factor w/ 2 levels "no_chemo","chemo": 2 1 1 1 2 2 1 2 1 2 ...
 $ dose_intensity   : num  1.08 0 0 0 1.01 ...
 $ patient_age      : num  81 61 81 74 41 74 22 61 26 22 ...
 $ tumor_grade      : Factor w/ 3 levels "G1","G2","G3": 2 2 3 2 2 2 1 2 3 2 ...
 $ performance_score: int  1 1 1 0 1 1 2 0 1 0 ...
 $ baseline_tumor_mm: num  52.2 43.3 43.2 63.8 54.2 44.9 51.5 95.1 69.5 54.7 ...
 $ post_tumor_mm    : num  25.8 43.3 43.2 61.2 33.6 37 51.5 60.4 69.5 29.8 ...
 $ response_percent : num  50.6 0 0 4.2 38 17.5 0 36.5 0 45.6 ...
 $ high_response    : int  1 0 0 0 1 0 0 1 0 1 ...
 $ gene_01          : num  11.01 9.26 10.09 8.99 9.01 ...
 $ gene_02          : num  9.31 7.79 8.95 7.8 8.33 ...
 $ gene_03          : num  9.51 8.02 9.45 7.78 8.23 ...
 $ gene_04          : num  10.27 9.16 9.42 8.87 9.03 ...
 $ gene_05          : num  7.31 8.14 7.83 7.49 7.23 ...
 $ gene_06          : num  7.44 7.22 7.41 6.28 7.01 ...
 $ gene_07          : num  9.13 9.24 8.96 8.23 7.96 ...
 $ gene_08          : num  1.722 -1.205 -1.211 -0.574 0.824 ...
 $ gene_09          : num  7.23 4.41 6.01 4.67 5.36 ...
 $ gene_10          : num  6.94 6.52 6.99 5.92 5.97 ...
 $ gene_11          : num  7.21 7 7.23 6.81 7.42 ...
 $ gene_12          : num  5.81 6.78 6.54 7.85 7.44 ...
 $ gene_13          : num  9.33 8.92 8.48 9.07 9.69 ...
 $ gene_14          : num  1.344 -1.212 -0.934 -0.639 1.07 ...
 $ gene_15          : num  8.79 9.1 8.95 9.33 9.22 ...
 $ gene_16          : num  6.79 7.36 7.23 7.74 7.94 ...
 $ gene_17          : num  7.31 5.58 6.11 5.7 6.14 ...
 $ gene_18          : num  7.56 7.82 7.98 7.97 7.66 ...
 $ gene_19          : num  1.504 -1.567 -1.099 -1.003 0.616 ...
 $ gene_20          : num  10.1 10.7 10.8 11.2 11.1 ...
 $ gene_21          : num  9.42 8.45 8.92 7.9 9.4 ...
 $ gene_22          : num  9.68 11.12 10.65 9.82 10.17 ...
 $ gene_23          : num  8.95 10.27 9.73 9.33 9.36 ...
 $ gene_24          : num  10.34 9.81 9.98 9.37 9.3 ...
 $ gene_25          : num  10.37 10 9.73 10.4 10.87 ...
 $ gene_26          : num  6.69 6.77 6.88 7.61 7.91 ...
 $ gene_27          : num  7.91 5.81 6.16 6.38 6.81 ...
 $ gene_28          : num  7.91 8.34 7.18 7.39 6.98 ...
 $ gene_29          : num  8.34 8.97 8.75 8.97 8.69 ...
 $ gene_30          : num  7.89 7.97 7.81 7.64 7.98 ...
 $ gene_31          : num  12.4 11.5 12.5 11 12 ...
 $ gene_32          : num  8.8 8.66 9.46 8.28 8.03 ...
 $ gene_33          : num  6.61 6.65 6.79 7.05 7.23 ...
 $ gene_34          : num  8.43 8.08 8.87 7.6 7.54 ...
 $ gene_35          : num  8.34 8.18 8.06 8.79 8.8 ...
 $ gene_36          : num  7.84 8.3 8.2 7.82 8.05 ...
 $ gene_37          : num  8.43 9.52 9.07 8.28 8.88 ...
 $ gene_38          : num  8.78 9.98 9.22 9.27 8.98 ...
 $ gene_39          : num  6.87 6.19 6.3 5.78 6.11 ...
 $ gene_40          : num  11.1 10.7 10.8 10.7 11.4 ...
 $ gene_41          : num  9.21 7.15 8.6 5.2 5.9 ...
 $ gene_42          : num  9 6.96 7.74 7.21 7.66 ...
 $ gene_43          : num  7.39 6.07 6.79 6.7 6.46 ...
 $ gene_44          : num  9.48 8.83 8.49 8.74 10.09 ...
 $ gene_45          : num  4.78 7.44 7.09 6.89 7.13 ...
 $ gene_46          : num  7.84 9.75 8.41 9.7 9.39 ...
 $ gene_47          : num  9.17 8.53 8.83 7.74 7.46 ...
 $ gene_48          : num  8.42 8.41 8.95 7.38 7.06 ...
 $ gene_49          : num  7.18 7.25 7.45 6.99 6.94 ...
 $ gene_50          : num  7.93 7.18 7.6 7.37 7.6 ...
 $ gene_51          : num  5.43 5.76 5.72 6.2 5.69 ...
 $ gene_52          : num  6.68 6.6 6.35 7.35 6.98 ...
 $ gene_53          : num  8.27 7.81 8.48 7.42 8.01 ...
 $ gene_54          : num  7.73 7.84 7.61 9.21 8.28 ...
 $ gene_55          : num  7.65 7.43 7.61 6.57 7.12 ...
 $ gene_56          : num  9.82 11.92 10.52 12.27 11.62 ...
 $ gene_57          : num  9.97 9.99 9.66 10.4 10.09 ...
 $ gene_58          : num  7.87 5.55 6.54 4.29 4.83 ...
 $ gene_59          : num  9.06 10.87 10.13 9.65 9.71 ...
 $ gene_60          : num  6.87 7.84 8.28 7.42 7.47 ...
 $ gene_61          : num  6.91 5.87 6.01 6.52 6.67 ...
 $ gene_62          : num  8.68 8.81 8.92 9.36 8.77 ...
 $ gene_63          : num  5.12 4.97 5.13 4.89 5.17 ...
 $ gene_64          : num  10.66 8.63 9.46 8.34 8.96 ...
 $ gene_65          : num  8.93 8.82 8.35 8.07 7.76 ...
 $ gene_66          : num  9.62 8.71 8.94 8.74 8.56 ...
 $ gene_67          : num  6.77 6.92 6.94 6.64 6.64 ...
 $ gene_68          : num  9.85 8.11 9.24 8.39 8.94 ...
 $ gene_69          : num  6.43 6.69 6.63 5.66 5.91 ...
 $ gene_70          : num  7.23 6.44 7.12 6.02 6.42 ...
 $ gene_71          : num  8.98 8.83 8.74 9.01 8.74 ...
 $ gene_72          : num  9.38 8.19 8.7 8.47 8.84 ...
 $ gene_73          : num  8.33 8.69 9.39 9.03 7.84 ...
 $ gene_74          : num  8.87 10.39 10.11 9.81 9.93 ...
 $ gene_75          : num  9.42 7.99 8.5 7.07 7.32 ...
 $ gene_76          : num  8.83 8.06 8.09 7.54 7.83 ...
 $ gene_77          : num  5.13 6.01 5.6 5.5 5.26 ...
 $ gene_78          : num  6.5 7.77 7.28 6.79 6.29 ...
 $ gene_79          : num  7.19 7.43 8.1 8.45 8.17 ...
 $ gene_80          : num  7.84 7.63 7.82 8.5 8.5 ...
 $ gene_81          : num  7.53 8.77 7.86 7.33 7.27 ...
 $ gene_82          : num  10.29 6.95 8.81 7.3 8.14 ...
 $ gene_83          : num  7.21 6.96 6.79 6.25 6.76 ...
 $ gene_84          : num  8.53 8.66 8.53 7.92 8.42 ...
 $ gene_85          : num  8.72 7.01 7.91 7.4 7.52 ...
 $ gene_86          : num  9.76 7.75 8.29 9.36 9.29 ...
 $ gene_87          : num  7.36 6.59 6.37 7.87 7.61 ...
 $ gene_88          : num  8.1 8.88 8.67 9.1 9.03 ...
 $ gene_89          : num  9.56 7.91 8.79 7.01 7.39 ...
  [list output truncated]</code></pre>
</div>
</div>
<section id="notes-for-analysis" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="notes-for-analysis"><span class="header-section-number">2.4.1</span> Notes for analysis</h3>
<p>An important first stage in any statistical or machine learning modelling is the exploratory analysis in which we use simple metrics of visualization tools to have a first glimpse of the dataset we have in hands. In this sense, we can use figures like histograms or boxplots that represent the distribution of continuous features and scatterplots that show the relationship between two continuous variables</p>
<p>For example, we can produce, Boxplots of <code>response_percent</code> by <code>treatment</code>, histograms of <code>response_percent</code>, and scatter plots of <code>baseline_tumor_mm</code> vs <code>post_tumor_mm</code>.</p>
<p>In summary, in our clinical trial example, <code>response_percent</code> is the main continuous endpoint, <code>high_response</code> is its clinically relevant binary version, <code>treatment</code> and <code>dose_intensity</code> define the intervention, and clinical plus gene variables explain <strong>for whom</strong> and <strong>how much</strong> the chemotherapy works.</p>
<p>Our objective in this chapter will be:</p>
<p>For linear regression:</p>
<ul>
<li><p>Report <strong>estimated coefficients</strong>, <strong>standard errors</strong>, <strong>t-values</strong>, and <strong>p-values</strong> for each predictor.</p></li>
<li><p>Evaluate <strong>model fit</strong> using metrics such as <strong>R²</strong> and <strong>adjusted R²</strong> to assess explained variability.</p></li>
<li><p>Check <strong>residual diagnostics</strong> (normality, homoscedasticity, and influential points) to verify model assumptions.</p></li>
<li><p>Plot <strong>fitted vs observed values</strong> and <strong>residual vs fitted</strong> to visually inspect model adequacy.</p></li>
</ul>
<!-- -->
<ul>
<li>Report <strong>confidence intervals</strong> for main effects (e.g., treatment effect, dose effect).</li>
</ul>
<!-- -->
<ul>
<li>Summarize <strong>predicted responses</strong> or <strong>marginal means</strong> by treatment group for interpretation and communication of clinical impact.</li>
</ul>
<!-- -->
<ul>
<li>For LASSO, Ridge and Elastic Net: use <strong>cross-validation</strong> to select the regularization parameter λ, and compare their stability and sparsity.<br>
</li>
<li>In your report, distinguish clearly between:
<ul>
<li><strong>Average treatment effects</strong> (<code>chemo</code> vs <code>no_chemo</code>)<br>
</li>
<li><strong>Modulating effects</strong> (genes, age, grade, performance, dose intensity)</li>
</ul></li>
<li>For logistic regression: report <strong>odds ratios</strong> with 95% CIs and evaluate <strong>ROC/AUC</strong> and <strong>calibration</strong>.</li>
</ul>
<p>We start usually by understanding if we have any bits of the data that may be missing. Using this code below we can see that our dataset is indeed complete. We will dedicate a section on missing data in future chapters. In the case of our motivational example we have a complete dataset.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>type_map <span class="ot">&lt;-</span> tibble<span class="sc">::</span><span class="fu">tibble</span>(</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">variable    =</span> <span class="fu">names</span>(trial_ct),</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">class       =</span> <span class="fu">sapply</span>(trial_ct, \(x) <span class="fu">paste</span>(<span class="fu">class</span>(x), <span class="at">collapse =</span> <span class="st">"/"</span>)),</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_missing   =</span> <span class="fu">sapply</span>(trial_ct, \(x) <span class="fu">sum</span>(<span class="fu">is.na</span>(x))),</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">pct_missing =</span> <span class="fu">round</span>(<span class="dv">100</span> <span class="sc">*</span> <span class="fu">sapply</span>(trial_ct, \(x) <span class="fu">mean</span>(<span class="fu">is.na</span>(x))), <span class="dv">2</span>),</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_unique    =</span> <span class="fu">sapply</span>(trial_ct, \(x) dplyr<span class="sc">::</span><span class="fu">n_distinct</span>(x)),</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">example     =</span> <span class="fu">sapply</span>(trial_ct, \(x) <span class="fu">paste</span>(utils<span class="sc">::</span><span class="fu">head</span>(<span class="fu">unique</span>(x), <span class="dv">3</span>), <span class="at">collapse =</span> <span class="st">", "</span>))</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>type_map <span class="sc">%&gt;%</span> <span class="fu">arrange</span>(<span class="fu">desc</span>(class))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2,010 × 6
   variable          class   n_missing pct_missing n_unique example             
   &lt;chr&gt;             &lt;chr&gt;       &lt;int&gt;       &lt;dbl&gt;    &lt;int&gt; &lt;chr&gt;               
 1 dose_intensity    numeric         0           0      302 1.085, 0, 1.007     
 2 patient_age       numeric         0           0       61 81, 61, 74          
 3 baseline_tumor_mm numeric         0           0      912 52.2, 43.3, 43.2    
 4 post_tumor_mm     numeric         0           0      869 25.8, 43.3, 43.2    
 5 response_percent  numeric         0           0      665 50.6, 0, 4.2        
 6 gene_01           numeric         0           0    10000 11.0132382528657, 9…
 7 gene_02           numeric         0           0    10000 9.31355524977464, 7…
 8 gene_03           numeric         0           0    10000 9.51020822690023, 8…
 9 gene_04           numeric         0           0    10000 10.272629360758, 9.…
10 gene_05           numeric         0           0    10000 7.30636755315514, 8…
# ℹ 2,000 more rows</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>p <span class="sc">+</span> <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="cn">NA</span>), <span class="at">expand =</span> <span class="fu">expansion</span>(<span class="at">mult =</span> <span class="fu">c</span>(<span class="dv">0</span>, .<span class="dv">05</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>An important first stage in any statistical or machine learning modelling is the exploratory analysis in which we use simple metrics of visualization tools to have a first glimpse of the dataset we have in hands. In this sense, we can use figures like histograms or boxplots that represent the distribution of continuous features and scatterplots that show the relationship between two continuous variables</p>
<p>For example, we can produce, Boxplots of <code>response_percent</code> by <code>treatment</code>, histograms of <code>response_percent</code>, and scatter plots of <code>baseline_tumor_mm</code> vs <code>post_tumor_mm</code>.</p>
<p>Below we have the codes to produce some exploratory graphics</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(trial_ct, <span class="fu">aes</span>(response_percent)) <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">30</span>) <span class="sc">+</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Response percent"</span>, <span class="at">y =</span> <span class="st">"Count"</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(trial_ct, <span class="fu">aes</span>(<span class="fu">factor</span>(high_response))) <span class="sc">+</span> <span class="fu">geom_bar</span>() <span class="sc">+</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"High response (≥30%)"</span>, <span class="at">y =</span> <span class="st">"Count"</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(trial_ct, <span class="fu">aes</span>(baseline_tumor_mm)) <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">30</span>) <span class="sc">+</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Baseline tumor (mm)"</span>, <span class="at">y =</span> <span class="st">"Count"</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>p4 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(trial_ct, <span class="fu">aes</span>(patient_age)) <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">30</span>) <span class="sc">+</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Age (years)"</span>, <span class="at">y =</span> <span class="st">"Count"</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(p1, p2, p3, p4, <span class="at">ncol =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/ea-hists-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Distributions of outcomes and key covariates.</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(trial_ct, <span class="fu">aes</span>(baseline_tumor_mm, post_tumor_mm, <span class="at">color =</span> treatment)) <span class="sc">+</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Baseline (mm)"</span>, <span class="at">y =</span> <span class="st">"Post (mm)"</span>, <span class="at">color =</span> <span class="st">"Treatment"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/ea-scatter-size-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Baseline vs post-treatment tumor size.</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(trial_ct, <span class="fu">aes</span>(treatment, response_percent)) <span class="sc">+</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Treatment"</span>, <span class="at">y =</span> <span class="st">"Response percent"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/ea-box-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Response by treatment.</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(trial_ct, <span class="fu">aes</span>(treatment, response_percent)) <span class="sc">+</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="at">outlier.shape =</span> <span class="cn">NA</span>, <span class="at">width =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_summary</span>(<span class="at">fun =</span> mean, <span class="at">geom =</span> <span class="st">"point"</span>, <span class="at">shape =</span> <span class="dv">23</span>, <span class="at">size =</span> <span class="dv">3</span>, <span class="at">fill =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_summary</span>(<span class="at">fun.data =</span> mean_cl_normal, <span class="at">geom =</span> <span class="st">"errorbar"</span>, <span class="at">width =</span> <span class="fl">0.15</span>) <span class="sc">+</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Treatment"</span>, <span class="at">y =</span> <span class="st">"Response percent"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/ea-box-plus-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Response by treatment with raw points and mean ± 95% CI.</figcaption>
</figure>
</div>
</div>
</div>
<p>We can also create some summaries of the dataset. For example we can summarise the reponse_percent feature in each of the groups.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>trial_ct <span class="sc">%&gt;%</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(treatment) <span class="sc">%&gt;%</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">n      =</span> <span class="fu">n</span>(),</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">mean   =</span> <span class="fu">mean</span>(response_percent),</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd     =</span> <span class="fu">sd</span>(response_percent),</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">median =</span> <span class="fu">median</span>(response_percent),</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">q1     =</span> <span class="fu">quantile</span>(response_percent, <span class="fl">0.25</span>),</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">q3     =</span> <span class="fu">quantile</span>(response_percent, <span class="fl">0.75</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 7
  treatment     n  mean    sd median    q1    q3
  &lt;fct&gt;     &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1 no_chemo   5078  4.83  6.81    0.8   0     8.2
2 chemo      4922 37.6  10.9    37.3  30.2  44.8</code></pre>
</div>
</div>
<p>We can also perform the calculation of some correlations to determine associations between features. Plotting this correlations is also important helping us to discuss the level of association between features. The code below calculates the correlation between the level of expression of each gene and the response_percent feature.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>gene_cols <span class="ot">&lt;-</span> <span class="fu">grep</span>(<span class="st">"^gene_"</span>, <span class="fu">names</span>(trial_ct), <span class="at">value =</span> <span class="cn">TRUE</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>cors <span class="ot">&lt;-</span> <span class="fu">sapply</span>(gene_cols, <span class="cf">function</span>(g) {</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">suppressWarnings</span>(<span class="fu">cor</span>(trial_ct[[g]], trial_ct<span class="sc">$</span>response_percent, <span class="at">use =</span> <span class="st">"pairwise.complete.obs"</span>))</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>top10_names <span class="ot">&lt;-</span> <span class="fu">names</span>(<span class="fu">sort</span>(<span class="fu">abs</span>(cors), <span class="at">decreasing =</span> <span class="cn">TRUE</span>))[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>top10_df <span class="ot">&lt;-</span> tibble<span class="sc">::</span><span class="fu">tibble</span>(</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">gene =</span> top10_names,</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">cor  =</span> <span class="fu">unname</span>(cors[top10_names])</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">gene =</span> <span class="fu">reorder</span>(gene, <span class="fu">abs</span>(cor)))</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(top10_df, <span class="fu">aes</span>(<span class="at">x =</span> gene, <span class="at">y =</span> cor, <span class="at">fill =</span> cor <span class="sc">&gt;</span> <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">fill =</span> <span class="st">"none"</span>) <span class="sc">+</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Gene"</span>, <span class="at">y =</span> <span class="st">"Correlation with response_percent"</span>,</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Top 10 genes by absolute correlation (signed)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/ea-gene-scan-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="metrics-for-model-comparison" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="metrics-for-model-comparison"><span class="header-section-number">2.5</span> Metrics for model comparison</h2>
<p>Before comparing regression methods, it is important to understand the metrics used to evaluate how well a model predicts continuous or binary outcomes. Each metric captures a different aspect of model performance: accuracy, precision, or calibration and helps interpret how reliable a model’s predictions are in practice.</p>
<p>We will focus on following main evaluation metrics commonly used for regression and classification.</p>
<section id="error" class="level3" data-number="2.5.1">
<h3 data-number="2.5.1" class="anchored" data-anchor-id="error"><span class="header-section-number">2.5.1</span> Error</h3>
<p>The <strong>error</strong> (also called the residual) for each observation is:</p>
<p><span class="math display">\[
e_i = \hat{y}_i - y_i
\]</span></p>
<p>Where: (y_i) is the observed (true) value for subject (i); (_i) is the model prediction; (e_i) is the individual prediction error. Positive error = overestimation; negative error = underestimation.</p>
<p>Example:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>(<span class="fu">library</span>(ggplot2))</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>df_err <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">patient   =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>,</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">observed  =</span> <span class="fu">c</span>(<span class="dv">20</span>, <span class="dv">35</span>, <span class="dv">40</span>, <span class="dv">60</span>, <span class="dv">75</span>, <span class="dv">85</span>, <span class="dv">95</span>, <span class="dv">100</span>),</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">predicted =</span> <span class="fu">c</span>(<span class="dv">18</span>, <span class="dv">38</span>, <span class="dv">37</span>, <span class="dv">65</span>, <span class="dv">71</span>, <span class="dv">89</span>, <span class="dv">92</span>, <span class="dv">102</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>df_err<span class="sc">$</span>error <span class="ot">&lt;-</span> df_err<span class="sc">$</span>predicted <span class="sc">-</span> df_err<span class="sc">$</span>observed</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_err, <span class="fu">aes</span>(<span class="at">x =</span> patient)) <span class="sc">+</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">y =</span> observed, <span class="at">yend =</span> predicted, <span class="at">xend =</span> patient), <span class="at">linewidth =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> observed), <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> predicted), <span class="at">size =</span> <span class="dv">2</span>, <span class="at">shape =</span> <span class="dv">17</span>) <span class="sc">+</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Patient"</span>, <span class="at">y =</span> <span class="st">"Response (%)"</span>,</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Prediction error (eᵢ = ŷᵢ − yᵢ): observed vs predicted"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-error-example" class="quarto-float quarto-figure quarto-figure-center anchored" width="672">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-error-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="supervised_regression_files/figure-html/fig-error-example-1.png" id="fig-error-example" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-error-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.1
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="mean-absolute-error-mae" class="level3" data-number="2.5.2">
<h3 data-number="2.5.2" class="anchored" data-anchor-id="mean-absolute-error-mae"><span class="header-section-number">2.5.2</span> Mean Absolute Error (MAE)</h3>
<p>The <strong>mean absolute error</strong> summarizes the average magnitude of errors, ignoring their sign:</p>
<p><span class="math display">\[
\mathrm{MAE} = \frac{1}{n}\sum_{i=1}^{n} |e_i| = \frac{1}{n}\sum_{i=1}^{n} |\hat{y}_i - y_i|
\]</span></p>
<p>MAE gives equal weight to all errors and is less sensitive to outliers than MSE/RMSE.<br>
Interpretation: if MAE = 4, predictions are, on average, 4 units away from the observed values (e.g., 4 percentage points of tumor reduction).</p>
</section>
<section id="mean-square-error-mse" class="level3" data-number="2.5.3">
<h3 data-number="2.5.3" class="anchored" data-anchor-id="mean-square-error-mse"><span class="header-section-number">2.5.3</span> Mean Square Error (MSE)</h3>
<p>The <strong>mean square error</strong> measures the average squared deviation:</p>
<p><span class="math display">\[
\mathrm{MSE} = \frac{1}{n}\sum_{i=1}^{n} (\hat{y}_i - y_i)^2 = \frac{1}{n}\sum_{i=1}^{n} e_i^2
\]</span></p>
<p>By squaring, large errors are penalized quadratically, making MSE more sensitive to occasional large misses useful when big mistakes are costly (for example, underestimating toxicity).</p>
</section>
<section id="root-mean-square-error-rmse" class="level3" data-number="2.5.4">
<h3 data-number="2.5.4" class="anchored" data-anchor-id="root-mean-square-error-rmse"><span class="header-section-number">2.5.4</span> Root Mean Square Error (RMSE)</h3>
<p>The <strong>root mean square error</strong> is the square root of MSE, returning to the original units of the outcome:</p>
<p><span class="math display">\[
\mathrm{RMSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n} (\hat{y}_i - y_i)^2} = \sqrt{\mathrm{MSE}}
\]</span></p>
<p>RMSE can be read as the typical magnitude (standard deviation) of prediction errors; it penalizes large errors more than MAE but remains directly interpretable.</p>
</section>
<section id="compact-comparison" class="level3" data-number="2.5.5">
<h3 data-number="2.5.5" class="anchored" data-anchor-id="compact-comparison"><span class="header-section-number">2.5.5</span> Compact comparison</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Metric</th>
<th style="text-align: left;">Formula</th>
<th style="text-align: center;">Penalizes large errors strongly?</th>
<th style="text-align: left;">Units</th>
<th style="text-align: left;">Practical meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Error</td>
<td style="text-align: left;"><span class="math inline">\((e_i = \hat{y}_i - y_i)\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: left;">Outcome units</td>
<td style="text-align: left;">Direction and size of each residual</td>
</tr>
<tr class="even">
<td style="text-align: left;">MAE</td>
<td style="text-align: left;"><span class="math inline">\((\frac{1}{n}\sum\)</span></td>
<td style="text-align: center;">e_i</td>
<td style="text-align: left;">)</td>
<td style="text-align: left;">No (linear)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">MSE</td>
<td style="text-align: left;"><span class="math inline">\((\frac{1}{n}\sum e_i^2)\)</span></td>
<td style="text-align: center;">Yes (quadratic)</td>
<td style="text-align: left;">Squared units</td>
<td style="text-align: left;">Average squared deviation</td>
</tr>
<tr class="even">
<td style="text-align: left;">RMSE</td>
<td style="text-align: left;"><span class="math inline">\((\sqrt{\frac{1}{n}\sum e_i^2})\)</span></td>
<td style="text-align: center;">Yes (quadratic)</td>
<td style="text-align: left;">Outcome units</td>
<td style="text-align: left;">Typical error size (√MSE)</td>
</tr>
</tbody>
</table>
</section>
<section id="visual-comparison-how-metrics-respond-to-error-size" class="level3" data-number="2.5.6">
<h3 data-number="2.5.6" class="anchored" data-anchor-id="visual-comparison-how-metrics-respond-to-error-size"><span class="header-section-number">2.5.6</span> Visual comparison (how metrics respond to error size)</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>(<span class="fu">library</span>(ggplot2))</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>(<span class="fu">library</span>(dplyr))</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>(<span class="fu">library</span>(tidyr))</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>df_metrics <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">error =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.25</span>)) <span class="sc">|&gt;</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">abs_error =</span> <span class="fu">abs</span>(error),</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">sq_error  =</span> error<span class="sc">^</span><span class="dv">2</span>,</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">rmse_unit =</span> <span class="fu">sqrt</span>(error<span class="sc">^</span><span class="dv">2</span>)  <span class="co"># same as abs(error), shown for relation to RMSE</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">cols =</span> <span class="fu">c</span>(abs_error, sq_error, rmse_unit),</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">names_to =</span> <span class="st">"metric"</span>, <span class="at">values_to =</span> <span class="st">"value"</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure fixed factor level order so colors map correctly</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">metric =</span> <span class="fu">factor</span>(metric, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"abs_error"</span>, <span class="st">"sq_error"</span>, <span class="st">"rmse_unit"</span>))</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>labs_map <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="at">abs_error =</span> <span class="st">"MAE contribution |e|"</span>,</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>              <span class="at">sq_error  =</span> <span class="st">"MSE contribution e²"</span>,</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>              <span class="at">rmse_unit =</span> <span class="st">"RMSE unit √(e²)"</span>)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Map colors by named vector to avoid level-order surprises</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>col_map <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">abs_error =</span> <span class="st">"#2f63c0"</span>,  <span class="co"># blue</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>  <span class="at">sq_error  =</span> <span class="st">"#ff7f50"</span>,  <span class="co"># orange/coral</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>  <span class="at">rmse_unit =</span> <span class="st">"#66c2a5"</span>   <span class="co"># green</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_metrics, <span class="fu">aes</span>(<span class="at">x =</span> error, <span class="at">y =</span> value, <span class="at">color =</span> metric, <span class="at">linetype =</span> metric)) <span class="sc">+</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> col_map, <span class="at">breaks =</span> <span class="fu">names</span>(labs_map), <span class="at">labels =</span> labs_map) <span class="sc">+</span></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_linetype_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="at">abs_error =</span> <span class="st">"solid"</span>, <span class="at">sq_error =</span> <span class="st">"dashed"</span>, <span class="at">rmse_unit =</span> <span class="st">"dotdash"</span>),</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>                        <span class="at">breaks =</span> <span class="fu">names</span>(labs_map), <span class="at">labels =</span> labs_map) <span class="sc">+</span></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Error (eᵢ = ŷᵢ − yᵢ)"</span>, <span class="at">y =</span> <span class="st">"Contribution"</span>, <span class="at">color =</span> <span class="cn">NULL</span>, <span class="at">linetype =</span> <span class="cn">NULL</span>,</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"How MAE, MSE, and RMSE respond to increasing error magnitude"</span>) <span class="sc">+</span></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-error-metrics-comparison" class="quarto-float quarto-figure quarto-figure-center anchored" width="672">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-error-metrics-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="supervised_regression_files/figure-html/fig-error-metrics-comparison-1.png" id="fig-error-metrics-comparison" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-error-metrics-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.2
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="worked-numeric-example-to-illustrate-how-to-calculate-errors-mae-mse-and-rmse-and-to-show-them-in-a-dataframe." class="level3" data-number="2.5.7">
<h3 data-number="2.5.7" class="anchored" data-anchor-id="worked-numeric-example-to-illustrate-how-to-calculate-errors-mae-mse-and-rmse-and-to-show-them-in-a-dataframe."><span class="header-section-number">2.5.7</span> Worked numeric example to illustrate how to calculate errors, mae, mse and rmse and to show them in a dataframe.</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>errors <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">2</span>, <span class="sc">-</span><span class="dv">3</span>, <span class="dv">8</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">4</span>, <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>mae  <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">abs</span>(errors))</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>mse  <span class="ot">&lt;-</span> <span class="fu">mean</span>(errors<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>rmse <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(mse)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">Metric =</span> <span class="fu">c</span>(<span class="st">"MAE"</span>,<span class="st">"MSE"</span>,<span class="st">"RMSE"</span>),</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">Value  =</span> <span class="fu">c</span>(mae, mse, rmse))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Metric     Value
1    MAE  3.250000
2    MSE 15.500000
3   RMSE  3.937004</code></pre>
</div>
</div>
</section>
<section id="notes-for-analysis-1" class="level3" data-number="2.5.8">
<h3 data-number="2.5.8" class="anchored" data-anchor-id="notes-for-analysis-1"><span class="header-section-number">2.5.8</span> Notes for analysis</h3>
<ul>
<li>Use MAE when you want an intuitive average error magnitude, robust to outliers.<br>
</li>
<li>Use RMSE when large errors must be penalized more heavily (and to keep units interpretable).<br>
</li>
<li>Report both MAE and RMSE for a balanced view; and residual diagnostics (validity).<br>
</li>
<li>Always compute metrics with cross-validation to estimate out-of-sample performance.</li>
</ul>
</section>
</section>
<section id="fitting-simple-linear-regression-to-our-data" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="fitting-simple-linear-regression-to-our-data"><span class="header-section-number">2.6</span> Fitting simple linear regression to our data</h2>
<p>We will fit the following model for our motivational example</p>
<p><span class="math display">\[Y = w_0 + w_1 X_1 + w_2 X_2 + \ldots + w_p X_p + \varepsilon\]</span></p>
<p>That in our particular case will be:</p>
<p><span class="math display">\[
\text{response\_percent} =
w_0 +
w_1(\text{compound\_dose}) +
w_2(\text{patient\_age}) +
w_3(\text{disease\_type}) +
w_4(\text{gene\_expression\_1}) +
w_5(\text{gene\_expression\_2}) +
\ldots +
w_{2000}(\text{gene\_expression\_2000}) +
\varepsilon
\]</span></p>
<p>The response variable (outcome) is response_percent the continuous measure of how much the tumor shrank (efficacy minus toxicity). The explanatory variables (predictors) include everything else in the dataset (.) except: patient_id (just an identifier) high_response (the binary version of the same outcome)</p>
<p>So our explanatory variables include: Gene expression features (gene_expression_1 … gene_expression_20) Clinical variables (compound_dose, patient_age, disease_type, etc.)</p>
<section id="model-assumptions-for-linear-regression" class="level3" data-number="2.6.1">
<h3 data-number="2.6.1" class="anchored" data-anchor-id="model-assumptions-for-linear-regression"><span class="header-section-number">2.6.1</span> Model assumptions for linear regression</h3>
<p>When we fit a linear regression model, we make several assumptions about the relationship between the predictors (X’s) and the outcome (Y). These assumptions matter because they affect whether the estimated coefficients and statistical tests can be trusted.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>plot_pair <span class="ot">&lt;-</span> <span class="cf">function</span>(data_good, data_bad, xvar, yvar, title_good, title_bad, xlabel, ylabel) {</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(data_good, <span class="fu">aes</span>({{xvar}}, {{yvar}})) <span class="sc">+</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">color =</span> <span class="st">"#2f63c0"</span>) <span class="sc">+</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"#ff7f50"</span>) <span class="sc">+</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="fu">labs</span>(<span class="at">title =</span> <span class="fu">paste</span>(<span class="st">"Correct:"</span>, title_good), <span class="at">x =</span> xlabel, <span class="at">y =</span> ylabel) <span class="sc">+</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_minimal</span>()</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(data_bad, <span class="fu">aes</span>({{xvar}}, {{yvar}})) <span class="sc">+</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">color =</span> <span class="st">"#2f63c0"</span>) <span class="sc">+</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">color =</span> <span class="st">"#ff7f50"</span>) <span class="sc">+</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="fu">labs</span>(<span class="at">title =</span> <span class="fu">paste</span>(<span class="st">"Incorrect:"</span>, title_bad), <span class="at">x =</span> xlabel, <span class="at">y =</span> ylabel) <span class="sc">+</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_minimal</span>()</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(p1, p2, <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol type="1">
<li>Linearity The relationship between each predictor and the outcome is assumed to be linear (on the model’s scale). If the true relationship is curved or nonlinear, the model may systematically under- or over-predict. Check: residuals vs fitted values or vs individual predictors should look patternless (no curves).</li>
</ol>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'
`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ol start="2" type="1">
<li>Independence of errors Residuals (errors) should be independent across observations. This is especially important for time series or clustered data (e.g., repeated measures, multi-center studies). Violation: autocorrelation or clustering inflates apparent precision.</li>
</ol>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/ols-assumptions-independence-better-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Independence of errors: correct (i.i.d.) vs incorrect (strong AR(1)). Each row shows residuals over order and their ACF.</figcaption>
</figure>
</div>
</div>
</div>
<ol start="3" type="1">
<li>Homoscedasticity (constant variance) The spread of residuals should be roughly constant across fitted values. If residuals fan out as predictions increase, that’s heteroskedasticity. Check: residuals vs fitted plot where spread should be similar across the range. Fixes: transform the outcome, use weighted least squares, or robust (HC) standard errors.</li>
</ol>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'
`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ol start="4" type="1">
<li>Normality of residuals Residuals should be approximately normally distributed around zero. This mainly underpins valid p-values and confidence intervals (less critical for pure prediction). Check: Q–Q plot or histogram of standardized residuals.</li>
</ol>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ol start="5" type="1">
<li>No multicollinearity Predictors should not be highly correlated with each other. Severe collinearity makes individual coefficient estimates unstable and hard to interpret. Check: Variance Inflation Factor (VIF); values &gt; 5 (or &gt; 10) suggest issues.</li>
</ol>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ol start="6" type="1">
<li>No influential outliers A few extreme points should not unduly determine the fit. Check: leverage and Cook’s distance; large Cook’s D indicates influential observations worth investigation.</li>
</ol>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'
`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>When these assumptions are reasonably met, Ordinary Least Squares (OLS) yields unbiased, efficient estimates and meaningful inference about how predictors relate to the response. In practice, diagnostic plots and simple tests help verify whether the model behaves well for the data at hand.</p>
<p>We know use the fabulous property of R to create functions and we will create three functions one to calculate <code>mae</code> and <code>rmse</code> which will be performed simultaneosly by the <code>eval_perform</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- 0) Metrics (MAE and RMSE) ----</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>mae  <span class="ot">&lt;-</span> <span class="cf">function</span>(y, yhat) <span class="fu">mean</span>(<span class="fu">abs</span>(y <span class="sc">-</span> yhat))</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>rmse <span class="ot">&lt;-</span> <span class="cf">function</span>(y, yhat) <span class="fu">sqrt</span>(<span class="fu">mean</span>((y <span class="sc">-</span> yhat)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- evaluation function (MAE and RMSE) ----</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>eval_perf <span class="ot">&lt;-</span> <span class="cf">function</span>(y_true, y_pred) {</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">MAE  =</span> <span class="fu">mae</span>(y_true, y_pred),</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">RMSE =</span> <span class="fu">rmse</span>(y_true, y_pred)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="co"># alias to avoid mistyping</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>eval_perform <span class="ot">&lt;-</span> eval_perf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>After that we split the data set into training (70%) of the data and test (30%) of the data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- 1) Train/Test split (70/30) ----</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>n  <span class="ot">&lt;-</span> <span class="fu">nrow</span>(trial_ct)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>ix <span class="ot">&lt;-</span> <span class="fu">sample.int</span>(n, <span class="at">size =</span> <span class="fu">floor</span>(<span class="fl">0.7</span> <span class="sc">*</span> n))</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> trial_ct[ix, , drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>test  <span class="ot">&lt;-</span> trial_ct[<span class="sc">-</span>ix, , drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then we can remove some unecessary columns from the dataset.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- 2) Remove columns that must NOT enter the model ----</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="co"># (ID and the binary endpoint; keeps the supervised task as a pure regression)</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>drop_cols <span class="ot">&lt;-</span> <span class="fu">intersect</span>(<span class="fu">names</span>(train), <span class="fu">c</span>(<span class="st">"patient_id"</span>, <span class="st">"high_response"</span>, <span class="st">"baseline_tumor_mm"</span>, <span class="st">"post_tumor_mm"</span>))</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>train_nopii <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(train, <span class="sc">-</span>dplyr<span class="sc">::</span><span class="fu">all_of</span>(drop_cols))</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>test_nopii  <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(test,  <span class="sc">-</span>dplyr<span class="sc">::</span><span class="fu">all_of</span>(drop_cols))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>After that we write some code that will inform to R the formula we want to consider for this model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Common formula for OLS (and to derive terms/dummies for glmnet)</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>f_ols <span class="ot">&lt;-</span> response_percent <span class="sc">~</span> .</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The function for fitting a linear regression in R is `lm` to which we indicate the formula of the model and the training dataset to be used for construction of the model. When we write&nbsp;<code>ols_tmp &lt;- lm(f_ols, data = train_nopii)</code>&nbsp;we are fitting a&nbsp;<strong>temporary</strong>&nbsp;linear model on the&nbsp;<strong>training</strong>set only to let R learn the exact design it should use: which predictors are in the model, how factors are encoded (their levels and the chosen reference), and the precise structure of any interactions or transformations. Extracting&nbsp;<code>ols_terms &lt;- terms(ols_tmp)</code>&nbsp;gives us that&nbsp;<strong>blueprint</strong>&nbsp;of the design matrix.</p>
<p>Later, when we build matrices with&nbsp;<code>model.matrix(ols_terms, data = train_nopii)</code>&nbsp;and&nbsp;<code>model.matrix(ols_terms, data = test_nopii)</code>, both training and test data are transformed&nbsp;<strong>with the same blueprint</strong>. This prevents issues like “factor has new levels in test,” mismatched dummy columns, or different column ordering problems that would otherwise break penalized models (e.g.,&nbsp;<code>glmnet</code>) or yield inconsistent predictions. In short: we lock in the training design so the test set is encoded&nbsp;<strong>identically</strong>, guaranteeing compatible inputs for all models.<br>
<br>
These steps are important because we will use the same training and testing datasets for running Lasso and Ridge Regression later using the <code>glmnet</code> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- 3) Capture TRAIN terms to ensure identical dummies in </span><span class="al">TEST</span><span class="co"> ----</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="co"># (fit a temporary OLS only to extract terms &amp; factor levels)</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>ols_tmp   <span class="ot">&lt;-</span> <span class="fu">lm</span>(f_ols, <span class="at">data =</span> train_nopii)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>ols_terms <span class="ot">&lt;-</span> <span class="fu">terms</span>(ols_tmp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Consistent design matrices for glmnet (no intercept column)</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>X_train <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(ols_terms, <span class="at">data =</span> train_nopii)[, <span class="sc">-</span><span class="dv">1</span>, drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>X_test  <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(ols_terms, <span class="at">data =</span> test_nopii)[,  <span class="sc">-</span><span class="dv">1</span>, drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> train_nopii<span class="sc">$</span>response_percent</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>y_test  <span class="ot">&lt;-</span> test_nopii<span class="sc">$</span>response_percent</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>No we proceed with the Ordinary Least Square regression analysis of our motivational example.</p>
<p>In this block of code we are fitting and evaluating our baseline Ordinary Least Squares (OLS) regression model. The command&nbsp;<code>mod_ols &lt;- lm(f_ols, data = train_nopii)</code>&nbsp;fits a linear regression model using only the training data. The formula&nbsp;<code>f_ols</code>&nbsp;expresses that we want to predict&nbsp;<code>response_percent</code>, our continuous measure of tumor shrinkage, using all available explanatory variables except for&nbsp;<code>patient_id</code>&nbsp;and&nbsp;<code>high_response</code>. These two variables are removed because one is simply an identifier and the other is a binary version of the same outcome, which would leak information into the model. The resulting object&nbsp;<code>mod_ols</code>&nbsp;contains the estimated coefficients and fitted values for the training set.</p>
<p>Next,&nbsp;<code>pred_ols_train &lt;- predict(mod_ols, newdata = train_nopii)</code>&nbsp;generates predictions for the same training data used to fit the model. These are the in-sample predictions. They allow us to evaluate how well the model fits the data it has already seen and to compute basic performance metrics such as the Mean Absolute Error (MAE) and the Root Mean Square Error (RMSE). They are also used to inspect diagnostic plots that reveal potential problems such as nonlinearity, heteroskedasticity, or outliers.</p>
<p>Finally,&nbsp;<code>pred_ols_test &lt;- predict(mod_ols, newdata = test_nopii)</code>&nbsp;applies the trained OLS model to the independent test dataset, which was not used during model fitting. These predictions are used to assess the model’s ability to generalize to new data. Comparing the errors on the training and test sets helps us detect whether the model is overfitting (performing much better on training data than on unseen data) or underfitting. Because we ensured earlier that categorical variables and factor levels are defined consistently between training and test sets, the prediction step runs smoothly without level-mismatch errors. In summary, this three-step process fits the baseline OLS model, obtains fitted and predicted values, and provides the foundation for fair comparison with the regularized models (LASSO and Ridge) that will be trained using the same data split.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- 4) OLS (uses data.frame; glmnet uses X/y) ----</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>mod_ols        <span class="ot">&lt;-</span> <span class="fu">lm</span>(f_ols, <span class="at">data =</span> train_nopii)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>pred_ols_train <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod_ols, <span class="at">newdata =</span> train_nopii)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>pred_ols_test  <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod_ols, <span class="at">newdata =</span> test_nopii)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In this block we prepare and run standard OLS diagnostics to check whether the linear model assumptions look reasonable. First, we load helper packages:&nbsp;<code>ggplot2</code>&nbsp;and&nbsp;<code>dplyr</code>&nbsp;for plotting and data handling,&nbsp;<code>lmtest</code>&nbsp;for tests like Breusch–Pagan and Durbin–Watson,&nbsp;<code>sandwich</code>&nbsp;for robust variance estimators, and&nbsp;<code>car</code>&nbsp;for tools such as variance inflation factors, component-plus-residual plots, and outlier checks. Then&nbsp;<code>par(mfrow = c(2, 2))</code>&nbsp;tells base R to arrange four plots in a 2 by 2 grid. The call&nbsp;<code>plot(mod_ols)</code>&nbsp;draws the default diagnostic panel for a fitted&nbsp;<code>lm</code>&nbsp;object: Residuals vs Fitted to look for nonlinearity or heteroskedasticity, Normal Q-Q to assess approximate normality of residuals, Scale–Location to check whether residual spread is roughly constant across fitted values, and Residuals vs Leverage with Cook’s distances to flag influential observations. Together these plots provide a quick visual screening of model adequacy before we proceed to formal tests or alternative specifications.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">#| label: ols-assumptions</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">#| message: false</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">#| warning: false</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">suppressPackageStartupMessages</span>({</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">library</span>(ggplot2)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">library</span>(dplyr)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">library</span>(lmtest)    <span class="co"># bptest(), dwtest()</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">library</span>(sandwich)  <span class="co"># robust (HC) variance estimators</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">library</span>(car)       <span class="co"># vif(), crPlots(), outlierTest()</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># --- 1) Quick base-R diagnostic panel (residuals, QQ, Scale-Location, Residuals vs Leverage)</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>op <span class="ot">&lt;-</span> <span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod_ols)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Residuals vs Fitted</strong><br>
This plot examines whether the residuals are centered around zero and whether there is any systematic pattern. The points here are scattered roughly around the horizontal line with no obvious curve, suggesting that the relationship between predictors and outcome is reasonably linear. There is a slight spread increase for larger fitted values, but it does not seem severe. Overall, the assumption of linearity and constant variance appears acceptable.</p>
<p><strong>Normal Q–Q</strong><br>
The Q–Q plot compares the standardized residuals to what would be expected if they followed a normal distribution. Most points lie very close to the diagonal reference line, except for a few at the extreme tails. This indicates that the residuals are approximately normal, with only minor deviations that are unlikely to affect inference materially.</p>
<p><strong>Scale–Location (Spread–Location)</strong><br>
This plot checks whether the variance of residuals is constant across the range of fitted values (homoskedasticity). The red line is nearly flat, and the spread of the points is fairly uniform across the x-axis. There is no strong funnel shape or trend, so the homoskedasticity assumption is reasonably satisfied.</p>
<p><strong>Residuals vs Leverage</strong><br>
This plot identifies influential cases observations that have both high leverage (unusual predictor combinations) and large residuals (poorly fitted). Most points lie within the Cook’s distance contours, indicating that no single case is exerting excessive influence on the fitted model. A few observations (such as those labeled 800 or 1920) have higher leverage, but they do not appear to distort the overall fit.</p>
<p><strong>Overall interpretation</strong><br>
Taken together, these diagnostics suggest that the OLS model fits the data adequately. The linearity, normality, and constant-variance assumptions hold reasonably well, and there are no major outliers or influential points. Minor departures at the extremes are typical in real data and do not undermine the general validity of the model.</p>
<p>The next block of code is a compact toolkit to inspect, interpret, and summarize your fitted OLS model from several complementary angles. It starts with&nbsp;<code>summary(mod_ols)</code>, which is the classic regression report. You get one row per coefficient with its estimate, standard error, t statistic, and p value, plus model-level diagnostics such as the residual standard error, R², adjusted R², and the F test for the null that all slopes are zero. Read this first to see direction and magnitude of effects and whether they are statistically distinguishable from zero after adjusting for the other variables in the model.</p>
<p>Next it calls&nbsp;<code>anova(mod_ols)</code>, which produces a Type I (sequential) ANOVA table. Here, sums of squares and p values are computed in the order that predictors enter the model. This is useful when there is a natural hierarchy or pre-specified entry order, but results can change if you reorder columns. If you need hypothesis tests that adjust for all other terms regardless of order (especially with factors and interactions), you would use&nbsp;<code>car::Anova(mod_ols, type = 3)</code>&nbsp;instead, which provides Type III tests.</p>
<p>Then it builds a tidy coefficient table with&nbsp;<code>broom::tidy(mod_ols, conf.int = TRUE)</code>. This converts the model output into a clean data frame that includes coefficient estimates, standard errors, test statistics, p values, and 95% confidence intervals. The code then arranges rows by p value and prints everything, which is convenient for scanning the most and least significant terms in a reproducible, table-friendly format.</p>
<p>The next step creates a quick ranking of “importance” by absolute t statistic. It removes the intercept, computes&nbsp;<code>abs_t = |t|</code>, sorts descending, and shows the top terms with their estimates, standard errors, test statistics, p values, and confidence intervals. This does not replace more formal variable-importance methods, but it is a fast way to see which coefficients have the strongest signal relative to their uncertainty within this linear specification.</p>
<p>Finally,&nbsp;<code>broom::glance(mod_ols)</code>&nbsp;provides a one-row summary of overall fit metrics. You get R² and adjusted R² (explanatory power with and without a penalty for model size),&nbsp;<code>sigma</code>&nbsp;(residual standard deviation), the model F statistic and its p value, and information criteria such as AIC and BIC for comparing alternative models on a goodness-of-fit versus complexity trade-off.</p>
<p>Taken together, these outputs let you check individual effects with uncertainty, evaluate sequential or fully adjusted hypothesis tests, order terms by signal-to-noise, and assess global model quality, all in tidy objects that can be reported or plotted downstream.</p>
<p>In the context of ANOVA,&nbsp;<strong>significance</strong>&nbsp;tells us whether a factor or variable has a real, measurable effect on the outcome, rather than the observed differences being just due to random chance.</p>
<p>The&nbsp;<strong>p-value</strong>&nbsp;is the probability of seeing a difference (or a larger one) in the data&nbsp;<strong>if, in reality, the factor had no effect at all</strong> that is, if the&nbsp;<strong>null hypothesis</strong>&nbsp;were true.</p>
<p>When a p-value is very small (typically below 0.05), it means such a difference would be very unlikely to appear by random chance, so we have&nbsp;<strong>evidence to reject the null hypothesis</strong>&nbsp;and conclude that the variable probably does influence the outcome.</p>
<p>In simple terms,&nbsp;<strong>ANOVA uses p-values as a decision criterion</strong>:</p>
<ul>
<li><p>A small p-value (below 0.05) → the group differences or predictor effects are statistically significant.</p></li>
<li><p>A large p-value (above 0.05) → the observed differences could easily occur by chance, so we do not have strong evidence of a real effect.</p></li>
</ul>
<p>Significance does not measure the size or importance of the effect it only measures how confident we are that an effect exists at all.</p>
<p>In a regression model, the&nbsp;<strong>parameters</strong>&nbsp;(often called coefficients or betas) quantify how much the response variable changes when a given predictor changes, while holding all other predictors constant.</p>
<p>Each parameter represents the&nbsp;<strong>direction</strong>&nbsp;and&nbsp;<strong>magnitude</strong>&nbsp;of that predictor’s influence on the outcome.</p>
<ul>
<li><p>A&nbsp;<strong>positive coefficient</strong>&nbsp;means that as the predictor increases, the response tends to increase as well.</p></li>
<li><p>A&nbsp;<strong>negative coefficient</strong>&nbsp;means that higher values of the predictor are associated with lower response values.</p></li>
<li><p>A coefficient close to&nbsp;<strong>zero</strong>&nbsp;suggests that the variable has little or no linear impact on the outcome, once the other predictors are accounted for.</p></li>
</ul>
<p>The&nbsp;<strong>absolute value</strong>&nbsp;of the coefficient reflects how strong the relationship is (how sensitive the response is to changes in that variable), but the units of measurement matter: one unit of a gene-expression score does not mean the same as one year of age, so direct comparisons of raw coefficients can be misleading.</p>
<p>When variables are standardized (converted to the same scale), larger absolute coefficients indicate stronger effects.</p>
<p>Statistical tests (t values and p values) assess whether each coefficient is significantly different from zero. A small p value suggests that the estimated effect is unlikely to be due to random noise, providing evidence that this predictor truly contributes to explaining variation in the response.</p>
<p>Following we have the code to generat the items above for our mod_ols object. We will avoid printing them here because each of the items would have thousands of elements… This brings to our minds the complexities of informing outputs of linear models with thousand of explanatories mantained by the model.</p>
<p>The next chunck of code evaluates how well the&nbsp;<strong>OLS model</strong>&nbsp;predicts the tumor response in both the training and test datasets, using two standard regression error metrics:&nbsp;<strong>MAE (Mean Absolute Error)</strong>&nbsp;and&nbsp;<strong>RMSE (Root Mean Square Error)</strong>.</p>
<p>The first two lines extract the true outcome values the observed tumor shrinkage percentages (<code>response_percent</code>) from the training and testing subsets. The next two blocks call the function&nbsp;<code>eval_perf()</code>, which calculates MAE and RMSE by comparing the true values (<code>y_train</code>&nbsp;or&nbsp;<code>y_test</code>) to the model’s predictions (<code>pred_ols_train</code>&nbsp;or&nbsp;<code>pred_ols_test</code>).</p>
<p>Recalling:</p>
<ul>
<li><p><strong>MAE</strong>&nbsp;represents the average absolute difference between predicted and observed values it tells how far off the predictions are, on average, in the same units as the outcome (percentage points of tumor reduction).</p></li>
<li><p><strong>RMSE</strong>&nbsp;is similar but gives more weight to large errors, making it more sensitive to occasional poor predictions.</p></li>
</ul>
<p>The results are stored in small tibbles and then combined into one table with the model name (“OLS”) and dataset origin (“Train” or “Test”).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Evaluate OLS with MAE and RMSE (using eval_perf) ---</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="co"># y vectors (true values)</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> train_nopii<span class="sc">$</span>response_percent</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>y_test  <span class="ot">&lt;-</span> test_nopii<span class="sc">$</span>response_percent</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>perf_ols_train <span class="ot">&lt;-</span> <span class="fu">eval_perf</span>(y_train, pred_ols_train) <span class="sc">|&gt;</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">Model =</span> <span class="st">"OLS"</span>, <span class="at">Dataset =</span> <span class="st">"Train"</span>)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>perf_ols_test <span class="ot">&lt;-</span> <span class="fu">eval_perf</span>(y_test, pred_ols_test) <span class="sc">|&gt;</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">Model =</span> <span class="st">"OLS"</span>, <span class="at">Dataset =</span> <span class="st">"Test"</span>)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Compact table</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>dplyr<span class="sc">::</span><span class="fu">bind_rows</span>(perf_ols_train, perf_ols_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 4
    MAE  RMSE Model Dataset
  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  
1  1.27  1.59 OLS   Train  
2  1.83  2.28 OLS   Test   </code></pre>
</div>
</div>
<p>The model fits the training data quite closely the average prediction error is about 1.3 percentage points. When applied to unseen data (the test set), the errors increase moderately to around 1.8–2.3 points.</p>
<p>This comparison is crucial because it shows&nbsp;<strong>generalization performance</strong>&nbsp; how well the model performs on new data that were not used for training.</p>
<ul>
<li><p>The&nbsp;<strong>training performance</strong>&nbsp;tells you how well the model explains patterns already seen during fitting.</p></li>
<li><p>The&nbsp;<strong>testing performance</strong>&nbsp;reveals how well those learned relationships extend to new, unseen patients.</p></li>
</ul>
<p>If the test errors are only slightly higher than the training errors, as in your case, it suggests a good model that generalizes reasonably well. If test errors were much larger, it would indicate&nbsp;<strong>overfitting</strong>&nbsp; the model memorized the training data instead of learning the general structure. Conversely, if both errors were high, it would point to&nbsp;<strong>underfitting</strong>, meaning the model is too simple to capture important relationships.</p>
<p>In summary, checking both training and test performance allows you to balance&nbsp;<strong>fit quality</strong>&nbsp;and&nbsp;<strong>predictive reliability</strong>, ensuring that the regression model is not only accurate on known data but also trustworthy for future predictions.<br>
<br>
As a general guideline, whenever you a see a work quoting a linear regression try to understand if the cross validation technique was applied. You will be amazed on how many works do not bother about these details.</p>
</section>
</section>
<section id="some-words-on-regularization" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="some-words-on-regularization"><span class="header-section-number">2.7</span> Some words on regularization</h2>
<p>We discussed in a previous section that the parameters of the model are important for interpretation because they tell us how each variable contributes to explaining the outcome. However, in practice, when we move from small, well-controlled models to modern biomedical or omics data, we often face a very different scenario: instead of a few predictors such as age, dose, or tumor grade, we may have&nbsp;<strong>hundreds or thousands of gene-expression features</strong>. In this context, interpreting the individual coefficients becomes nearly impossible. Many of them will be correlated with one another, some may carry redundant information, and others may simply represent random noise. Traditional linear regression tends to overfit in such high-dimensional settings it tries to give every variable a non-zero weight, which leads to unstable and unreliable estimates that generalize poorly to new data.</p>
<p>To address this, machine-learning methods introduce the idea of&nbsp;<strong>regularization</strong>, also called&nbsp;<strong>shrinkage</strong>. The key idea is to constrain or penalize the size of the coefficients so that the model prefers simpler explanations that still fit the data well. Regularization discourages the algorithm from assigning large weights to predictors that do not truly improve predictive accuracy.</p>
<p>Two common approaches are&nbsp;<strong>Ridge regression</strong>&nbsp;and&nbsp;<strong>LASSO regression</strong>. Ridge regression applies an&nbsp;<em>L2 penalty</em>, which shrinks all coefficients toward zero but rarely eliminates them completely; it is particularly effective when many predictors have small, distributed effects. LASSO regression, in contrast, uses an&nbsp;<em>L1 penalty</em>, which can shrink some coefficients exactly to zero, performing&nbsp;<strong>variable selection</strong>&nbsp;at the same time as estimation. This means that LASSO can automatically identify a smaller subset of genes or variables that carry most of the predictive signal, making the model both simpler and easier to interpret.### Ordinary Least Squares Sum of Squares</p>
<section id="ordinary-least-squares-sum-of-squares" class="level3" data-number="2.7.1">
<h3 data-number="2.7.1" class="anchored" data-anchor-id="ordinary-least-squares-sum-of-squares"><span class="header-section-number">2.7.1</span> Ordinary Least Squares Sum of Squares</h3>
<p>The <strong>residual sum of squares (RSS)</strong> minimized by Ordinary Least Squares (OLS) is:</p>
<p><span class="math display">\[
\text{RSS} = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
           = \sum_{i=1}^{n} (y_i - \mathbf{x}_i^\top \boldsymbol{\beta})^2
\]</span></p>
<p>OLS estimates the parameters ( ) that minimize this quadratic error term, without any regularization.</p>
</section>
<section id="ridge-regression-l2-regularization" class="level3" data-number="2.7.2">
<h3 data-number="2.7.2" class="anchored" data-anchor-id="ridge-regression-l2-regularization"><span class="header-section-number">2.7.2</span> Ridge Regression (L2 regularization)</h3>
<p>Ridge regression introduces a penalty proportional to the <strong>L2 norm</strong> of the coefficients:</p>
<p><span class="math display">\[
L_{\text{ridge}}(\boldsymbol{\beta})
= \sum_{i=1}^{n} (y_i - \mathbf{x}_i^\top \boldsymbol{\beta})^2
+ \lambda \sum_{j=1}^{p} \beta_j^2
\]</span></p>
<p>where ( ) controls the penalty strength.<br>
The L2 term shrinks all coefficients toward zero but does <strong>not</strong> set them exactly to zero.<br>
It is especially useful when predictors are highly correlated.</p>
</section>
<section id="lasso-regression-l1-regularization" class="level3" data-number="2.7.3">
<h3 data-number="2.7.3" class="anchored" data-anchor-id="lasso-regression-l1-regularization"><span class="header-section-number">2.7.3</span> Lasso Regression (L1 regularization)</h3>
<p>Lasso regression adds a penalty proportional to the <strong>L1 norm</strong> of the coefficients:</p>
<p><span class="math display">\[
L_{\text{lasso}}(\boldsymbol{\beta})
= \sum_{i=1}^{n} (y_i - \mathbf{x}_i^\top \boldsymbol{\beta})^2
+ \lambda \sum_{j=1}^{p} |\beta_j|
\]</span></p>
<p>The L1 term encourages <strong>sparsity</strong>, meaning that some coefficients are driven exactly to zero, effectively performing <strong>variable selection</strong>.</p>
</section>
<section id="elastic-net-combination-of-l1-and-l2" class="level3" data-number="2.7.4">
<h3 data-number="2.7.4" class="anchored" data-anchor-id="elastic-net-combination-of-l1-and-l2"><span class="header-section-number">2.7.4</span> Elastic Net (Combination of L1 and L2)</h3>
<p>The <strong>Elastic Net</strong> combines both Ridge (L2) and Lasso (L1) penalties:</p>
<p><span class="math display">\[
L_{\text{elastic-net}}(\boldsymbol{\beta})
= \sum_{i=1}^{n} (y_i - \mathbf{x}_i^\top \boldsymbol{\beta})^2
+ \lambda \left[
  \alpha \sum_{j=1}^{p} |\beta_j|
  + (1 - \alpha) \sum_{j=1}^{p} \beta_j^2
\right]
\]</span></p>
<p>where ( 0 ) controls the mix between L1 and L2 regularization:</p>
<ul>
<li>( = 1 ) → Lasso<br>
</li>
<li>( = 0 ) → Ridge<br>
</li>
<li>( 0 &lt; &lt; 1 ) → Elastic Net</li>
</ul>
<p>Elastic Net is particularly effective when there are many correlated predictors: it keeps Ridge’s stability while still allowing Lasso-style variable selection.</p>
<p>In the next section we will see how to perform these three types of regression: LASSO, ridge regression, and elastic net.</p>
</section>
</section>
<section id="hyperparameters" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="hyperparameters"><span class="header-section-number">2.8</span> Hyperparameters</h2>
<p>In <span class="math inline">\(Y=f\left(x_1, x_2, \ldots, x_n\right)+\)</span> error, the parameters are the quantities inside the function <span class="math inline">\(f\)</span> that the algorithm learns from the data to make <span class="math inline">\(f\)</span> fit well (e.g., the <span class="math inline">\(b\)</span> s in a linear model</p>
<p>A hyperparameter is a setting that controls how f is learned, not something learned directly from the data by the usual fitting step. Hyperparameters define the shape/complexity of the function class you allow and how aggressively you search within it. They live outside f, but they constrain and guide the learning of f.</p>
<p>Hyperparameters are configuration choices that control the learning process and the capacity of the model class used to approximate <span class="math inline">\(f(\cdot)\)</span>. They are not learned from the training loss directly; instead, they are selected (e.g., via cross-validation) to achieve good generalization, helping <span class="math inline">\(f\)</span> capture the signal in <span class="math inline">\(Y\)</span> without fitting the random error.</p>
<p>In supervised learning we seek to approximate an unknown function <span class="math inline">\(f(\cdot)\)</span> that links explanatory features <span class="math inline">\(x_1, x_2, \ldots, x_n\)</span> to a response variable <span class="math inline">\(Y\)</span> :</p>
<p><span class="math display">\[
Y=f\left(x_1, x_2, \ldots, x_n\right)+\varepsilon,
\]</span></p>
<p>where <span class="math inline">\(\varepsilon\)</span> captures random noise and unmeasured influences. When <span class="math inline">\(f(\cdot)\)</span> is assumed to be linear, the model becomes</p>
<p><span class="math display">\[
\hat{Y}=w_0+\beta_1 x_1+\cdots+w_p x_p,
\]</span></p>
<p>and the learning task consists of estimating the coefficients <span class="math inline">\(w_j\)</span> that minimize prediction error. These coefficients are the model parameters-they are learned directly from the data.</p>
<p>However, in modern regression we often introduce an additional layer of control: hyperparameters, which determine how the coefficients are estimated and how much flexibility the model is allowed to have. Hyperparameters live outside the function <span class="math inline">\(f(\cdot)\)</span>; they are not part of the fitted equation but instead regulate the learning process.</p>
<p>OLS and the absence of hyperparameters Ordinary Least Squares (OLS) minimizes the Residual Sum of Squares (RSS):</p>
<p><span class="math display">\[
\mathrm{RSS}=\sum_{i=1}^n\left(y_i-\hat{y}_i\right)^2 .
\]</span></p>
<p>The solution for <span class="math inline">\(\beta\)</span> has a closed analytical form and depends only on the data. Because there is no external control over model complexity, OLS has no hyperparameters. Its flexibility is entirely determined by the number of predictors in the model.</p>
<p>While OLS is unbiased and efficient under ideal conditions, it becomes unstable when predictors are highly correlated or when <span class="math inline">\(p\)</span> (number of variables) is large relative to <span class="math inline">\(n\)</span>.</p>
<p>To improve generalization, we introduce regularization-penalties that shrink coefficients toward zero and prevent overfitting.</p>
<p>Ridge, Lasso, and Elastic Net: controlling complexity with penalties Regularized regression modifies the OLS loss by adding a penalty term that constrains the magnitude of the coefficients.</p>
<p>The resulting objective function is</p>
<p><span class="math display">\[
\operatorname{RSS}_{\text {penalized }}=\sum_{i=1}^n\left(y_i-\hat{y}_i\right)^2+\lambda P(\boldsymbol{\beta}),
\]</span></p>
<p>where <span class="math inline">\(P(\boldsymbol{\beta})\)</span> defines the type of penalty and <span class="math inline">\(\lambda&gt;0\)</span> is a hyperparameter that controls its strength.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Model</th>
<th style="text-align: left;">Penalty term ( P() )</th>
<th style="text-align: left;">Main hyperparameters</th>
<th style="text-align: left;">Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Ridge</strong></td>
<td style="text-align: left;"><span class="math inline">\(( \sum_j \beta_j^2 )\)</span> (L2)</td>
<td style="text-align: left;"><span class="math inline">\(( \lambda )\)</span></td>
<td style="text-align: left;">Shrinks coefficients toward zero smoothly; keeps all variables.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Lasso</strong></td>
<td style="text-align: left;"><span class="math inline">\(( \sum_j |\beta_j| )\)</span> (L1)</td>
<td style="text-align: left;"><span class="math inline">\(( \lambda )\)</span></td>
<td style="text-align: left;">Shrinks some coefficients exactly to zero → automatic variable selection.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Elastic Net</strong></td>
<td style="text-align: left;"><span class="math inline">\(( (1-\alpha)\sum_j \beta_j^2/2 + \alpha\sum_j |\beta_j|)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(( \lambda, \alpha )\)</span></td>
<td style="text-align: left;">Combines both effects; balances stability (Ridge) and sparsity (Lasso).</td>
</tr>
</tbody>
</table>
<p>Understanding <span class="math inline">\(\lambda\)</span> : the bias-variance control knob The hyperparameter <span class="math inline">\(\lambda\)</span> regulates how strongly the model is penalized: - Small <span class="math inline">\(\lambda \rightarrow\)</span> minimal penalty, coefficients close to OLS estimates.</p>
<p>Low bias, high variance (risk of overfitting). - Large <span class="math inline">\(\lambda \rightarrow\)</span> heavy penalty, coefficients shrink strongly.</p>
<p>Higher bias, lower variance (risk of underfitting). Tuning <span class="math inline">\(\lambda\)</span> therefore manages the bias-variance trade-off, shaping the smoothness and generalization capacity of the learned function <span class="math inline">\(f(\cdot)\)</span>.</p>
<p>Tuning and selection Unlike <span class="math inline">\(\beta\)</span>, hyperparameters are not optimized by minimizing training error. If we simply fitted the model for the smallest training loss, <span class="math inline">\(\lambda\)</span> would always shrink toward zero (i.e., revert to OLS). Instead, hyperparameters are chosen using cross-validation, evaluating predictive error on unseen folds of the data.</p>
<p>The value of <span class="math inline">\(\lambda\)</span> (and <span class="math inline">\(\alpha\)</span> for Elastic Net) that minimizes cross-validated error-or is within one standard error of the minimum (the 1-SE rule)-is selected as optimal.</p>
<p>After choosing the hyperparameters, the model is re-trained on the full training set to estimate the final coefficients.</p>
<p>Conceptual summary - Parameters ( <span class="math inline">\(w_j\)</span> ) define the learned relationship <span class="math inline">\(f(\cdot)\)</span>. - Hyperparameters ( <span class="math inline">\(\lambda, \alpha\)</span> ) define how the relationship is learned-controlling model flexibility and generalization. - OLS has no hyperparameters; Ridge, Lasso, and Elastic Net introduce <span class="math inline">\(\lambda\)</span> (and possibly <span class="math inline">\(\alpha\)</span> ) to regularize the model. - Choosing good hyperparameters ensures <span class="math inline">\(f(X)\)</span> captures the true signal in <span class="math inline">\(Y\)</span> rather than noise in <span class="math inline">\(\varepsilon\)</span></p>
</section>
<section id="fitting-lasso-regression" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="fitting-lasso-regression"><span class="header-section-number">2.9</span> Fitting LASSO Regression</h2>
<p>The next block of code uses the glmnet package to fit a LASSO regression and to choose its penalty strength by cross-validation. The call to&nbsp;<code>cv.glmnet(X_train, y_train, alpha = 1, nfolds = 10)</code>&nbsp;runs a ten-fold cross-validation loop over a grid of lambda values with the L1 penalty, which defines the LASSO. For each lambda the algorithm fits the model on nine folds and evaluates prediction error on the remaining fold, then averages the error across folds. glmnet standardizes predictors internally by default, which is important so that the penalty treats variables on the same footing regardless of their scale.</p>
<p>From this cross-validation object we extract&nbsp;<code>lambda.min</code>, the lambda that achieved the smallest mean cross-validated error. We then refit the model on the full training set with&nbsp;<code>glmnet(X_train, y_train, alpha = 1, lambda = cv_lasso$lambda.min)</code>. This produces a single LASSO model whose coefficients have been shrunk toward zero. Many uninformative coefficients are exactly zero, which performs built-in variable selection and improves interpretability while controlling variance.</p>
<p>Finally, we obtain predicted values for both the training and the test sets with&nbsp;<code>predict(mod_lasso, newx = X_train)</code>and&nbsp;<code>predict(mod_lasso, newx = X_test)</code>. These predictions allow us to compute performance metrics such as MAE and RMSE on data used to fit the model and on held-out data. Evaluating both is useful because the training metrics show how well the model can fit observed samples, while the test metrics indicate how well the model generalizes to new patients. Some analysts also report&nbsp;<code>lambda.1se</code>, which is the largest lambda within one standard error of the minimum error. That choice usually yields a sparser model with similar predictive accuracy and can be attractive when parsimony is a priority.</p>
<p>The next three chunks’ outputs show the fitted&nbsp;<strong>LASSO regression model</strong>&nbsp;and how it performs on the training and testing data. Unlike ordinary least squares, which gives every variable a non-zero coefficient, LASSO includes a penalty that forces many coefficients exactly to zero. The result is a simpler model that keeps only the most informative predictors.</p>
<p>The table of coefficients lists all variables that remain active after regularization. The first line, the&nbsp;<strong>intercept (27.99)</strong>, represents the baseline predicted tumor response (in percentage points) when all other predictors are at their reference or zero levels. The next few coefficients correspond to clinical factors. For instance,&nbsp;<code>treatmentchemo = 3.11</code>&nbsp;means that, on average and holding other variables constant, patients who received chemotherapy are predicted to have about three percentage points higher tumor shrinkage than those who did not. The coefficient for&nbsp;<code>dose_intensity = 3.34</code>&nbsp;indicates that stronger chemotherapy doses are associated with greater reductions in tumor size. Age has a small positive coefficient, suggesting a very mild increase in response with age, while the negative sign for&nbsp;<code>performance_score</code>&nbsp;shows that patients with worse functional status tend to respond less effectively to treatment. Tumor grade also has a clear effect, with higher grades showing larger coefficients and therefore stronger responses.</p>
<p>After the clinical covariates, the list continues with gene expression variables. Only a fraction of the hundreds of available genes appear, meaning that the LASSO has automatically selected those with the most predictive value. For example,&nbsp;<code>gene_08</code>,&nbsp;<code>gene_14</code>, and&nbsp;<code>gene_19</code>&nbsp;have relatively large positive coefficients (around five), identifying them as strong predictors of greater tumor reduction. In contrast, genes such as&nbsp;<code>gene_05</code>&nbsp;or&nbsp;<code>gene_1778</code>&nbsp;have large negative coefficients, implying that higher expression of these genes is associated with poorer therapeutic response. The many small coefficients near zero reflect genes with weak or marginal contributions that the model nonetheless retained under the chosen regularization strength. In situation where the number of features to be considered is giant LASSO returns a smaller reasonable amount of variables compared with the original number, making interpretation of the model more facilitated.</p>
<p>The last section of the output shows model performance using the&nbsp;<code>eval_perf()</code>&nbsp;function. The&nbsp;<strong>MAE</strong>&nbsp;(mean absolute error) and&nbsp;<strong>RMSE</strong>&nbsp;(root mean square error) values quantify how far, on average, the predictions are from the true tumor responses. The training errors are MAE = 1.49 and RMSE = 1.87, while the test errors are MAE = 1.57 and RMSE = 1.96. The similarity of these values suggests that the model generalizes well: it fits the training data closely but not excessively and maintains similar predictive accuracy on unseen test patients.</p>
<p>Overall, this LASSO fit yields a parsimonious model that identifies a handful of relevant clinical variables and a limited subset of genes that together explain much of the variation in tumor response. The regularization penalty has successfully balanced interpretability and predictive performance by shrinking or eliminating irrelevant coefficients while preserving the key biological and clinical signals in the data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- 5) LASSO (alpha = 1) with CV to choose lambda ----</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: glmnet standardizes features by default (standardize = TRUE).</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>cv_lasso  <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X_train, y_train, <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">nfolds =</span> <span class="dv">10</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>mod_lasso <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X_train, y_train, <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">lambda =</span> cv_lasso<span class="sc">$</span>lambda.min)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>pred_lasso_train <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(mod_lasso, <span class="at">newx =</span> X_train))</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>pred_lasso_test  <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(mod_lasso, <span class="at">newx =</span> X_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Nonzero coefficients selected by LASSO</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>coef_lasso <span class="ot">&lt;-</span> <span class="fu">coef</span>(mod_lasso)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>nz <span class="ot">&lt;-</span> <span class="fu">which</span>(coef_lasso <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="fu">as.matrix</span>(coef_lasso[nz, , <span class="at">drop =</span> <span class="cn">FALSE</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                             s0
(Intercept)       27.9894094231
treatmentchemo     3.1094150609
dose_intensity     3.3438592381
patient_age        0.0132882299
tumor_gradeG2      0.1316015652
tumor_gradeG3      0.5547952038
performance_score -0.2943083530
gene_01            0.8494564076
gene_05           -2.7310539064
gene_08            5.1436742116
gene_12            0.4288133459
gene_14            5.1013463595
gene_19            5.1746627223
gene_27            0.0180460908
gene_30           -0.0863467996
gene_32           -0.0361982838
gene_104           0.0211677652
gene_116          -0.0218406711
gene_117          -0.0052744538
gene_123           0.0056347167
gene_146           0.0498361359
gene_157          -0.0279668435
gene_165          -0.0080882163
gene_187           0.0222580351
gene_210          -0.0036941301
gene_221           0.0096723727
gene_225           0.0644057360
gene_242           0.0684388670
gene_253          -0.0077187155
gene_287           0.0498245130
gene_311          -0.0424858360
gene_359          -0.0232784490
gene_373          -0.0568150918
gene_416           0.0008864799
gene_459           0.0443358981
gene_484           0.0190060279
gene_490           0.0172107152
gene_503          -0.0079158529
gene_514          -0.0248283328
gene_535          -0.0577584654
gene_537          -0.0072821908
gene_550           0.0375150155
gene_576          -0.0704458018
gene_600           0.0158202468
gene_605           0.0196117982
gene_627           0.0103392261
gene_648          -0.0034662864
gene_669           0.0008621344
gene_670           0.0132388638
gene_696          -0.0155218791
gene_720          -0.0435232964
gene_757           0.0366479160
gene_760          -0.0310746046
gene_795          -0.0038151634
gene_804           0.0071026491
gene_840           0.0162446672
gene_864          -0.0570875844
gene_874           0.0108188945
gene_877          -0.0084290925
gene_911           0.0303575087
gene_916          -0.0135076583
gene_956          -0.0240584781
gene_969          -0.0054693674
gene_976          -0.0569288581
gene_980           0.0015706121
gene_1013          0.0291775413
gene_1024          0.0417414081
gene_1051          0.0308411643
gene_1059         -0.0030128212
gene_1071         -0.0383864043
gene_1084          0.0129566818
gene_1096         -0.0226222064
gene_1117          0.0243128673
gene_1120          0.0600242242
gene_1137         -0.0634424258
gene_1150         -0.0576782902
gene_1161          0.0050430799
gene_1237          0.0121748732
gene_1241          0.1164865560
gene_1255          0.0025642628
gene_1265         -0.0059853938
gene_1292         -0.0114866186
gene_1306          0.0069838046
gene_1363         -0.0465489365
gene_1376         -0.0113973153
gene_1419          0.1117123380
gene_1421          0.0343775734
gene_1428         -0.1140875119
gene_1437         -0.0166104156
gene_1442          0.0553966751
gene_1476         -0.0179387369
gene_1490         -0.0272055274
gene_1506          0.1071247869
gene_1518         -0.0434573068
gene_1556          0.0845555983
gene_1564         -0.0539480912
gene_1602         -0.0595800034
gene_1610         -0.0390650740
gene_1678          0.0569013521
gene_1685         -0.0028281900
gene_1691         -0.0119213530
gene_1708          0.0561465041
gene_1737          0.0029350844
gene_1738          0.0040687069
gene_1746          0.0015397073
gene_1748         -0.0079077542
gene_1761          0.0616664687
gene_1763          0.0344047529
gene_1775          0.0004665486
gene_1778         -0.1198702861
gene_1846         -0.0227816308
gene_1858         -0.0464153923
gene_1871         -0.0011798398
gene_1892          0.0823542888
gene_1927          0.0532531012
gene_1976         -0.1120061133
gene_1994          0.0020424817</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare errors with your eval_perf()</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>perf_lasso_train <span class="ot">&lt;-</span> <span class="fu">eval_perf</span>(y_train, pred_lasso_train) <span class="sc">|&gt;</span> dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">Model=</span><span class="st">"LASSO"</span>, <span class="at">Dataset=</span><span class="st">"Train"</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>perf_lasso_test  <span class="ot">&lt;-</span> <span class="fu">eval_perf</span>(y_test,  pred_lasso_test)  <span class="sc">|&gt;</span> dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">Model=</span><span class="st">"LASSO"</span>, <span class="at">Dataset=</span><span class="st">"Test"</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>dplyr<span class="sc">::</span><span class="fu">bind_rows</span>(perf_lasso_train, perf_lasso_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 4
    MAE  RMSE Model Dataset
  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  
1  1.49  1.87 LASSO Train  
2  1.57  1.96 LASSO Test   </code></pre>
</div>
</div>
</section>
<section id="fitting-ridge-regression" class="level2" data-number="2.10">
<h2 data-number="2.10" class="anchored" data-anchor-id="fitting-ridge-regression"><span class="header-section-number">2.10</span> Fitting Ridge Regression</h2>
<p>In the following chunks of code we will implement a ridgre regression model.</p>
<p>The Ridge model is trained using&nbsp;<code>cv.glmnet()</code>&nbsp;with&nbsp;<code>alpha = 0</code>, which specifies the L2 penalty. The algorithm performs 10-fold cross-validation over a grid of possible penalty values (lambda) and identifies the one that minimizes the mean prediction error. The value of&nbsp;<code>lambda.min = 1.83</code>&nbsp;is the penalty that achieved the lowest average cross-validation error, while&nbsp;<code>lambda.1se = 2.01</code>&nbsp;corresponds to a slightly stronger penalty that still performs within one standard error of the minimum. The model is then refitted on the entire training dataset with this optimal lambda, and predictions are generated for both training and test sets.</p>
<p>The code then computes the&nbsp;<strong>Mean Absolute Error (MAE)</strong>&nbsp;and&nbsp;<strong>Root Mean Square Error (RMSE)</strong>&nbsp;for each model OLS, LASSO, and Ridge on both the training and test sets using the&nbsp;<code>eval_perf()</code>&nbsp;function. These metrics quantify how close the model’s predictions are to the observed tumor response. The Ridge model shows MAE = 1.43 and RMSE = 1.79 on the training data, and MAE = 1.77 and RMSE = 2.23 on the test data. Compared to OLS (MAE = 1.83, RMSE = 2.28 on the test set), Ridge performs slightly better, reducing both bias and variance without overfitting. Its performance is similar to that of LASSO but typically smoother, since Ridge keeps all variables in the model rather than setting some coefficients exactly to zero.</p>
<p>The Ridge model coefficients provide additional insight. In contrast to LASSO, which eliminates many predictors, Ridge keeps all coefficients non-zero (2,006 in this dataset) but shrinks them toward zero depending on their contribution strength. The list of the top fifteen coefficients shows that the variables with the strongest influence on tumor response are consistent with previous models:&nbsp;<strong>dose_intensity</strong>&nbsp;and&nbsp;<strong>treatmentchemo</strong>&nbsp;have the largest positive effects, indicating that higher doses and chemotherapy are associated with greater tumor shrinkage. Several genes such as&nbsp;<code>gene_14</code>,&nbsp;<code>gene_19</code>, and&nbsp;<code>gene_08</code> also have strong positive associations, while&nbsp;<code>gene_05</code>&nbsp;has a large negative coefficient, suggesting a detrimental effect on treatment response. Other predictors, such as tumor grade and performance score, have smaller but directionally meaningful coefficients that align with clinical expectations.</p>
<p>Overall, these results illustrate the essence of Ridge regularization: instead of discarding predictors as LASSO does, it&nbsp;<strong>shrinks all coefficients toward zero</strong>, reducing overfitting and stabilizing estimates when many correlated variables (such as thousands of gene expressions) are present. The outcome is a model that generalizes better than OLS, retains all variables but with moderated influence, and highlights which features exert the most consistent effects across the dataset.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- 6) Ridge (alpha = 0) with CV ----</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>cv_ridge  <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X_train, y_train, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">nfolds =</span> <span class="dv">10</span>)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>mod_ridge <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X_train, y_train, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">lambda =</span> cv_ridge<span class="sc">$</span>lambda.min)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>pred_ridge_train <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(mod_ridge, <span class="at">newx =</span> X_train))</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>pred_ridge_test  <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(mod_ridge, <span class="at">newx =</span> X_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- Performance (MAE, RMSE) using eval_perform / eval_perf ----</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>perf_ridge_train <span class="ot">&lt;-</span> <span class="fu">eval_perform</span>(y_train, pred_ridge_train) <span class="sc">|&gt;</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">Model =</span> <span class="st">"Ridge"</span>, <span class="at">Dataset =</span> <span class="st">"Train"</span>)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>perf_ridge_test <span class="ot">&lt;-</span> <span class="fu">eval_perform</span>(y_test, pred_ridge_test) <span class="sc">|&gt;</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">Model =</span> <span class="st">"Ridge"</span>, <span class="at">Dataset =</span> <span class="st">"Test"</span>)</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>dplyr<span class="sc">::</span><span class="fu">bind_rows</span>(perf_ridge_train, perf_ridge_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 4
    MAE  RMSE Model Dataset
  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  
1  1.43  1.79 Ridge Train  
2  1.77  2.23 Ridge Test   </code></pre>
</div>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- Quick model “summary” for discussion ----</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Lambdas chosen by CV</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>cv_ridge<span class="sc">$</span>lambda.min</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.82942</code></pre>
</div>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>cv_ridge<span class="sc">$</span>lambda<span class="fl">.1</span>se</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.007787</code></pre>
</div>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Coefficients at lambda.min</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>ridge_coefs <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">coef</span>(mod_ridge))</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>ridge_coef_tbl <span class="ot">&lt;-</span> tibble<span class="sc">::</span><span class="fu">tibble</span>(</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">term     =</span> <span class="fu">rownames</span>(ridge_coefs),</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> <span class="fu">as.numeric</span>(ridge_coefs[, <span class="dv">1</span>])</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a><span class="co"># How many non-zero coefficients (excluding intercept)</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>nnz <span class="ot">&lt;-</span> ridge_coef_tbl <span class="sc">|&gt;</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(term <span class="sc">!=</span> <span class="st">"(Intercept)"</span>, estimate <span class="sc">!=</span> <span class="dv">0</span>) <span class="sc">|&gt;</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nrow</span>()</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>nnz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2006</code></pre>
</div>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Top coefficients by absolute magnitude (exclude intercept)</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>ridge_top <span class="ot">&lt;-</span> ridge_coef_tbl <span class="sc">|&gt;</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(term <span class="sc">!=</span> <span class="st">"(Intercept)"</span>) <span class="sc">|&gt;</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">abs_est =</span> <span class="fu">abs</span>(estimate)) <span class="sc">|&gt;</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">arrange</span>(dplyr<span class="sc">::</span><span class="fu">desc</span>(abs_est)) <span class="sc">|&gt;</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>)</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="do">## seeing the top 15 features regarding estimate</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>ridge_top</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 15 × 3
   term              estimate abs_est
   &lt;chr&gt;                &lt;dbl&gt;   &lt;dbl&gt;
 1 dose_intensity       5.28    5.28 
 2 treatmentchemo       5.03    5.03 
 3 gene_14              4.33    4.33 
 4 gene_19              4.30    4.30 
 5 gene_08              4.29    4.29 
 6 gene_05             -3.50    3.50 
 7 gene_01              0.983   0.983
 8 tumor_gradeG3        0.949   0.949
 9 gene_12              0.526   0.526
10 performance_score   -0.517   0.517
11 tumor_gradeG2        0.283   0.283
12 gene_1419            0.269   0.269
13 gene_1506            0.233   0.233
14 gene_1976           -0.215   0.215
15 gene_907            -0.213   0.213</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- 7) Elastic Net (tune alpha and lambda via CV) ----</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>({</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(glmnet)</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(dplyr)</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(tibble)</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># assumes eval_perform() already defined and X_train, X_test, y_train, y_test exist</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Grid of alpha values (0=ridge, 1=lasso)</span></span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>alpha_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">0.05</span>, <span class="fl">0.95</span>, <span class="at">by =</span> <span class="fl">0.05</span>)</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a><span class="co"># For each alpha, run cv.glmnet to pick lambda; record CV error at lambda.min</span></span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>cv_list <span class="ot">&lt;-</span> <span class="fu">lapply</span>(alpha_grid, <span class="cf">function</span>(a) {</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cv.glmnet</span>(X_train, y_train, <span class="at">alpha =</span> a, <span class="at">nfolds =</span> <span class="dv">10</span>)</span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a>cv_errors <span class="ot">&lt;-</span> <span class="fu">sapply</span>(cv_list, <span class="cf">function</span>(cv) <span class="fu">min</span>(cv<span class="sc">$</span>cvm))  <span class="co"># lower is better</span></span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a>best_idx  <span class="ot">&lt;-</span> <span class="fu">which.min</span>(cv_errors)</span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a>best_alpha <span class="ot">&lt;-</span> alpha_grid[best_idx]</span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a>best_cv    <span class="ot">&lt;-</span> cv_list[[best_idx]]</span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a>best_lambda_min <span class="ot">&lt;-</span> best_cv<span class="sc">$</span>lambda.min</span>
<span id="cb50-24"><a href="#cb50-24" aria-hidden="true" tabindex="-1"></a>best_lambda_1se <span class="ot">&lt;-</span> best_cv<span class="sc">$</span>lambda<span class="fl">.1</span>se</span>
<span id="cb50-25"><a href="#cb50-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-26"><a href="#cb50-26" aria-hidden="true" tabindex="-1"></a>best_alpha</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.15</code></pre>
</div>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>best_lambda_min</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1811088</code></pre>
</div>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>best_lambda_1se</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2883763</code></pre>
</div>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit final Elastic Net at best alpha/lambda</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>mod_enet <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X_train, y_train, <span class="at">alpha =</span> best_alpha, <span class="at">lambda =</span> best_lambda_min)</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>pred_enet_train <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(mod_enet, <span class="at">newx =</span> X_train))</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>pred_enet_test  <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(mod_enet, <span class="at">newx =</span> X_test))</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Performance</span></span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>perf_enet_train <span class="ot">&lt;-</span> <span class="fu">eval_perform</span>(y_train, pred_enet_train) <span class="sc">|&gt;</span></span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Model =</span> <span class="st">"Elastic Net"</span>, <span class="at">Dataset =</span> <span class="st">"Train"</span>, <span class="at">alpha =</span> best_alpha, <span class="at">lambda =</span> best_lambda_min)</span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>perf_enet_test <span class="ot">&lt;-</span> <span class="fu">eval_perform</span>(y_test, pred_enet_test) <span class="sc">|&gt;</span></span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Model =</span> <span class="st">"Elastic Net"</span>, <span class="at">Dataset =</span> <span class="st">"Test"</span>, <span class="at">alpha =</span> best_alpha, <span class="at">lambda =</span> best_lambda_min)</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a><span class="fu">bind_rows</span>(perf_enet_train, perf_enet_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 6
    MAE  RMSE Model       Dataset alpha lambda
  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;
1  1.50  1.88 Elastic Net Train    0.15  0.181
2  1.57  1.95 Elastic Net Test     0.15  0.181</code></pre>
</div>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Coefficients summary</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>enet_coefs <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">coef</span>(mod_enet))</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>enet_coef_tbl <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">term     =</span> <span class="fu">rownames</span>(enet_coefs),</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> <span class="fu">as.numeric</span>(enet_coefs[, <span class="dv">1</span>])</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Count non-zero (excluding intercept)</span></span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>enet_nnz <span class="ot">&lt;-</span> enet_coef_tbl <span class="sc">|&gt;</span></span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(term <span class="sc">!=</span> <span class="st">"(Intercept)"</span>, estimate <span class="sc">!=</span> <span class="dv">0</span>) <span class="sc">|&gt;</span></span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nrow</span>()</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>enet_nnz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 87</code></pre>
</div>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Top coefficients by absolute value (exclude intercept)</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>enet_top <span class="ot">&lt;-</span> enet_coef_tbl <span class="sc">|&gt;</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(term <span class="sc">!=</span> <span class="st">"(Intercept)"</span>) <span class="sc">|&gt;</span></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">abs_est =</span> <span class="fu">abs</span>(estimate)) <span class="sc">|&gt;</span></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(abs_est)) <span class="sc">|&gt;</span></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>)</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>enet_top</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 20 × 3
   term              estimate abs_est
   &lt;chr&gt;                &lt;dbl&gt;   &lt;dbl&gt;
 1 gene_19             5.08    5.08  
 2 gene_08             5.01    5.01  
 3 gene_14             4.98    4.98  
 4 dose_intensity      3.54    3.54  
 5 treatmentchemo      3.49    3.49  
 6 gene_05            -2.92    2.92  
 7 gene_01             0.863   0.863 
 8 tumor_gradeG3       0.606   0.606 
 9 gene_12             0.456   0.456 
10 performance_score  -0.320   0.320 
11 tumor_gradeG2       0.141   0.141 
12 gene_1976          -0.110   0.110 
13 gene_1419           0.107   0.107 
14 gene_1241           0.106   0.106 
15 gene_1428          -0.0990  0.0990
16 gene_1778          -0.0947  0.0947
17 gene_1506           0.0947  0.0947
18 gene_1892           0.0793  0.0793
19 gene_1556           0.0705  0.0705
20 gene_30            -0.0676  0.0676</code></pre>
</div>
</div>
</section>
<section id="elastic-net" class="level2" data-number="2.11">
<h2 data-number="2.11" class="anchored" data-anchor-id="elastic-net"><span class="header-section-number">2.11</span> Elastic Net</h2>
<p>The next chunk fits an Elastic Net regression and tunes its two key hyperparameters using cross-validation, then evaluates how well it predicts on unseen data and inspects the model’s coefficients.</p>
<p>First, it defines a grid of candidate mixing parameters alpha from 0.05 to 0.95. Elastic Net blends Ridge and LASSO: alpha equal to 0 behaves like Ridge, alpha equal to 1 behaves like LASSO, values in between trade off between the two penalties. For each alpha in the grid,&nbsp;<code>cv.glmnet()</code>&nbsp;runs 10-fold cross-validation over a sequence of lambda values and records the mean cross-validated error. The code then picks the alpha that achieves the lowest error across its lambda path, identifies the corresponding best lambda at the minimum error (<code>lambda.min</code>) and also records&nbsp;<code>lambda.1se</code>&nbsp;which is a slightly stronger penalty within one standard error of the minimum. In your run, the best alpha is 0.15, with&nbsp;<code>lambda.min</code>about 0.181 and&nbsp;<code>lambda.1se</code>&nbsp;about 0.288. This indicates that a model closer to Ridge than to LASSO gave the best cross-validated performance on this dataset.</p>
<p>With the best alpha and&nbsp;<code>lambda.min</code>&nbsp;fixed, the code refits a final Elastic Net model on the full training matrix and generates predictions for both training and test sets. It then computes MAE and RMSE via&nbsp;<code>eval_perform()</code>. Your results show MAE 1.50 and RMSE 1.88 on training, and MAE 1.57 and RMSE 1.95 on test. The similarity between train and test errors suggests good generalization with limited overfitting. Test performance is competitive with or slightly better than the individual Ridge and LASSO models you fitted earlier, which is a common outcome when Elastic Net can borrow strengths from both penalties in the presence of many correlated predictors.</p>
<p>Finally, the code examines the coefficient vector. It converts the sparse coefficient matrix to a tibble, counts how many coefficients are non-zero excluding the intercept, and ranks predictors by absolute magnitude. You obtained 87 non-zero coefficients, which is far sparser than Ridge and far denser than a very aggressive LASSO, reflecting the balance enforced by alpha 0.15. The top effects are biologically and clinically interpretable:&nbsp;<code>gene_19</code>,&nbsp;<code>gene_08</code>, and&nbsp;<code>gene_14</code>&nbsp;have the largest positive coefficients,&nbsp;<code>dose_intensity</code>&nbsp;and&nbsp;<code>treatmentchemo</code>&nbsp;are also strongly positive, while&nbsp;<code>gene_05</code>&nbsp;is strongly negative, and&nbsp;<code>performance_score</code>&nbsp;is moderately negative. Tumor grade indicators and several additional genes appear with smaller but non-zero effects. This pattern is what Elastic Net is designed to produce in high-dimensional settings with correlated features: it keeps groups of correlated predictors, shrinks them toward zero to control variance, and still performs variable selection to improve interpretability and prediction.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- 7) Elastic Net (tune alpha and lambda via CV) ----</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>({</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(glmnet)</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(dplyr)</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(tibble)</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># assumes eval_perform() already defined and X_train, X_test, y_train, y_test exist</span></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Grid of alpha values (0=ridge, 1=lasso)</span></span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a>alpha_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">0.05</span>, <span class="fl">0.95</span>, <span class="at">by =</span> <span class="fl">0.05</span>)</span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a><span class="co"># For each alpha, run cv.glmnet to pick lambda; record CV error at lambda.min</span></span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a>cv_list <span class="ot">&lt;-</span> <span class="fu">lapply</span>(alpha_grid, <span class="cf">function</span>(a) {</span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cv.glmnet</span>(X_train, y_train, <span class="at">alpha =</span> a, <span class="at">nfolds =</span> <span class="dv">10</span>)</span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a>cv_errors <span class="ot">&lt;-</span> <span class="fu">sapply</span>(cv_list, <span class="cf">function</span>(cv) <span class="fu">min</span>(cv<span class="sc">$</span>cvm))  <span class="co"># lower is better</span></span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a>best_idx  <span class="ot">&lt;-</span> <span class="fu">which.min</span>(cv_errors)</span>
<span id="cb62-21"><a href="#cb62-21" aria-hidden="true" tabindex="-1"></a>best_alpha <span class="ot">&lt;-</span> alpha_grid[best_idx]</span>
<span id="cb62-22"><a href="#cb62-22" aria-hidden="true" tabindex="-1"></a>best_cv    <span class="ot">&lt;-</span> cv_list[[best_idx]]</span>
<span id="cb62-23"><a href="#cb62-23" aria-hidden="true" tabindex="-1"></a>best_lambda_min <span class="ot">&lt;-</span> best_cv<span class="sc">$</span>lambda.min</span>
<span id="cb62-24"><a href="#cb62-24" aria-hidden="true" tabindex="-1"></a>best_lambda_1se <span class="ot">&lt;-</span> best_cv<span class="sc">$</span>lambda<span class="fl">.1</span>se</span>
<span id="cb62-25"><a href="#cb62-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-26"><a href="#cb62-26" aria-hidden="true" tabindex="-1"></a>best_alpha</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.15</code></pre>
</div>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>best_lambda_min</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1811088</code></pre>
</div>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>best_lambda_1se</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2883763</code></pre>
</div>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit final Elastic Net at best alpha/lambda</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>mod_enet <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X_train, y_train, <span class="at">alpha =</span> best_alpha, <span class="at">lambda =</span> best_lambda_min)</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions</span></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>pred_enet_train <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(mod_enet, <span class="at">newx =</span> X_train))</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>pred_enet_test  <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(mod_enet, <span class="at">newx =</span> X_test))</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Performance</span></span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a>perf_enet_train <span class="ot">&lt;-</span> <span class="fu">eval_perform</span>(y_train, pred_enet_train) <span class="sc">|&gt;</span></span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Model =</span> <span class="st">"Elastic Net"</span>, <span class="at">Dataset =</span> <span class="st">"Train"</span>, <span class="at">alpha =</span> best_alpha, <span class="at">lambda =</span> best_lambda_min)</span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a>perf_enet_test <span class="ot">&lt;-</span> <span class="fu">eval_perform</span>(y_test, pred_enet_test) <span class="sc">|&gt;</span></span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Model =</span> <span class="st">"Elastic Net"</span>, <span class="at">Dataset =</span> <span class="st">"Test"</span>, <span class="at">alpha =</span> best_alpha, <span class="at">lambda =</span> best_lambda_min)</span>
<span id="cb68-14"><a href="#cb68-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-15"><a href="#cb68-15" aria-hidden="true" tabindex="-1"></a><span class="fu">bind_rows</span>(perf_enet_train, perf_enet_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 6
    MAE  RMSE Model       Dataset alpha lambda
  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;
1  1.50  1.88 Elastic Net Train    0.15  0.181
2  1.57  1.95 Elastic Net Test     0.15  0.181</code></pre>
</div>
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Coefficients summary</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>enet_coefs <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">coef</span>(mod_enet))</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>enet_coef_tbl <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">term     =</span> <span class="fu">rownames</span>(enet_coefs),</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> <span class="fu">as.numeric</span>(enet_coefs[, <span class="dv">1</span>])</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Count non-zero (excluding intercept)</span></span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>enet_nnz <span class="ot">&lt;-</span> enet_coef_tbl <span class="sc">|&gt;</span></span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(term <span class="sc">!=</span> <span class="st">"(Intercept)"</span>, estimate <span class="sc">!=</span> <span class="dv">0</span>) <span class="sc">|&gt;</span></span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nrow</span>()</span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>enet_nnz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 87</code></pre>
</div>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Top coefficients by absolute value (exclude intercept)</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>enet_top <span class="ot">&lt;-</span> enet_coef_tbl <span class="sc">|&gt;</span></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(term <span class="sc">!=</span> <span class="st">"(Intercept)"</span>) <span class="sc">|&gt;</span></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">abs_est =</span> <span class="fu">abs</span>(estimate)) <span class="sc">|&gt;</span></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(abs_est)) <span class="sc">|&gt;</span></span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>)</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a>enet_top</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 20 × 3
   term              estimate abs_est
   &lt;chr&gt;                &lt;dbl&gt;   &lt;dbl&gt;
 1 gene_19             5.08    5.08  
 2 gene_08             5.01    5.01  
 3 gene_14             4.98    4.98  
 4 dose_intensity      3.54    3.54  
 5 treatmentchemo      3.49    3.49  
 6 gene_05            -2.92    2.92  
 7 gene_01             0.863   0.863 
 8 tumor_gradeG3       0.606   0.606 
 9 gene_12             0.456   0.456 
10 performance_score  -0.320   0.320 
11 tumor_gradeG2       0.141   0.141 
12 gene_1976          -0.110   0.110 
13 gene_1419           0.107   0.107 
14 gene_1241           0.106   0.106 
15 gene_1428          -0.0990  0.0990
16 gene_1778          -0.0947  0.0947
17 gene_1506           0.0947  0.0947
18 gene_1892           0.0793  0.0793
19 gene_1556           0.0705  0.0705
20 gene_30            -0.0676  0.0676</code></pre>
</div>
</div>
</section>
<section id="comparing-ols-lasso-ridge-and-elastic-net-regression" class="level2" data-number="2.12">
<h2 data-number="2.12" class="anchored" data-anchor-id="comparing-ols-lasso-ridge-and-elastic-net-regression"><span class="header-section-number">2.12</span> Comparing OLS, LASSO, Ridge and Elastic Net Regression</h2>
<p>This section compares the performance and interpretability of the four regression models Ordinary Least Squares (OLS), LASSO, Ridge, and Elastic Net using the same training and testing datasets. The code constructs two tables, one for the training set and one for the test set, summarizing each model’s&nbsp;<strong>Mean Absolute Error (MAE)</strong>&nbsp;and&nbsp;<strong>Root Mean Square Error (RMSE)</strong>. These metrics quantify how close the predicted tumor responses are to the observed values: lower numbers indicate more accurate predictions.</p>
<p>On the&nbsp;<strong>training data</strong>, OLS achieves the smallest apparent errors (MAE = 1.27, RMSE = 1.59), which is expected because it freely adjusts all coefficients without any penalty. However, its flexibility can also lead to overfitting, meaning it might perform worse on new, unseen data. The Ridge model (MAE = 1.43, RMSE = 1.79) and the Elastic Net (MAE = 1.50, RMSE = 1.88) show slightly higher training errors, reflecting the effect of regularization that constrains coefficient size to prevent overfitting. LASSO (MAE = 1.49, RMSE = 1.87) behaves similarly, as it shrinks and even eliminates some coefficients.</p>
<p>The&nbsp;<strong>test set</strong>&nbsp;results are more revealing, since they reflect how well each model generalizes. OLS now has the highest errors (MAE = 1.83, RMSE = 2.28), showing a clear drop in performance compared with the training data. In contrast, the regularized models maintain nearly identical errors across training and test sets. LASSO and Elastic Net both achieve MAE around 1.57 and RMSE near 1.95, while Ridge performs slightly worse but still better than OLS. This stability across datasets indicates that the regularization terms have successfully reduced overfitting, producing models that generalize better to new observations.</p>
<p>Beyond predictive accuracy, each method differs in&nbsp;<strong>interpretability</strong>&nbsp;and in how easily its results can be communicated. OLS is the simplest to interpret: every coefficient represents the independent effect of a predictor on the outcome, assuming all other variables are fixed. However, in high-dimensional data such as gene-expression studies, OLS becomes unstable and hard to explain because of multicollinearity and noise. LASSO improves interpretability by setting many coefficients exactly to zero, leaving only a small, focused subset of relevant predictors that can be examined biologically or clinically. Ridge, by contrast, keeps all variables but shrinks their effects toward zero, which stabilizes the estimates but makes it harder to identify a small list of “important” predictors. Elastic Net combines both approaches, preserving correlated groups of variables while still performing selection, offering a compromise between the simplicity of LASSO and the robustness of Ridge.</p>
<p>In practical terms, these results illustrate the trade-off between fit, generalization, and interpretability. OLS fits training data best but generalizes poorly. Ridge and Elastic Net offer more stable and realistic predictions in complex, high-dimensional problems. LASSO and Elastic Net, in particular, produce more interpretable models that highlight a concise subset of genes and clinical variables that drive tumor response, making them easier to communicate in biomedical contexts where explanation is as important as prediction.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- 8) Side-by-side performance tables (MAE and RMSE)   now with Elastic Net ----</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Assumes you already computed:</span></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a><span class="co">#   pred_ols_train,  pred_ols_test</span></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   pred_lasso_train, pred_lasso_test</span></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a><span class="co">#   pred_ridge_train, pred_ridge_test</span></span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a><span class="co">#   pred_enet_train,  pred_enet_test</span></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a><span class="co"># And (optionally) best_alpha, best_lambda_min from your Elastic Net CV</span></span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper: safely carry alpha/lambda for ENet if they exist</span></span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>alpha_enet  <span class="ot">&lt;-</span> <span class="cf">if</span> (<span class="fu">exists</span>(<span class="st">"best_alpha"</span>)) best_alpha <span class="cf">else</span> <span class="cn">NA_real_</span></span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a>lambda_enet <span class="ot">&lt;-</span> <span class="cf">if</span> (<span class="fu">exists</span>(<span class="st">"best_lambda_min"</span>)) best_lambda_min <span class="cf">else</span> <span class="cn">NA_real_</span></span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Build TRAIN table</span></span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a>metrics_train <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb74-15"><a href="#cb74-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">Model =</span> <span class="fu">c</span>(<span class="st">"OLS"</span>, <span class="st">"LASSO (λ.min)"</span>, <span class="st">"Ridge (λ.min)"</span>, <span class="st">"Elastic Net"</span>)</span>
<span id="cb74-16"><a href="#cb74-16" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span></span>
<span id="cb74-17"><a href="#cb74-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(</span>
<span id="cb74-18"><a href="#cb74-18" aria-hidden="true" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">bind_rows</span>(</span>
<span id="cb74-19"><a href="#cb74-19" aria-hidden="true" tabindex="-1"></a>      <span class="fu">eval_perf</span>(y_train, pred_ols_train),</span>
<span id="cb74-20"><a href="#cb74-20" aria-hidden="true" tabindex="-1"></a>      <span class="fu">eval_perf</span>(y_train, pred_lasso_train),</span>
<span id="cb74-21"><a href="#cb74-21" aria-hidden="true" tabindex="-1"></a>      <span class="fu">eval_perf</span>(y_train, pred_ridge_train),</span>
<span id="cb74-22"><a href="#cb74-22" aria-hidden="true" tabindex="-1"></a>      <span class="fu">eval_perf</span>(y_train, pred_enet_train)</span>
<span id="cb74-23"><a href="#cb74-23" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb74-24"><a href="#cb74-24" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb74-25"><a href="#cb74-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Alpha =</span> <span class="fu">c</span>(<span class="cn">NA</span>, <span class="fl">1.00</span>, <span class="fl">0.00</span>, alpha_enet),</span>
<span id="cb74-26"><a href="#cb74-26" aria-hidden="true" tabindex="-1"></a>         <span class="at">Lambda =</span> <span class="fu">c</span>(<span class="cn">NA</span>, <span class="cn">NA</span>, <span class="cn">NA</span>, lambda_enet))</span>
<span id="cb74-27"><a href="#cb74-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-28"><a href="#cb74-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Build </span><span class="al">TEST</span><span class="co"> table</span></span>
<span id="cb74-29"><a href="#cb74-29" aria-hidden="true" tabindex="-1"></a>metrics_test <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb74-30"><a href="#cb74-30" aria-hidden="true" tabindex="-1"></a>  <span class="at">Model =</span> <span class="fu">c</span>(<span class="st">"OLS"</span>, <span class="st">"LASSO (λ.min)"</span>, <span class="st">"Ridge (λ.min)"</span>, <span class="st">"Elastic Net"</span>)</span>
<span id="cb74-31"><a href="#cb74-31" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span></span>
<span id="cb74-32"><a href="#cb74-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(</span>
<span id="cb74-33"><a href="#cb74-33" aria-hidden="true" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">bind_rows</span>(</span>
<span id="cb74-34"><a href="#cb74-34" aria-hidden="true" tabindex="-1"></a>      <span class="fu">eval_perf</span>(y_test, pred_ols_test),</span>
<span id="cb74-35"><a href="#cb74-35" aria-hidden="true" tabindex="-1"></a>      <span class="fu">eval_perf</span>(y_test, pred_lasso_test),</span>
<span id="cb74-36"><a href="#cb74-36" aria-hidden="true" tabindex="-1"></a>      <span class="fu">eval_perf</span>(y_test, pred_ridge_test),</span>
<span id="cb74-37"><a href="#cb74-37" aria-hidden="true" tabindex="-1"></a>      <span class="fu">eval_perf</span>(y_test, pred_enet_test)</span>
<span id="cb74-38"><a href="#cb74-38" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb74-39"><a href="#cb74-39" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span></span>
<span id="cb74-40"><a href="#cb74-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Alpha =</span> <span class="fu">c</span>(<span class="cn">NA</span>, <span class="fl">1.00</span>, <span class="fl">0.00</span>, alpha_enet),</span>
<span id="cb74-41"><a href="#cb74-41" aria-hidden="true" tabindex="-1"></a>         <span class="at">Lambda =</span> <span class="fu">c</span>(<span class="cn">NA</span>, <span class="cn">NA</span>, <span class="cn">NA</span>, lambda_enet))</span>
<span id="cb74-42"><a href="#cb74-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-43"><a href="#cb74-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Print results</span></span>
<span id="cb74-44"><a href="#cb74-44" aria-hidden="true" tabindex="-1"></a>metrics_train</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 5
  Model           MAE  RMSE Alpha Lambda
  &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
1 OLS            1.27  1.59 NA    NA    
2 LASSO (λ.min)  1.49  1.87  1    NA    
3 Ridge (λ.min)  1.43  1.79  0    NA    
4 Elastic Net    1.50  1.88  0.15  0.181</code></pre>
</div>
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>metrics_test</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 5
  Model           MAE  RMSE Alpha Lambda
  &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
1 OLS            1.83  2.28 NA    NA    
2 LASSO (λ.min)  1.57  1.96  1    NA    
3 Ridge (λ.min)  1.77  2.23  0    NA    
4 Elastic Net    1.57  1.95  0.15  0.181</code></pre>
</div>
</div>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Penalty norm</th>
<th>Variable selection/Regularization</th>
<th>Explanation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>OLS</td>
<td></td>
<td>No</td>
<td>No regularization , all variables retained.</td>
</tr>
<tr class="even">
<td>Ridge</td>
<td>L2</td>
<td>No</td>
<td>Shrinks coefficients but keeps all variables.</td>
</tr>
<tr class="odd">
<td>Lasso</td>
<td>L1</td>
<td><strong>Yes</strong></td>
<td>L1 penalty can drive some coefficients to exactly zero.</td>
</tr>
<tr class="even">
<td>Elastic Net</td>
<td>L1 + L2 (mix)</td>
<td><strong>Partial</strong></td>
<td>Combines both effects some zeroing, some shrinkage.</td>
</tr>
</tbody>
</table>
</section>
<section id="organizing-our-study-questions" class="level2" data-number="2.13">
<h2 data-number="2.13" class="anchored" data-anchor-id="organizing-our-study-questions"><span class="header-section-number">2.13</span> Organizing our study questions</h2>
<section id="main-treatment-effect" class="level3" data-number="2.13.1">
<h3 data-number="2.13.1" class="anchored" data-anchor-id="main-treatment-effect"><span class="header-section-number">2.13.1</span> Main treatment effect</h3>
<p>In order to answer the first study question we use the following code:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>({</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(dplyr)</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(broom)</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(stringr)</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(tibble)</span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a><span class="co"># OLS: adjusted main effect of treatment (chemo vs reference)</span></span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a>coef_ols <span class="ot">&lt;-</span> <span class="fu">tidy</span>(mod_ols, <span class="at">conf.int =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a><span class="fu">filter</span>(<span class="fu">grepl</span>(<span class="st">"^treatment"</span>, term))</span>
<span id="cb78-13"><a href="#cb78-13" aria-hidden="true" tabindex="-1"></a>coef_ols</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 7
  term           estimate std.error statistic  p.value conf.low conf.high
  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 treatmentchemo     3.47     0.420      8.26 1.90e-16     2.65      4.30</code></pre>
</div>
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Regularized models: report the treatment coefficient (main effect)</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>grab_coef <span class="ot">&lt;-</span> <span class="cf">function</span>(m, name) {</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">coef</span>(m))</span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span>name <span class="sc">%in%</span> <span class="fu">rownames</span>(b)) <span class="fu">return</span>(<span class="cn">NA_real_</span>)</span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a><span class="fu">as.numeric</span>(b[name, <span class="dv">1</span>])</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a>main_effects_tbl <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a><span class="at">Model =</span> <span class="fu">c</span>(<span class="st">"OLS"</span>,<span class="st">"LASSO"</span>,<span class="st">"Ridge"</span>,<span class="st">"Elastic Net"</span>),</span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a><span class="at">Treatment_Beta =</span> <span class="fu">c</span>(</span>
<span id="cb80-11"><a href="#cb80-11" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod_ols)[[<span class="st">"treatmentchemo"</span>]],</span>
<span id="cb80-12"><a href="#cb80-12" aria-hidden="true" tabindex="-1"></a><span class="fu">grab_coef</span>(mod_lasso, <span class="st">"treatmentchemo"</span>),</span>
<span id="cb80-13"><a href="#cb80-13" aria-hidden="true" tabindex="-1"></a><span class="fu">grab_coef</span>(mod_ridge, <span class="st">"treatmentchemo"</span>),</span>
<span id="cb80-14"><a href="#cb80-14" aria-hidden="true" tabindex="-1"></a><span class="fu">grab_coef</span>(mod_enet,  <span class="st">"treatmentchemo"</span>)</span>
<span id="cb80-15"><a href="#cb80-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb80-16"><a href="#cb80-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb80-17"><a href="#cb80-17" aria-hidden="true" tabindex="-1"></a>main_effects_tbl</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 2
  Model       Treatment_Beta
  &lt;chr&gt;                &lt;dbl&gt;
1 OLS                   3.47
2 LASSO                 3.11
3 Ridge                 5.03
4 Elastic Net           3.49</code></pre>
</div>
</div>
<p>The last table reports the estimated main treatment effect the adjusted average difference in tumor shrinkage between patients who received chemotherapy and those who did not across four models. The OLS estimate of 3.47 percentage points suggests a clear benefit of chemotherapy after accounting for other covariates. Introducing L1 regularization with LASSO yields a slightly smaller effect of 3.11, consistent with the tendency of sparsity penalties to dampen coefficients in the presence of multicollinearity or weak predictors. Ridge regression, which applies an L2 penalty but retains all variables, produces a larger estimate of 5.03, indicating that when correlated predictors are jointly shrunk rather than selected away, the treatment signal can be expressed more strongly. Elastic Net, blending L1 and L2 penalties, returns 3.49 essentially aligning with OLS while offering greater stability than an unpenalized fit. Taken together, the results are directionally consistent and clinically coherent given the fact that regardless of modeling strategy, chemotherapy is associated with higher average tumor reduction, with the magnitude ranging from roughly three to five percentage points depending on how the method handles correlation and complexity in the predictors.</p>
</section>
<section id="clinical-covariates" class="level3" data-number="2.13.2">
<h3 data-number="2.13.2" class="anchored" data-anchor-id="clinical-covariates"><span class="header-section-number">2.13.2</span> Clinical covariates:</h3>
<p>What are the main-effect associations of age, tumor grade, and performance score with tumor shrinkage, controlling for treatment?</p>
<p>To answer this question we run the code below which helps us to extract the parameters associated with the variables of interest.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Clinical (no interactions): OLS + LASSO + RIDGE + ENET ------------------</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>({</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(dplyr)</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(broom)</span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(stringr)</span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(tibble)</span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper: make a regex that matches `patient age` with or without backticks (case-insensitive)</span></span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a>age_regex <span class="ot">&lt;-</span> <span class="fu">regex</span>(<span class="st">"^`?patient_age`?$"</span>, <span class="at">ignore_case =</span> <span class="cn">TRUE</span>)</span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-12"><a href="#cb82-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) OLS clinical table (with CIs and p-values)</span></span>
<span id="cb82-13"><a href="#cb82-13" aria-hidden="true" tabindex="-1"></a><span class="co">#    Keep: patient age, performance_score, and ALL tumor_grade dummies</span></span>
<span id="cb82-14"><a href="#cb82-14" aria-hidden="true" tabindex="-1"></a>ols_tidy <span class="ot">&lt;-</span> <span class="fu">tidy</span>(mod_ols, <span class="at">conf.int =</span> <span class="cn">TRUE</span>)</span>
<span id="cb82-15"><a href="#cb82-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-16"><a href="#cb82-16" aria-hidden="true" tabindex="-1"></a>ols_clinical <span class="ot">&lt;-</span> ols_tidy <span class="sc">%&gt;%</span></span>
<span id="cb82-17"><a href="#cb82-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(</span>
<span id="cb82-18"><a href="#cb82-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">str_detect</span>(term, age_regex) <span class="sc">|</span></span>
<span id="cb82-19"><a href="#cb82-19" aria-hidden="true" tabindex="-1"></a>    term <span class="sc">==</span> <span class="st">"performance_score"</span> <span class="sc">|</span></span>
<span id="cb82-20"><a href="#cb82-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">str_detect</span>(term, <span class="st">"^tumor_grade"</span>)</span>
<span id="cb82-21"><a href="#cb82-21" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb82-22"><a href="#cb82-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(p.value) <span class="sc">%&gt;%</span></span>
<span id="cb82-23"><a href="#cb82-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(</span>
<span id="cb82-24"><a href="#cb82-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">beta_ols   =</span> estimate,</span>
<span id="cb82-25"><a href="#cb82-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">se_ols     =</span> std.error,</span>
<span id="cb82-26"><a href="#cb82-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">t_ols      =</span> statistic,</span>
<span id="cb82-27"><a href="#cb82-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">p_ols      =</span> p.value,</span>
<span id="cb82-28"><a href="#cb82-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">ci_low_ols =</span> conf.low,</span>
<span id="cb82-29"><a href="#cb82-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">ci_high_ols=</span> conf.high</span>
<span id="cb82-30"><a href="#cb82-30" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb82-31"><a href="#cb82-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-32"><a href="#cb82-32" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) Helper to extract glmnet coefficients by term ----------------------------</span></span>
<span id="cb82-33"><a href="#cb82-33" aria-hidden="true" tabindex="-1"></a>get_glmnet_coefs <span class="ot">&lt;-</span> <span class="cf">function</span>(mod_glmnet, <span class="at">keep_regex =</span> <span class="cn">NULL</span>, <span class="at">keep_exact_regex =</span> <span class="cn">NULL</span>, <span class="at">colname =</span> <span class="st">"beta"</span>){</span>
<span id="cb82-34"><a href="#cb82-34" aria-hidden="true" tabindex="-1"></a>  B <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">coef</span>(mod_glmnet))</span>
<span id="cb82-35"><a href="#cb82-35" aria-hidden="true" tabindex="-1"></a>  tab <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">term =</span> <span class="fu">rownames</span>(B), <span class="sc">!!</span><span class="at">colname :=</span> <span class="fu">as.numeric</span>(B[, <span class="dv">1</span>])) <span class="sc">%&gt;%</span></span>
<span id="cb82-36"><a href="#cb82-36" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(term <span class="sc">!=</span> <span class="st">"(Intercept)"</span>)</span>
<span id="cb82-37"><a href="#cb82-37" aria-hidden="true" tabindex="-1"></a>  tab <span class="sc">%&gt;%</span></span>
<span id="cb82-38"><a href="#cb82-38" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(</span>
<span id="cb82-39"><a href="#cb82-39" aria-hidden="true" tabindex="-1"></a>      (<span class="cf">if</span> (<span class="sc">!</span><span class="fu">is.null</span>(keep_exact_regex)) <span class="fu">str_detect</span>(term, keep_exact_regex) <span class="cf">else</span> <span class="cn">FALSE</span>) <span class="sc">|</span></span>
<span id="cb82-40"><a href="#cb82-40" aria-hidden="true" tabindex="-1"></a>      (<span class="cf">if</span> (<span class="sc">!</span><span class="fu">is.null</span>(keep_regex))       <span class="fu">str_detect</span>(term, keep_regex)       <span class="cf">else</span> <span class="cn">FALSE</span>)</span>
<span id="cb82-41"><a href="#cb82-41" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb82-42"><a href="#cb82-42" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb82-43"><a href="#cb82-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-44"><a href="#cb82-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Keep exactly patient age (with/without backticks) and performance_score;</span></span>
<span id="cb82-45"><a href="#cb82-45" aria-hidden="true" tabindex="-1"></a><span class="co"># plus everything that starts with tumor_grade</span></span>
<span id="cb82-46"><a href="#cb82-46" aria-hidden="true" tabindex="-1"></a>keep_exact_regex <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"("</span>, <span class="fu">paste</span>(<span class="fu">c</span>(<span class="st">"performance_score"</span>, age_regex), <span class="at">collapse=</span><span class="st">"|"</span>), <span class="st">")"</span>)</span>
<span id="cb82-47"><a href="#cb82-47" aria-hidden="true" tabindex="-1"></a>keep_regex_grade <span class="ot">&lt;-</span> <span class="st">"^tumor_grade"</span></span>
<span id="cb82-48"><a href="#cb82-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-49"><a href="#cb82-49" aria-hidden="true" tabindex="-1"></a>lasso_tab <span class="ot">&lt;-</span> <span class="fu">get_glmnet_coefs</span>(mod_lasso, <span class="at">keep_regex =</span> keep_regex_grade,</span>
<span id="cb82-50"><a href="#cb82-50" aria-hidden="true" tabindex="-1"></a>                              <span class="at">keep_exact_regex =</span> keep_exact_regex, <span class="at">colname =</span> <span class="st">"beta_lasso"</span>)</span>
<span id="cb82-51"><a href="#cb82-51" aria-hidden="true" tabindex="-1"></a>ridge_tab <span class="ot">&lt;-</span> <span class="fu">get_glmnet_coefs</span>(mod_ridge, <span class="at">keep_regex =</span> keep_regex_grade,</span>
<span id="cb82-52"><a href="#cb82-52" aria-hidden="true" tabindex="-1"></a>                              <span class="at">keep_exact_regex =</span> keep_exact_regex, <span class="at">colname =</span> <span class="st">"beta_ridge"</span>)</span>
<span id="cb82-53"><a href="#cb82-53" aria-hidden="true" tabindex="-1"></a>enet_tab  <span class="ot">&lt;-</span> <span class="fu">get_glmnet_coefs</span>(mod_enet,  <span class="at">keep_regex =</span> keep_regex_grade,</span>
<span id="cb82-54"><a href="#cb82-54" aria-hidden="true" tabindex="-1"></a>                              <span class="at">keep_exact_regex =</span> keep_exact_regex, <span class="at">colname =</span> <span class="st">"beta_enet"</span>)</span>
<span id="cb82-55"><a href="#cb82-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-56"><a href="#cb82-56" aria-hidden="true" tabindex="-1"></a><span class="co"># 3) Join everything by term --------------------------------------------------</span></span>
<span id="cb82-57"><a href="#cb82-57" aria-hidden="true" tabindex="-1"></a>clin_compare <span class="ot">&lt;-</span> ols_clinical <span class="sc">%&gt;%</span></span>
<span id="cb82-58"><a href="#cb82-58" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term, beta_ols, se_ols, t_ols, p_ols, ci_low_ols, ci_high_ols) <span class="sc">%&gt;%</span></span>
<span id="cb82-59"><a href="#cb82-59" aria-hidden="true" tabindex="-1"></a>  <span class="fu">left_join</span>(lasso_tab, <span class="at">by =</span> <span class="st">"term"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb82-60"><a href="#cb82-60" aria-hidden="true" tabindex="-1"></a>  <span class="fu">left_join</span>(ridge_tab, <span class="at">by =</span> <span class="st">"term"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb82-61"><a href="#cb82-61" aria-hidden="true" tabindex="-1"></a>  <span class="fu">left_join</span>(enet_tab,  <span class="at">by =</span> <span class="st">"term"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb82-62"><a href="#cb82-62" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb82-63"><a href="#cb82-63" aria-hidden="true" tabindex="-1"></a>    <span class="at">beta_lasso =</span> <span class="fu">coalesce</span>(beta_lasso, <span class="dv">0</span>),</span>
<span id="cb82-64"><a href="#cb82-64" aria-hidden="true" tabindex="-1"></a>    <span class="at">beta_ridge =</span> <span class="fu">coalesce</span>(beta_ridge, <span class="dv">0</span>),</span>
<span id="cb82-65"><a href="#cb82-65" aria-hidden="true" tabindex="-1"></a>    <span class="at">beta_enet  =</span> <span class="fu">coalesce</span>(beta_enet,  <span class="dv">0</span>)</span>
<span id="cb82-66"><a href="#cb82-66" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb82-67"><a href="#cb82-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-68"><a href="#cb82-68" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(clin_compare)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>               term    beta_ols      se_ols     t_ols        p_ols  ci_low_ols
1       patient_age  0.01708261 0.001573078 10.859354 3.614794e-27  0.01399868
2 performance_score -0.40130130 0.041437926 -9.684396 5.477501e-22 -0.48253783
3     tumor_gradeG3  0.69494056 0.074639941  9.310572 1.860192e-20  0.54861349
4     tumor_gradeG2  0.23598487 0.066305941  3.559030 3.756879e-04  0.10599610
  ci_high_ols  beta_lasso  beta_ridge   beta_enet
1  0.02016653  0.01328823  0.02179867  0.01439859
2 -0.32006476 -0.29430835 -0.51698819 -0.32020568
3  0.84126763  0.55479520  0.94884736  0.60613069
4  0.36597363  0.13160157  0.28258697  0.14149931</code></pre>
</div>
</div>
<p>The last table compares the estimated effects of key clinical predictors on tumor response across four regression approaches ordinary least squares (OLS), LASSO, Ridge, and Elastic Netfocusing on main effects. The coefficients represent how much the tumor shrinkage percentage is expected to change for a one-unit increase in each variable, holding all others constant. The OLS model serves as a baseline reference. The coefficient for patient_age is positive (0.017 ± 0.0016, p ≈ 3.6 × 10⁻²⁷), indicating that, on average, each additional year of age is associated with roughly a 0.017 percentage-point increase in tumor shrinkage. Although small in magnitude, this effect is highly significant, suggesting a subtle but consistent relationship between age and treatment response. The performance_score shows a strong negative association (β = –0.40, p ≈ 5.5 × 10⁻²²), implying that patients with poorer functional status tend to experience smaller reductions in tumor size. Tumor grade, in contrast, shows clear positive effects: compared with the reference category (grade 1), both grade 2 (β = 0.24, p ≈ 3.8 × 10⁻⁴) and grade 3 (β = 0.69, p ≈ 1.9 × 10⁻²⁰) are associated with progressively greater shrinkage, consistent with more aggressive tumors responding more markedly to treatment. When regularization is introduced, the three penalized methods yield broadly similar patterns but with slightly shrunk coefficients. LASSO reduces effect magnitudes toward zero, particularly for performance_score (–0.29) and tumor_gradeG2 (0.13), reflecting its tendency to suppress weaker signals. Ridge regression, which applies a smooth L2 penalty, retains all variables and yields somewhat larger estimates (e.g., tumor_gradeG3 = 0.95), showing how correlated predictors can share information without being zeroed out. Elastic Net, which blends LASSO and Ridge penalties, produces intermediate values that balance sparsity and stability (e.g., performance_score = –0.32, tumor_gradeG3 = 0.61). Across all models, the direction of effects remains stable: older age and higher tumor grade predict better tumor shrinkage, while poorer performance status predicts worse response. Regularization mainly reduces the absolute size of coefficients but does not alter their interpretation. These results reinforce the robustness of the main clinical signals age, performance status, and tumor grade as reliable determinants of treatment response, even under different modeling assumptions and penalty schemes.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Q3. Molecular biomarkers: which genes are associated with response? ----</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Goal: identify gene predictors associated with continuous response (response_percent)</span></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Models used: OLS (with p-values and BH-FDR), LASSO, Ridge, Elastic Net (coefficients)</span></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Assumptions:</span></span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a><span class="co">#   - Genes are encoded as columns whose names start with "gene_" in X_train/X_test</span></span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a><span class="co">#   - No interactions in the model</span></span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a><span class="co">#   - mod_ols was fit with response_percent ~ clinical + genes (no interactions)</span></span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a><span class="co">#   - mod_lasso, mod_ridge, mod_enet were fit with glmnet on (X_train, y_train)</span></span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>({</span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(dplyr)</span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(stringr)</span>
<span id="cb84-12"><a href="#cb84-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(tibble)</span>
<span id="cb84-13"><a href="#cb84-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(broom)</span>
<span id="cb84-14"><a href="#cb84-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(purrr)</span>
<span id="cb84-15"><a href="#cb84-15" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb84-16"><a href="#cb84-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-17"><a href="#cb84-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 0) Identify gene columns from the model matrix you used to fit glmnet</span></span>
<span id="cb84-18"><a href="#cb84-18" aria-hidden="true" tabindex="-1"></a>gene_terms <span class="ot">&lt;-</span> <span class="fu">colnames</span>(X_train)[<span class="fu">str_detect</span>(<span class="fu">colnames</span>(X_train), <span class="st">"^gene_"</span>)]</span>
<span id="cb84-19"><a href="#cb84-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-20"><a href="#cb84-20" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Helper to extract glmnet coefs for a list of terms ----------------------</span></span>
<span id="cb84-21"><a href="#cb84-21" aria-hidden="true" tabindex="-1"></a>get_glmnet_coefs <span class="ot">&lt;-</span> <span class="cf">function</span>(mod_glmnet, terms_keep, <span class="at">colname =</span> <span class="st">"beta"</span>) {</span>
<span id="cb84-22"><a href="#cb84-22" aria-hidden="true" tabindex="-1"></a>  B <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">coef</span>(mod_glmnet))</span>
<span id="cb84-23"><a href="#cb84-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">term =</span> <span class="fu">rownames</span>(B), <span class="sc">!!</span><span class="at">colname :=</span> <span class="fu">as.numeric</span>(B[, <span class="dv">1</span>])) <span class="sc">%&gt;%</span></span>
<span id="cb84-24"><a href="#cb84-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(term <span class="sc">!=</span> <span class="st">"(Intercept)"</span>, term <span class="sc">%in%</span> terms_keep)</span>
<span id="cb84-25"><a href="#cb84-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb84-26"><a href="#cb84-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-27"><a href="#cb84-27" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) OLS gene table with t-stat and FDR ---------------------------------------</span></span>
<span id="cb84-28"><a href="#cb84-28" aria-hidden="true" tabindex="-1"></a>ols_genes <span class="ot">&lt;-</span> <span class="fu">tidy</span>(mod_ols, <span class="at">conf.int =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb84-29"><a href="#cb84-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(term <span class="sc">%in%</span> gene_terms) <span class="sc">%&gt;%</span></span>
<span id="cb84-30"><a href="#cb84-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb84-31"><a href="#cb84-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">beta_ols =</span> estimate,</span>
<span id="cb84-32"><a href="#cb84-32" aria-hidden="true" tabindex="-1"></a>    <span class="at">se_ols   =</span> std.error,</span>
<span id="cb84-33"><a href="#cb84-33" aria-hidden="true" tabindex="-1"></a>    <span class="at">t_ols    =</span> statistic,</span>
<span id="cb84-34"><a href="#cb84-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">p_ols    =</span> p.value,</span>
<span id="cb84-35"><a href="#cb84-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">fdr_bh   =</span> <span class="fu">p.adjust</span>(p_ols, <span class="at">method =</span> <span class="st">"BH"</span>),</span>
<span id="cb84-36"><a href="#cb84-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">imp_ols  =</span> <span class="fu">abs</span>(t_ols)             <span class="co"># importance = |t|</span></span>
<span id="cb84-37"><a href="#cb84-37" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb84-38"><a href="#cb84-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term, beta_ols, se_ols, t_ols, p_ols, fdr_bh, imp_ols)</span>
<span id="cb84-39"><a href="#cb84-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-40"><a href="#cb84-40" aria-hidden="true" tabindex="-1"></a>top10_ols <span class="ot">&lt;-</span> ols_genes <span class="sc">%&gt;%</span></span>
<span id="cb84-41"><a href="#cb84-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(imp_ols)) <span class="sc">%&gt;%</span></span>
<span id="cb84-42"><a href="#cb84-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_head</span>(<span class="at">n =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb84-43"><a href="#cb84-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Model =</span> <span class="st">"OLS"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb84-44"><a href="#cb84-44" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Model, term, <span class="at">beta =</span> beta_ols, <span class="at">importance =</span> imp_ols, t_ols, p_ols, fdr_bh)</span>
<span id="cb84-45"><a href="#cb84-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-46"><a href="#cb84-46" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) LASSO / Ridge / Elastic Net gene coefficients (importance = |beta|) ------</span></span>
<span id="cb84-47"><a href="#cb84-47" aria-hidden="true" tabindex="-1"></a>lasso_genes <span class="ot">&lt;-</span> <span class="fu">get_glmnet_coefs</span>(mod_lasso, gene_terms, <span class="at">colname =</span> <span class="st">"beta_lasso"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb84-48"><a href="#cb84-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">imp_lasso =</span> <span class="fu">abs</span>(beta_lasso))</span>
<span id="cb84-49"><a href="#cb84-49" aria-hidden="true" tabindex="-1"></a>ridge_genes <span class="ot">&lt;-</span> <span class="fu">get_glmnet_coefs</span>(mod_ridge, gene_terms, <span class="at">colname =</span> <span class="st">"beta_ridge"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb84-50"><a href="#cb84-50" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">imp_ridge =</span> <span class="fu">abs</span>(beta_ridge))</span>
<span id="cb84-51"><a href="#cb84-51" aria-hidden="true" tabindex="-1"></a>enet_genes  <span class="ot">&lt;-</span> <span class="fu">get_glmnet_coefs</span>(mod_enet,  gene_terms, <span class="at">colname =</span> <span class="st">"beta_enet"</span>)  <span class="sc">%&gt;%</span></span>
<span id="cb84-52"><a href="#cb84-52" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">imp_enet  =</span> <span class="fu">abs</span>(beta_enet))</span>
<span id="cb84-53"><a href="#cb84-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-54"><a href="#cb84-54" aria-hidden="true" tabindex="-1"></a>top10_lasso <span class="ot">&lt;-</span> lasso_genes <span class="sc">%&gt;%</span></span>
<span id="cb84-55"><a href="#cb84-55" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(imp_lasso)) <span class="sc">%&gt;%</span></span>
<span id="cb84-56"><a href="#cb84-56" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_head</span>(<span class="at">n =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb84-57"><a href="#cb84-57" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Model =</span> <span class="st">"LASSO"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb84-58"><a href="#cb84-58" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Model, term, <span class="at">beta =</span> beta_lasso, <span class="at">importance =</span> imp_lasso)</span>
<span id="cb84-59"><a href="#cb84-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-60"><a href="#cb84-60" aria-hidden="true" tabindex="-1"></a>top10_ridge <span class="ot">&lt;-</span> ridge_genes <span class="sc">%&gt;%</span></span>
<span id="cb84-61"><a href="#cb84-61" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(imp_ridge)) <span class="sc">%&gt;%</span></span>
<span id="cb84-62"><a href="#cb84-62" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_head</span>(<span class="at">n =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb84-63"><a href="#cb84-63" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Model =</span> <span class="st">"Ridge"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb84-64"><a href="#cb84-64" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Model, term, <span class="at">beta =</span> beta_ridge, <span class="at">importance =</span> imp_ridge)</span>
<span id="cb84-65"><a href="#cb84-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-66"><a href="#cb84-66" aria-hidden="true" tabindex="-1"></a>top10_enet <span class="ot">&lt;-</span> enet_genes <span class="sc">%&gt;%</span></span>
<span id="cb84-67"><a href="#cb84-67" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(imp_enet)) <span class="sc">%&gt;%</span></span>
<span id="cb84-68"><a href="#cb84-68" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_head</span>(<span class="at">n =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb84-69"><a href="#cb84-69" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Model =</span> <span class="st">"Elastic Net"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb84-70"><a href="#cb84-70" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Model, term, <span class="at">beta =</span> beta_enet, <span class="at">importance =</span> imp_enet)</span>
<span id="cb84-71"><a href="#cb84-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-72"><a href="#cb84-72" aria-hidden="true" tabindex="-1"></a><span class="co"># 3) Combine into a single tidy table -----------------------------------------</span></span>
<span id="cb84-73"><a href="#cb84-73" aria-hidden="true" tabindex="-1"></a>top10_all_models <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(</span>
<span id="cb84-74"><a href="#cb84-74" aria-hidden="true" tabindex="-1"></a>  top10_ols,</span>
<span id="cb84-75"><a href="#cb84-75" aria-hidden="true" tabindex="-1"></a>  top10_lasso,</span>
<span id="cb84-76"><a href="#cb84-76" aria-hidden="true" tabindex="-1"></a>  top10_ridge,</span>
<span id="cb84-77"><a href="#cb84-77" aria-hidden="true" tabindex="-1"></a>  top10_enet</span>
<span id="cb84-78"><a href="#cb84-78" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb84-79"><a href="#cb84-79" aria-hidden="true" tabindex="-1"></a>  <span class="co"># rank within model by importance (1 = most important)</span></span>
<span id="cb84-80"><a href="#cb84-80" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Model) <span class="sc">%&gt;%</span></span>
<span id="cb84-81"><a href="#cb84-81" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(importance), <span class="at">.by_group =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb84-82"><a href="#cb84-82" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">rank =</span> <span class="fu">row_number</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb84-83"><a href="#cb84-83" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span>
<span id="cb84-84"><a href="#cb84-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-85"><a href="#cb84-85" aria-hidden="true" tabindex="-1"></a><span class="co"># View the result (one long table with 10 rows per model)#</span></span>
<span id="cb84-86"><a href="#cb84-86" aria-hidden="true" tabindex="-1"></a><span class="co">#top10_all_models</span></span>
<span id="cb84-87"><a href="#cb84-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-88"><a href="#cb84-88" aria-hidden="true" tabindex="-1"></a><span class="co"># Optional: a wide, side-by-side comparison (terms only) ----------------------</span></span>
<span id="cb84-89"><a href="#cb84-89" aria-hidden="true" tabindex="-1"></a>top10_wide_terms <span class="ot">&lt;-</span> top10_all_models <span class="sc">%&gt;%</span></span>
<span id="cb84-90"><a href="#cb84-90" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(Model, rank) <span class="sc">%&gt;%</span></span>
<span id="cb84-91"><a href="#cb84-91" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Model, rank, term) <span class="sc">%&gt;%</span></span>
<span id="cb84-92"><a href="#cb84-92" aria-hidden="true" tabindex="-1"></a>  tidyr<span class="sc">::</span><span class="fu">pivot_wider</span>(<span class="at">names_from =</span> Model, <span class="at">values_from =</span> term)</span>
<span id="cb84-93"><a href="#cb84-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-94"><a href="#cb84-94" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(top10_wide_terms)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   rank Elastic.Net     LASSO       OLS     Ridge
1     1     gene_19   gene_19   gene_14   gene_14
2     2     gene_08   gene_08   gene_08   gene_19
3     3     gene_14   gene_14   gene_19   gene_08
4     4     gene_05   gene_05   gene_05   gene_05
5     5     gene_01   gene_01   gene_01   gene_01
6     6     gene_12   gene_12   gene_12   gene_12
7     7   gene_1976 gene_1778 gene_1024 gene_1419
8     8   gene_1419 gene_1241   gene_27 gene_1506
9     9   gene_1241 gene_1428 gene_1419 gene_1976
10   10   gene_1428 gene_1976 gene_1927  gene_907</code></pre>
</div>
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Optional: barplot for a quick visual per model ------------------------------</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="co"># (Make sure ggplot2 is loaded.)</span></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ggplot(top10_all_models, aes(x = reorder(term, importance), y = importance)) +</span></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   geom_col() +</span></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a><span class="co">#   coord_flip() +</span></span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a><span class="co">#   facet_wrap(~ Model, scales = "free_y") +</span></span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a><span class="co">#   labs(x = "Gene", y = "Importance (|t| for OLS; |β| for penalized models)",</span></span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a><span class="co">#        title = "Top 10 genes by model") +</span></span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a><span class="co">#   theme_minimal(base_size = 12)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The last table compares the top ten genes most strongly associated with tumor response according to four regression models OLS, LASSO, Ridge, and Elastic Net based on the magnitude of each gene’s estimated effect. While the specific coefficient values are not shown here, the ranking reveals how different modeling strategies emphasize or penalize predictors in slightly distinct ways. A clear pattern emerges across all methods: several genes consistently appear among the most influential. gene_19, gene_08, gene_14, gene_05, gene_01, and gene_12 are common to nearly every model, suggesting that these markers carry robust predictive information about treatment response. Their presence across OLS (which estimates effects freely), LASSO and Elastic Net (which perform variable selection), and Ridge (which shrinks but retains all coefficients) indicates that these signals are not artifacts of a particular modeling assumption but stable features of the dataset. The agreement among Elastic Net and LASSO is especially notable. Both methods rely on sparsity-inducing penalties, and they rank genes gene_19, gene_08, gene_14, gene_05, gene_01, and gene_12 in nearly identical order. This consistency supports the interpretation that these genes represent the core set most predictive of tumor shrinkage. The few differences such as the inclusion of gene_1976 or gene_1241 in the Elastic Net list reflect the method’s ability to keep correlated predictors that LASSO might exclude. The Ridge model, which shrinks coefficients without setting any to zero, yields a slightly more diverse list. It retains the same leading genes (gene_14, gene_19, gene_08, gene_05, gene_01, gene_12) but also highlights additional candidates such as gene_1419, gene_1506, gene_1976, and gene_907. This broader selection reflects Ridge’s tendency to distribute importance among correlated features, capturing groups of genes that may be co-expressed or functionally linked. Finally, OLS, which lacks regularization, identifies a very similar top tier dominated by gene_14, gene_08, and gene_19. Its overlap with the penalized models suggests that these genes have both strong individual associations and stability under penalization key indicators of biological and statistical relevance. In summary, despite methodological differences, all models converge on a common biological signature: a small set of genes (notably gene_19, gene_08, gene_14, gene_05, gene_01, and gene_12) emerge as consistent predictors of tumor response. The regularized approaches (especially Elastic Net) reinforce their robustness while reducing noise from less informative or redundant variables. Together, these findings highlight a reproducible molecular profile potentially linked to therapeutic sensitivity.</p>
</section>
<section id="predictive-modeling" class="level3" data-number="2.13.3">
<h3 data-number="2.13.3" class="anchored" data-anchor-id="predictive-modeling"><span class="header-section-number">2.13.3</span> Predictive modeling:</h3>
<p>Given a patient’s main-effect clinical and molecular profile, how well do OLS, Ridge, LASSO, and Elastic Net predict tumor shrinkage (MAE/RMSE on train/test).</p>
<p>The answert to this question relates directly with the comparison we did regarding OLS, Rige, LASSO and Elastic net MAE and RMSEs.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print results</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>metrics_train</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 5
  Model           MAE  RMSE Alpha Lambda
  &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
1 OLS            1.27  1.59 NA    NA    
2 LASSO (λ.min)  1.49  1.87  1    NA    
3 Ridge (λ.min)  1.43  1.79  0    NA    
4 Elastic Net    1.50  1.88  0.15  0.181</code></pre>
</div>
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>metrics_test</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 5
  Model           MAE  RMSE Alpha Lambda
  &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
1 OLS            1.83  2.28 NA    NA    
2 LASSO (λ.min)  1.57  1.96  1    NA    
3 Ridge (λ.min)  1.77  2.23  0    NA    
4 Elastic Net    1.57  1.95  0.15  0.181</code></pre>
</div>
</div>
</section>
</section>
<section id="logistic-regression" class="level2" data-number="2.14">
<h2 data-number="2.14" class="anchored" data-anchor-id="logistic-regression"><span class="header-section-number">2.14</span> Logistic Regression</h2>
<p>Logistic regression models the probability that a patient is a high responder using a logistic ( S -shaped) link. Instead of predicting a continuous shrinkage value, we now predict <span class="math inline">\(P(Y=1 \mid X)\)</span>, where <span class="math inline">\(Y=1\)</span> means a clinically meaningful tumor reduction. The model is linear on the log-odds scale:</p>
<p><span class="math display">\[
\operatorname{Pr}(Y=1 \mid X)=\frac{1}{1+\exp \left\{-\left(w_0+w_1 x_1+\cdots+w_p x_p\right)\right\}}
\]</span></p>
<p>Coefficients remain interpretable: a positive <span class="math inline">\(w_j\)</span> increases the log-odds, which increases the probability of high response, holding other variables fixed. We will fit a clean, leakage-free specification that excludes identifiers and any variables used to compute the continuous outcome.</p>
<p>An alternative representation for a logistic regression model is the following diagram that has a structure of a network. We will come back this in later chapters. Can you guess which kind of networks is this?</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
    x1["x₁"] --&gt; w1["× w₁"]
    x2["x₂"] --&gt; w2["× w₂"]
    xp["xₚ"] --&gt; wp["× wₚ"]

    w1 --&gt; SUM
    w2 --&gt; SUM
    wp --&gt; SUM

    SUM["Σ (wⱼ xⱼ + b)"] --&gt; ACT["σ ( · )  (sigmoid)"]
    ACT --&gt; y["ŷ"]

</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>Metrics we will use to compare models We will evaluate models with threshold-based metrics and threshold-free curves.</p>
<ul>
<li><p>Accuracy: fraction of correct classifications.</p></li>
<li><p>Sensitivity (recall): fraction of true positives captured.</p></li>
<li><p>Specificity: fraction of true negatives correctly rejected.</p></li>
<li><p>Precision (PPV): among predicted positives, fraction that are truly positive.</p></li>
<li><p>F1: harmonic mean of precision and recall.</p></li>
<li><p>ROC and AUC: trade-off between TPR and FPR across all thresholds; AUC summarizes discrimination from 0.5 (random) a 1.0 (perfeito).</p></li>
<li><p>Precision-Recall and AUC-PR: useful when we have unbalanced data, focus on performance in the rare set.</p></li>
</ul>
<section id="understanding-roc-and-auc-through-examples" class="level3" data-number="2.14.1">
<h3 data-number="2.14.1" class="anchored" data-anchor-id="understanding-roc-and-auc-through-examples"><span class="header-section-number">2.14.1</span> Understanding ROC and AUC through examples</h3>
<p>The ROC curve (Receiver Operating Characteristic) and the AUC (Area Under the Curve) are fundamental tools for evaluating binary classification models. The series of plots generated by the next blocks of code illustrates how ROC curves behave under different modeling situations, helping us understand what a “good,” “bad,” or “misleading” model looks like. The examples are from simulated data and not related to our motivational context.</p>
<p>Each plot shows&nbsp;sensitivity&nbsp;(true positive rate) on the vertical axis and&nbsp;1 – specificity&nbsp;(false positive rate) on the horizontal axis. A diagonal line represents the performance of a random classifier. Curves that rise sharply toward the upper-left corner correspond to models that discriminate well between positive and negative cases. The AUC value, printed in the title of each facet, summarizes this ability numerically.</p>
<p>In the first scenario, labeled&nbsp;Excellent model, the two classes are highly separable. T</p>
<p>The name “logistic” comes from the&nbsp;<strong>logit</strong>, or&nbsp;<strong>log-odds</strong>, transformation that the model uses. Instead of modeling the probability itself, it models the&nbsp;<em>log of the odds</em>&nbsp;of success (for example, the log of the odds of being a high responder). This logit is linear in the predictors, which means we can still use familiar regression ideas while keeping the predictions bounded between 0 and 1</p>
</section>
<section id="logistic-regression-in-our-motivating-example" class="level3" data-number="2.14.2">
<h3 data-number="2.14.2" class="anchored" data-anchor-id="logistic-regression-in-our-motivating-example"><span class="header-section-number">2.14.2</span> Logistic Regression in our motivating example</h3>
<p>Our response variable is now <code>high_response</code> (binary, 0/1): equal to 1 if&nbsp;<code>response_percent ≥ 30</code>(similar to RECIST clinical criteria)&nbsp;<span class="citation" data-cites="eisenhauer2009recist">Eisenhauer et al. (<a href="references.html#ref-eisenhauer2009recist" role="doc-biblioref">2009</a>)</span>.</p>
<p>The next chunk of code makes sure that the response is binary, and prepare the datasets for analysis and the formula we will use in the R function `glm` that will fit the logistic regression for us.</p>
<p>In logistic regression, the model does not minimize squared errors like ordinary least squares does. Instead, it estimates the coefficients <span class="math inline">\(\boldsymbol{\beta}\)</span> that make the observed data most probable under the assumed binomial distribution, a distribution that models binary outcomes. This is achieved through Maximum Likelihood Estimation (MLE). In essence, MLE finds the set of parameters <span class="math inline">\(\beta\)</span> that maximize the log-likelihood function, which measures how well the model’s predicted probabilities align with the actual outcomes. For each observation, the model computes the probability of belonging to class 1 (success) as <span class="math inline">\(\hat{p}_i=\frac{1}{1+e^{-\left(x_i^T w\right)}}\)</span>; the log-likelihood then accumulates the logarithm of these probabilities across all samples. Maximizing this quantity ensures that the estimated coefficients produce predicted probabilities that are as consistent as possible with the observed binary responses.</p>
</section>
<section id="roc-and-auc" class="level3" data-number="2.14.3">
<h3 data-number="2.14.3" class="anchored" data-anchor-id="roc-and-auc"><span class="header-section-number">2.14.3</span> ROC and AUC</h3>
<p>Before moving to the code that implements these methods, it is useful to understand two fundamental concepts for evaluating the performance of binary classification models: the&nbsp;<strong>Receiver Operating Characteristic (ROC) curve</strong>&nbsp;and the&nbsp;<strong>Area Under the Curve (AUC)</strong>.</p>
<p>When a model predicts probabilities such as the likelihood that a patient will show a high tumor response it is not limited to a single classification threshold (for example, 0.5). Instead, the threshold can vary. For each possible threshold, the model produces a different balance between&nbsp;<strong>sensitivity</strong>&nbsp;(the proportion of true responders correctly identified) and&nbsp;<strong>specificity</strong>&nbsp;(the proportion of non-responders correctly rejected).</p>
<p>The ROC curve visualizes this trade-off. It plots&nbsp;<strong>sensitivity</strong>&nbsp;on the vertical axis against&nbsp;<strong>1 – specificity</strong>&nbsp;on the horizontal axis, across all thresholds from 0 to 1. Each point on the curve represents a possible decision rule. A model that predicts perfectly has a curve that rises immediately to the top-left corner of the plot (sensitivity = 1, specificity = 1). A model that performs no better than random chance follows the diagonal line from (0, 0) to (1, 1).</p>
<p>The&nbsp;<strong>Area Under the ROC Curve (AUC)</strong>&nbsp;condenses this information into a single number between 0 and 1. An AUC of 1 indicates perfect discrimination: the model always ranks true responders above non-responders. An AUC of 0.5 corresponds to random guessing. Values between 0.7 and 0.8 are generally considered acceptable, 0.8 to 0.9 good, and above 0.9 excellent, though interpretation depends on the context and the consequences of errors.</p>
<p>In the context of our clinical trial, the ROC curve tells us how well the logistic regression model can distinguish patients who achieve a meaningful tumor reduction from those who do not. The AUC gives an overall summary of this discrimination ability, independent of any specific threshold. It is particularly useful in medicine, where the decision threshold may later be adjusted to achieve a desired balance between missing true responders (false negatives) and incorrectly labeling non-responders as high responders (false positives).</p>
<p>he ROC curve quickly approaches the top-left corner, and the AUC is close to 1. This means the model ranks nearly all true responders above non-responders, providing excellent discrimination.</p>
<p>In the second panel,&nbsp;<em>Reasonable model</em>, the curve still bows above the diagonal, but less dramatically. The AUC is around 0.8–0.9, which is common in real clinical prediction problems. This represents a solid model that balances sensitivity and specificity reasonably well.</p>
<p>The third example,&nbsp;<em>Near random</em>, has an ROC curve close to the diagonal with an AUC around 0.5. This model is essentially guessing; its predictions carry no discriminative information beyond random chance.</p>
<p>The fourth panel,&nbsp;<em>Inverted score</em>, shows a curve that falls below the diagonal. Here the model systematically reverses the ordering of cases high probabilities are assigned to negatives and low probabilities to positives. In practice, such a model can be “fixed” simply by reversing its decision rule, but its presence is a clear sign that something in the data or labeling is inverted.</p>
<p>The fifth case,&nbsp;<em>Imbalanced classes</em>, demonstrates a subtle but important limitation of the ROC curve. Even with a heavily skewed dataset (for example, many more non-responders than responders), the ROC may still appear fairly high. However, when the number of positive cases is small,&nbsp;<strong>precision</strong> the proportion of predicted positives that are correct can drop sharply even if the ROC looks good. For this reason, the code also produces&nbsp;<strong>Precision–Recall (PR)</strong>&nbsp;curves, which tend to give a clearer picture when class imbalance is severe. In these PR plots, precision is shown against recall, and a high-quality model maintains both values simultaneously at high levels.</p>
<p>The final figure illustrates the effect of changing the decision&nbsp;<strong>threshold</strong>. Each dot along the ROC curve corresponds to a different cutoff value for the predicted probability. Lowering the threshold increases sensitivity (the model captures more true responders) but also raises the false positive rate. Raising the threshold has the opposite effect: fewer false alarms, but more missed responders. Choosing the “best” threshold depends on clinical priorities whether we prefer to err on the side of overtreatment (high sensitivity) or undertreatment (high specificity).</p>
<p>Taken together, these plots demonstrate that ROC curves and AUC values offer a concise but nuanced summary of model discrimination. A high AUC indicates that the model generally ranks positive cases above negative ones, but the exact trade-off between sensitivity and specificity still depends on how we set the classification threshold. Complementing ROC and AUC with PR curves and context-specific thresholds ensures a more complete understanding of predictive performance, especially in medical settings where the balance between false positives and false negatives carries real clinical implications.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/unnamed-chunk-35-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/unnamed-chunk-35-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/unnamed-chunk-35-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="penalized-logistic-models-lasso-ridge-and-elastic-net" class="level3" data-number="2.14.4">
<h3 data-number="2.14.4" class="anchored" data-anchor-id="penalized-logistic-models-lasso-ridge-and-elastic-net"><span class="header-section-number">2.14.4</span> Penalized logistic models: LASSO, Ridge, and Elastic Net</h3>
<p>High dimensionality and correlated features make it hard to interpret thousands of coefficients and can hurt generalization. Penalized logistic regression addresses this by shrinking coefficients. Ridge (L2) shrinks all coefficients toward zero without removing variables. LASSO (L1) can set some coefficients exactly to zero, performing embedded feature selection. Elastic Net blends both penalties and is helpful when many predictors are correlated. We fit all three using the binomial family so the comparison with logistic regression is fair. We always evaluate probabilities from these models in ROC and PR calculations.</p>
</section>
<section id="fitting-logistic-regression-and-equivalent-lasso-ridgeand-elastic-net-approaches" class="level3" data-number="2.14.5">
<h3 data-number="2.14.5" class="anchored" data-anchor-id="fitting-logistic-regression-and-equivalent-lasso-ridgeand-elastic-net-approaches"><span class="header-section-number">2.14.5</span> Fitting Logistic Regression and equivalent LASSO, RIDGE,and Elastic Net Approaches</h3>
<p>To make the results reproducible by users with any kind of machine we will first create a smaller version of our dataset containing only 100 genes.</p>
<p>The next chunk reads the smaller version of the data. In this dataset we have a subset of the 1000 genes, this is the reason for genes names not being 1….2000.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === Load the reduced dataset and quick checks ================================</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>({</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(dplyr)</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>ct_reduced <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"~/att_ai_ml/data/ct_reduced_v1.rds"</span>)</span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Basic sanity checks</span></span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(ct_reduced)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 10000   106</code></pre>
</div>
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(ct_reduced)[<span class="dv">1</span><span class="sc">:</span><span class="fu">min</span>(<span class="dv">20</span>, <span class="fu">ncol</span>(ct_reduced))]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] "treatment"         "dose_intensity"    "patient_age"      
 [4] "tumor_grade"       "performance_score" "gene_1242"        
 [7] "gene_397"          "gene_1754"         "gene_355"         
[10] "gene_308"          "gene_234"          "gene_1598"        
[13] "gene_1551"         "gene_588"          "gene_779"         
[16] "gene_599"          "gene_2000"         "gene_1190"        
[19] "gene_1568"         "gene_1321"        </code></pre>
</div>
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(ct_reduced)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   10000 obs. of  106 variables:
 $ treatment        : Factor w/ 2 levels "no_chemo","chemo": 2 1 1 1 2 2 1 2 1 2 ...
 $ dose_intensity   : num  1.08 0 0 0 1.01 ...
 $ patient_age      : num  81 61 81 74 41 74 22 61 26 22 ...
 $ tumor_grade      : Factor w/ 3 levels "G1","G2","G3": 2 2 3 2 2 2 1 2 3 2 ...
 $ performance_score: int  1 1 1 0 1 1 2 0 1 0 ...
 $ gene_1242        : num  9.15 6.34 7.55 4.64 6.12 ...
 $ gene_397         : num  6.34 8.44 7.13 9.8 9.67 ...
 $ gene_1754        : num  5.34 8.27 6.9 5.74 5.49 ...
 $ gene_355         : num  8.06 9.06 8.91 6.84 7.21 ...
 $ gene_308         : num  10.39 8.81 9.73 7.17 7.9 ...
 $ gene_234         : num  8.38 8.83 8.4 10.43 10.81 ...
 $ gene_1598        : num  7.56 11 9.45 9.79 9.41 ...
 $ gene_1551        : num  5.96 9.13 7.99 7.87 7.28 ...
 $ gene_588         : num  8.79 4.28 6.6 5.04 5.94 ...
 $ gene_779         : num  8.29 4.05 5.63 4.39 5.12 ...
 $ gene_599         : num  9.35 5.89 7.31 5.74 6.55 ...
 $ gene_2000        : num  9.63 7.43 8.14 6.3 6.44 ...
 $ gene_1190        : num  7.8 6.28 7.72 5.2 5.3 ...
 $ gene_1568        : num  8.62 7.09 8.41 5.41 5.97 ...
 $ gene_1321        : num  6.94 4.74 5.6 6.14 6.53 ...
 $ gene_1379        : num  7.63 4.72 5.91 4.12 4.64 ...
 $ gene_746         : num  6.62 9.59 8.43 9.21 9.36 ...
 $ gene_1480        : num  12.8 11.9 12.5 13.6 13.9 ...
 $ gene_1973        : num  7.73 9.63 9.2 11.02 10.55 ...
 $ gene_1448        : num  8.36 9.11 9.25 10.44 10.87 ...
 $ gene_1733        : num  8.62 9.31 9.51 7.86 8.09 ...
 $ gene_41          : num  9.21 7.15 8.6 5.2 5.9 ...
 $ gene_1668        : num  7.02 7.55 7.11 8.68 8.46 ...
 $ gene_1400        : num  7.15 9.14 9.23 7.51 7.77 ...
 $ gene_1716        : num  5.66 8.06 7.21 7 6.89 ...
 $ gene_1213        : num  8.31 9.42 9 6.85 7.21 ...
 $ gene_873         : num  8.9 9.47 8.53 10.9 10.53 ...
 $ gene_207         : num  8.2 4.94 6.85 4.77 5.29 ...
 $ gene_609         : num  9.53 5.43 7.58 7.2 7.43 ...
 $ gene_1923        : num  6.72 9.03 8.05 9.67 9.14 ...
 $ gene_772         : num  8.3 5.56 6.6 4.61 5.24 ...
 $ gene_1039        : num  6.4 2.99 3.99 4.44 4.66 ...
 $ gene_1291        : num  7.87 5.9 7.13 4.26 5.25 ...
 $ gene_58          : num  7.87 5.55 6.54 4.29 4.83 ...
 $ gene_1760        : num  8.53 11.48 10.64 11 10.96 ...
 $ gene_1232        : num  6.9 10.18 8.68 9.72 9.23 ...
 $ gene_1925        : num  6.74 9.46 8.76 9.63 9.39 ...
 $ gene_340         : num  8.04 5.27 6.25 4.5 5.5 ...
 $ gene_663         : num  6.73 5.7 5.92 7.5 6.88 ...
 $ gene_681         : num  9.33 11.85 10.72 11.88 11.28 ...
 $ gene_1596        : num  8.57 6.87 7.99 8.61 9.36 ...
 $ gene_821         : num  9.9 9 9.22 7.91 7.64 ...
 $ gene_94          : num  7.07 10.25 9.02 9.21 8.83 ...
 $ gene_814         : num  9.67 9.43 9.13 11.23 11.75 ...
 $ gene_719         : num  7.67 9.99 9.59 10.78 10.31 ...
 $ gene_122         : num  10.63 7.86 9.68 9.93 10.12 ...
 $ gene_1240        : num  8.11 9.81 9.22 7.75 7.62 ...
 $ gene_577         : num  7.99 7.24 7.91 5.92 5.57 ...
 $ gene_1233        : num  8.47 9.85 9.58 8.99 8.55 ...
 $ gene_1811        : num  5.15 9.11 6.91 7.83 7.81 ...
 $ gene_713         : num  9.17 9.19 9.81 8.37 7.77 ...
 $ gene_819         : num  6.83 6.82 7.52 5.99 5.88 ...
 $ gene_1196        : num  8.61 5.52 7.53 5.67 6.2 ...
 $ gene_56          : num  9.82 11.92 10.52 12.27 11.62 ...
 $ gene_1188        : num  7.96 7.07 7.63 5.88 5.97 ...
 $ gene_1319        : num  7.12 6.62 7.17 8.65 8.2 ...
 $ gene_1820        : num  9.55 9.21 9.55 7.33 7.9 ...
 $ gene_926         : num  6.4 8.88 7.85 8.8 8.17 ...
 $ gene_1698        : num  5.39 4.88 5.97 3.48 4.02 ...
 $ gene_1690        : num  8.9 7.24 8.09 6.53 7.3 ...
 $ gene_1758        : num  7.05 6.13 6.55 4.88 5.44 ...
 $ gene_1909        : num  8.39 11.61 10.65 11.21 10.83 ...
 $ gene_1003        : num  6.47 9.16 7.79 8.45 8.03 ...
 $ gene_890         : num  7.18 9.41 9.01 10.49 9.55 ...
 $ gene_186         : num  7.28 7.69 7.89 6.38 6.82 ...
 $ gene_1912        : num  7.82 5.25 7.02 4.84 5.09 ...
 $ gene_787         : num  8.28 4.86 6.78 5.39 6.16 ...
 $ gene_967         : num  5.7 6.21 6.14 4.4 4.78 ...
 $ gene_233         : num  7.88 5.22 6.81 7.11 7.25 ...
 $ gene_564         : num  8.28 10.65 9.85 9.52 9.29 ...
 $ gene_307         : num  9.96 10.27 10.56 7.9 8.56 ...
 $ gene_1099        : num  8.56 10.69 9.48 10.21 9.53 ...
 $ gene_1460        : num  6.46 3.58 4.58 3.36 4.57 ...
 $ gene_1830        : num  5.11 7 6.18 7.59 7.26 ...
 $ gene_289         : num  7.53 4.57 5.83 6.41 6.27 ...
 $ gene_1740        : num  10.31 8.9 10.31 7.95 8.67 ...
 $ gene_1116        : num  11.36 9.97 10.66 12.17 11.82 ...
 $ gene_1946        : num  10.12 9.64 9.98 7.82 8.42 ...
 $ gene_371         : num  10.82 8.71 9.29 10.47 10.59 ...
 $ gene_1033        : num  12.3 13.8 13.2 14.8 14.2 ...
 $ gene_579         : num  8.39 9.28 9.36 8.57 9.26 ...
 $ gene_333         : num  8.79 8.73 8.16 9.2 8.9 ...
 $ gene_1222        : num  6.78 7.3 7.32 6.71 6.57 ...
 $ gene_1139        : num  10.48 9.69 10.02 10.82 10.64 ...
 $ gene_1302        : num  8.87 6.51 7.46 7.85 8.06 ...
 $ gene_1215        : num  7.42 8.53 8.2 7.68 7.62 ...
 $ gene_655         : num  7.44 5.14 5.82 5.39 5.6 ...
 $ gene_50          : num  7.93 7.18 7.6 7.37 7.6 ...
 $ gene_1195        : num  7.31 8.83 8.35 9.25 8.63 ...
 $ gene_1380        : num  6.96 5.45 6.14 5.2 5.33 ...
 $ gene_24          : num  10.34 9.81 9.98 9.37 9.3 ...
 $ gene_1940        : num  7.64 6.54 7.27 6.62 6.88 ...
 $ gene_370         : num  4.34 5 4.65 5.19 5.09 ...
 $ gene_1687        : num  8.6 9.92 9.11 10.74 10.32 ...
  [list output truncated]
 - attr(*, "created_with")= chr "variance+random gene selection (80+20), target_total_genes=100"
 - attr(*, "created_at")= POSIXct[1:1], format: "2025-11-11 11:42:34"</code></pre>
</div>
</div>
<p>First we force the data to be binary</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === Ensure binary target and remove any accidental leakage ===================</span></span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ct_reduced SHOULD already include 'high_response' (0/1). We enforce 0/1 safely.</span></span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a>to_binary01 <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">is.logical</span>(x)) <span class="fu">return</span>(<span class="fu">as.integer</span>(x))</span>
<span id="cb97-6"><a href="#cb97-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">is.factor</span>(x))  <span class="fu">return</span>(<span class="fu">as.integer</span>(<span class="fu">as.numeric</span>(x) <span class="sc">==</span> <span class="fu">max</span>(<span class="fu">as.numeric</span>(x))))</span>
<span id="cb97-7"><a href="#cb97-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.integer</span>(x)</span>
<span id="cb97-8"><a href="#cb97-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb97-9"><a href="#cb97-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-10"><a href="#cb97-10" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="st">"high_response"</span> <span class="sc">%in%</span> <span class="fu">names</span>(ct_reduced)) {</span>
<span id="cb97-11"><a href="#cb97-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stop</span>(<span class="st">"`high_response` is not in ct_reduced. Recreate ct_reduced with the target."</span>)</span>
<span id="cb97-12"><a href="#cb97-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb97-13"><a href="#cb97-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-14"><a href="#cb97-14" aria-hidden="true" tabindex="-1"></a>ct_reduced <span class="ot">&lt;-</span> ct_reduced <span class="sc">%&gt;%</span></span>
<span id="cb97-15"><a href="#cb97-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">high_response =</span> <span class="fu">to_binary01</span>(high_response))</span>
<span id="cb97-16"><a href="#cb97-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-17"><a href="#cb97-17" aria-hidden="true" tabindex="-1"></a><span class="co"># If any of these exist, drop them for modeling as potential leakage/IDs.</span></span>
<span id="cb97-18"><a href="#cb97-18" aria-hidden="true" tabindex="-1"></a>leak_or_id <span class="ot">&lt;-</span> <span class="fu">intersect</span>(</span>
<span id="cb97-19"><a href="#cb97-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(<span class="st">"patient_id"</span>, <span class="st">"response_percent"</span>, <span class="st">"baseline_tumor_mm"</span>, <span class="st">"post_tumor_mm"</span>),</span>
<span id="cb97-20"><a href="#cb97-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">names</span>(ct_reduced)</span>
<span id="cb97-21"><a href="#cb97-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb97-22"><a href="#cb97-22" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">length</span>(leak_or_id)) {</span>
<span id="cb97-23"><a href="#cb97-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">message</span>(<span class="st">"Dropping potential leakage/ID columns: "</span>, <span class="fu">paste</span>(leak_or_id, <span class="at">collapse =</span> <span class="st">", "</span>))</span>
<span id="cb97-24"><a href="#cb97-24" aria-hidden="true" tabindex="-1"></a>  ct_reduced <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(ct_reduced, <span class="sc">-</span><span class="fu">all_of</span>(leak_or_id))</span>
<span id="cb97-25"><a href="#cb97-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb97-26"><a href="#cb97-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-27"><a href="#cb97-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Optional: remove zero-variance predictors (defensive)</span></span>
<span id="cb97-28"><a href="#cb97-28" aria-hidden="true" tabindex="-1"></a>nzv <span class="ot">&lt;-</span> <span class="cf">function</span>(x) <span class="fu">is.numeric</span>(x) <span class="sc">&amp;&amp;</span> (<span class="fu">sd</span>(x, <span class="at">na.rm =</span> <span class="cn">TRUE</span>) <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb97-29"><a href="#cb97-29" aria-hidden="true" tabindex="-1"></a>drop_nzv <span class="ot">&lt;-</span> <span class="fu">names</span>(ct_reduced)[<span class="fu">vapply</span>(ct_reduced, nzv, <span class="fu">logical</span>(<span class="dv">1</span>))]</span>
<span id="cb97-30"><a href="#cb97-30" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">length</span>(drop_nzv)) {</span>
<span id="cb97-31"><a href="#cb97-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">message</span>(<span class="st">"Dropping zero-variance numeric columns: "</span>, <span class="fu">paste</span>(drop_nzv, <span class="at">collapse =</span> <span class="st">", "</span>))</span>
<span id="cb97-32"><a href="#cb97-32" aria-hidden="true" tabindex="-1"></a>  ct_reduced <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(ct_reduced, <span class="sc">-</span><span class="fu">all_of</span>(drop_nzv))</span>
<span id="cb97-33"><a href="#cb97-33" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>After reading and preparing the data we proceed with the division of the dataset into training and testing dataset.<br>
<br>
</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === Stratified train/test split (e.g., 70/30) ================================</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>prop_train <span class="ot">&lt;-</span> <span class="fl">0.70</span></span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>idx_train <span class="ot">&lt;-</span> ct_reduced <span class="sc">%&gt;%</span></span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">row_id =</span> dplyr<span class="sc">::</span><span class="fu">row_number</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(high_response) <span class="sc">%&gt;%</span></span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_sample</span>(<span class="at">prop =</span> prop_train) <span class="sc">%&gt;%</span></span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(row_id)</span>
<span id="cb98-11"><a href="#cb98-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-12"><a href="#cb98-12" aria-hidden="true" tabindex="-1"></a>train_df <span class="ot">&lt;-</span> ct_reduced[idx_train, , drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span>
<span id="cb98-13"><a href="#cb98-13" aria-hidden="true" tabindex="-1"></a>test_df  <span class="ot">&lt;-</span> ct_reduced[<span class="sc">-</span>idx_train, , drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span>
<span id="cb98-14"><a href="#cb98-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-15"><a href="#cb98-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Quick balance check</span></span>
<span id="cb98-16"><a href="#cb98-16" aria-hidden="true" tabindex="-1"></a>table_train <span class="ot">&lt;-</span> <span class="fu">table</span>(train_df<span class="sc">$</span>high_response)</span>
<span id="cb98-17"><a href="#cb98-17" aria-hidden="true" tabindex="-1"></a>table_test  <span class="ot">&lt;-</span> <span class="fu">table</span>(test_df<span class="sc">$</span>high_response)</span>
<span id="cb98-18"><a href="#cb98-18" aria-hidden="true" tabindex="-1"></a>table_train; table_test</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
   0    1 
4385 2614 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
   0    1 
1880 1121 </code></pre>
</div>
</div>
<p>Now we will build the model formula to be used by R</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === Build the modeling formula (use everything except the target) ============</span></span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>predictors <span class="ot">&lt;-</span> <span class="fu">setdiff</span>(<span class="fu">names</span>(train_df), <span class="st">"high_response"</span>)</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>rhs <span class="ot">&lt;-</span> <span class="fu">paste</span>(predictors, <span class="at">collapse =</span> <span class="st">" + "</span>)</span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>f_logit <span class="ot">&lt;-</span> <span class="fu">as.formula</span>(<span class="fu">paste</span>(<span class="st">"high_response ~"</span>, rhs))</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>f_logit</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>high_response ~ treatment + dose_intensity + patient_age + tumor_grade + 
    performance_score + gene_1242 + gene_397 + gene_1754 + gene_355 + 
    gene_308 + gene_234 + gene_1598 + gene_1551 + gene_588 + 
    gene_779 + gene_599 + gene_2000 + gene_1190 + gene_1568 + 
    gene_1321 + gene_1379 + gene_746 + gene_1480 + gene_1973 + 
    gene_1448 + gene_1733 + gene_41 + gene_1668 + gene_1400 + 
    gene_1716 + gene_1213 + gene_873 + gene_207 + gene_609 + 
    gene_1923 + gene_772 + gene_1039 + gene_1291 + gene_58 + 
    gene_1760 + gene_1232 + gene_1925 + gene_340 + gene_663 + 
    gene_681 + gene_1596 + gene_821 + gene_94 + gene_814 + gene_719 + 
    gene_122 + gene_1240 + gene_577 + gene_1233 + gene_1811 + 
    gene_713 + gene_819 + gene_1196 + gene_56 + gene_1188 + gene_1319 + 
    gene_1820 + gene_926 + gene_1698 + gene_1690 + gene_1758 + 
    gene_1909 + gene_1003 + gene_890 + gene_186 + gene_1912 + 
    gene_787 + gene_967 + gene_233 + gene_564 + gene_307 + gene_1099 + 
    gene_1460 + gene_1830 + gene_289 + gene_1740 + gene_1116 + 
    gene_1946 + gene_371 + gene_1033 + gene_579 + gene_333 + 
    gene_1222 + gene_1139 + gene_1302 + gene_1215 + gene_655 + 
    gene_50 + gene_1195 + gene_1380 + gene_24 + gene_1940 + gene_370 + 
    gene_1687 + gene_170 + gene_643 + gene_1617 + gene_426 + 
    gene_934 + gene_1373</code></pre>
</div>
</div>
</section>
<section id="fitting-logistic-regression" class="level3" data-number="2.14.6">
<h3 data-number="2.14.6" class="anchored" data-anchor-id="fitting-logistic-regression"><span class="header-section-number">2.14.6</span> Fitting logistic regression</h3>
<p>In order to fit the logistic regression we use the R function `<code>glm</code>` that is the short for generalized linear models, a generic type of models from which logistic regression is a specific example.<br>
<br>
</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === Fit logistic regression (glm) and get predictions =======================</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>({</span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(broom)   <span class="co"># tidy output</span></span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a>mod_logit <span class="ot">&lt;-</span> <span class="fu">glm</span>(f_logit,</span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data   =</span> train_df,</span>
<span id="cb103-8"><a href="#cb103-8" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family =</span> <span class="fu">binomial</span>(),</span>
<span id="cb103-9"><a href="#cb103-9" aria-hidden="true" tabindex="-1"></a>                 <span class="at">control =</span> <span class="fu">glm.control</span>(<span class="at">maxit =</span> <span class="dv">100</span>))  <span class="co"># a few more iterations can help</span></span>
<span id="cb103-10"><a href="#cb103-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-11"><a href="#cb103-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted probabilities</span></span>
<span id="cb103-12"><a href="#cb103-12" aria-hidden="true" tabindex="-1"></a>p_train <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod_logit, <span class="at">newdata =</span> train_df, <span class="at">type =</span> <span class="st">"response"</span>)</span>
<span id="cb103-13"><a href="#cb103-13" aria-hidden="true" tabindex="-1"></a>p_test  <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod_logit, <span class="at">newdata =</span> test_df,  <span class="at">type =</span> <span class="st">"response"</span>)</span>
<span id="cb103-14"><a href="#cb103-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-15"><a href="#cb103-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Class predictions at a default 0.5 threshold (tune later as needed)</span></span>
<span id="cb103-16"><a href="#cb103-16" aria-hidden="true" tabindex="-1"></a>thr <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb103-17"><a href="#cb103-17" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> train_df<span class="sc">$</span>high_response</span>
<span id="cb103-18"><a href="#cb103-18" aria-hidden="true" tabindex="-1"></a>y_test  <span class="ot">&lt;-</span> test_df<span class="sc">$</span>high_response</span>
<span id="cb103-19"><a href="#cb103-19" aria-hidden="true" tabindex="-1"></a>yhat_train <span class="ot">&lt;-</span> <span class="fu">as.integer</span>(p_train <span class="sc">&gt;=</span> thr)</span>
<span id="cb103-20"><a href="#cb103-20" aria-hidden="true" tabindex="-1"></a>yhat_test  <span class="ot">&lt;-</span> <span class="fu">as.integer</span>(p_test  <span class="sc">&gt;=</span> thr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we create some helper functions to get metrics from the model</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === Metrics helpers (confusion-matrix stats, ROC AUC, PR AUC) ===============</span></span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>({</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(pROC)       <span class="co"># ROC/AUC</span></span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">suppressWarnings</span>(<span class="fu">require</span>(PRROC))  <span class="co"># PR curves (optional)</span></span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(tidyr)</span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(ggplot2)</span>
<span id="cb104-7"><a href="#cb104-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb104-8"><a href="#cb104-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-9"><a href="#cb104-9" aria-hidden="true" tabindex="-1"></a>cm_metrics <span class="ot">&lt;-</span> <span class="cf">function</span>(y, yhat) {</span>
<span id="cb104-10"><a href="#cb104-10" aria-hidden="true" tabindex="-1"></a>  tp <span class="ot">&lt;-</span> <span class="fu">sum</span>(y <span class="sc">==</span> <span class="dv">1</span> <span class="sc">&amp;</span> yhat <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb104-11"><a href="#cb104-11" aria-hidden="true" tabindex="-1"></a>  tn <span class="ot">&lt;-</span> <span class="fu">sum</span>(y <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> yhat <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb104-12"><a href="#cb104-12" aria-hidden="true" tabindex="-1"></a>  fp <span class="ot">&lt;-</span> <span class="fu">sum</span>(y <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> yhat <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb104-13"><a href="#cb104-13" aria-hidden="true" tabindex="-1"></a>  fn <span class="ot">&lt;-</span> <span class="fu">sum</span>(y <span class="sc">==</span> <span class="dv">1</span> <span class="sc">&amp;</span> yhat <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb104-14"><a href="#cb104-14" aria-hidden="true" tabindex="-1"></a>  acc  <span class="ot">&lt;-</span> (tp <span class="sc">+</span> tn) <span class="sc">/</span> (tp <span class="sc">+</span> tn <span class="sc">+</span> fp <span class="sc">+</span> fn)</span>
<span id="cb104-15"><a href="#cb104-15" aria-hidden="true" tabindex="-1"></a>  sens <span class="ot">&lt;-</span> <span class="fu">ifelse</span>((tp <span class="sc">+</span> fn) <span class="sc">&gt;</span> <span class="dv">0</span>, tp <span class="sc">/</span> (tp <span class="sc">+</span> fn), <span class="cn">NA_real_</span>)  <span class="co"># recall</span></span>
<span id="cb104-16"><a href="#cb104-16" aria-hidden="true" tabindex="-1"></a>  spec <span class="ot">&lt;-</span> <span class="fu">ifelse</span>((tn <span class="sc">+</span> fp) <span class="sc">&gt;</span> <span class="dv">0</span>, tn <span class="sc">/</span> (tn <span class="sc">+</span> fp), <span class="cn">NA_real_</span>)</span>
<span id="cb104-17"><a href="#cb104-17" aria-hidden="true" tabindex="-1"></a>  prec <span class="ot">&lt;-</span> <span class="fu">ifelse</span>((tp <span class="sc">+</span> fp) <span class="sc">&gt;</span> <span class="dv">0</span>, tp <span class="sc">/</span> (tp <span class="sc">+</span> fp), <span class="cn">NA_real_</span>)  <span class="co"># PPV</span></span>
<span id="cb104-18"><a href="#cb104-18" aria-hidden="true" tabindex="-1"></a>  f1   <span class="ot">&lt;-</span> <span class="fu">ifelse</span>((prec <span class="sc">+</span> sens) <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="dv">2</span> <span class="sc">*</span> prec <span class="sc">*</span> sens <span class="sc">/</span> (prec <span class="sc">+</span> sens), <span class="cn">NA_real_</span>)</span>
<span id="cb104-19"><a href="#cb104-19" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">tibble</span>(<span class="at">TP =</span> tp, <span class="at">TN =</span> tn, <span class="at">FP =</span> fp, <span class="at">FN =</span> fn,</span>
<span id="cb104-20"><a href="#cb104-20" aria-hidden="true" tabindex="-1"></a>                <span class="at">Accuracy =</span> acc, <span class="at">Sensitivity =</span> sens, <span class="at">Specificity =</span> spec,</span>
<span id="cb104-21"><a href="#cb104-21" aria-hidden="true" tabindex="-1"></a>                <span class="at">Precision =</span> prec, <span class="at">F1 =</span> f1)</span>
<span id="cb104-22"><a href="#cb104-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb104-23"><a href="#cb104-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-24"><a href="#cb104-24" aria-hidden="true" tabindex="-1"></a>auc_roc <span class="ot">&lt;-</span> <span class="cf">function</span>(labels, scores) {</span>
<span id="cb104-25"><a href="#cb104-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.numeric</span>(pROC<span class="sc">::</span><span class="fu">auc</span>(pROC<span class="sc">::</span><span class="fu">roc</span>(labels, scores, <span class="at">quiet =</span> <span class="cn">TRUE</span>)))</span>
<span id="cb104-26"><a href="#cb104-26" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb104-27"><a href="#cb104-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-28"><a href="#cb104-28" aria-hidden="true" tabindex="-1"></a>auc_pr <span class="ot">&lt;-</span> <span class="cf">function</span>(labels, scores, <span class="at">positive_class =</span> <span class="dv">1</span>) {</span>
<span id="cb104-29"><a href="#cb104-29" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="sc">!</span><span class="st">"PRROC"</span> <span class="sc">%in%</span> <span class="fu">.packages</span>()) <span class="fu">return</span>(<span class="cn">NA_real_</span>)</span>
<span id="cb104-30"><a href="#cb104-30" aria-hidden="true" tabindex="-1"></a>  s <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(scores); y <span class="ot">&lt;-</span> <span class="fu">as.integer</span>(labels)</span>
<span id="cb104-31"><a href="#cb104-31" aria-hidden="true" tabindex="-1"></a>  fg <span class="ot">&lt;-</span> s[y <span class="sc">==</span> positive_class]</span>
<span id="cb104-32"><a href="#cb104-32" aria-hidden="true" tabindex="-1"></a>  bg <span class="ot">&lt;-</span> s[y <span class="sc">!=</span> positive_class]</span>
<span id="cb104-33"><a href="#cb104-33" aria-hidden="true" tabindex="-1"></a>  out <span class="ot">&lt;-</span> PRROC<span class="sc">::</span><span class="fu">pr.curve</span>(<span class="at">scores.class0 =</span> fg, <span class="at">scores.class1 =</span> bg, <span class="at">curve =</span> <span class="cn">FALSE</span>)</span>
<span id="cb104-34"><a href="#cb104-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.numeric</span>(out<span class="sc">$</span>auc.integral)</span>
<span id="cb104-35"><a href="#cb104-35" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Lets calculate metrics of true positives true negatives false positives and false negatives for our example.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === Metrics table for glm on TRAIN/</span><span class="al">TEST</span><span class="co"> ======================================</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>logit_train_metrics <span class="ot">&lt;-</span> <span class="fu">cm_metrics</span>(y_train, yhat_train) <span class="sc">%&gt;%</span></span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Model =</span> <span class="st">"Logistic (glm)"</span>, <span class="at">Dataset =</span> <span class="st">"Train"</span>,</span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">AUC_ROC =</span> <span class="fu">auc_roc</span>(y_train, p_train),</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">AUC_PR  =</span> <span class="fu">auc_pr</span>(y_train,  p_train))</span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a>logit_test_metrics <span class="ot">&lt;-</span> <span class="fu">cm_metrics</span>(y_test, yhat_test) <span class="sc">%&gt;%</span></span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Model =</span> <span class="st">"Logistic (glm)"</span>, <span class="at">Dataset =</span> <span class="st">"Test"</span>,</span>
<span id="cb105-9"><a href="#cb105-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">AUC_ROC =</span> <span class="fu">auc_roc</span>(y_test, p_test),</span>
<span id="cb105-10"><a href="#cb105-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">AUC_PR  =</span> <span class="fu">auc_pr</span>(y_test,  p_test))</span>
<span id="cb105-11"><a href="#cb105-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-12"><a href="#cb105-12" aria-hidden="true" tabindex="-1"></a>dplyr<span class="sc">::</span><span class="fu">bind_rows</span>(logit_train_metrics, logit_test_metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 13
     TP    TN    FP    FN Accuracy Sensitivity Specificity Precision    F1 Model
  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;
1  2406  4017   368   208    0.918       0.920       0.916     0.867 0.893 Logi…
2  1005  1717   163   116    0.907       0.897       0.913     0.860 0.878 Logi…
# ℹ 3 more variables: Dataset &lt;chr&gt;, AUC_ROC &lt;dbl&gt;, AUC_PR &lt;dbl&gt;</code></pre>
</div>
</div>
<p>Moving we can construct the ROC and AUC curves for our example<br>
<br>
</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === ROC curves for glm (downsampled for plotting stability) ==================</span></span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>roc_train <span class="ot">&lt;-</span> pROC<span class="sc">::</span><span class="fu">roc</span>(y_train, p_train, <span class="at">quiet =</span> <span class="cn">TRUE</span>)</span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a>roc_test  <span class="ot">&lt;-</span> pROC<span class="sc">::</span><span class="fu">roc</span>(y_test,  p_test,  <span class="at">quiet =</span> <span class="cn">TRUE</span>)</span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a>roc_df <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">bind_rows</span>(</span>
<span id="cb107-6"><a href="#cb107-6" aria-hidden="true" tabindex="-1"></a>  tibble<span class="sc">::</span><span class="fu">tibble</span>(<span class="at">FPR =</span> <span class="dv">1</span> <span class="sc">-</span> roc_train<span class="sc">$</span>specificities, <span class="at">TPR =</span> roc_train<span class="sc">$</span>sensitivities, <span class="at">Dataset =</span> <span class="st">"Train"</span>),</span>
<span id="cb107-7"><a href="#cb107-7" aria-hidden="true" tabindex="-1"></a>  tibble<span class="sc">::</span><span class="fu">tibble</span>(<span class="at">FPR =</span> <span class="dv">1</span> <span class="sc">-</span> roc_test<span class="sc">$</span>specificities,  <span class="at">TPR =</span> roc_test<span class="sc">$</span>sensitivities,  <span class="at">Dataset =</span> <span class="st">"Test"</span>)</span>
<span id="cb107-8"><a href="#cb107-8" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb107-9"><a href="#cb107-9" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">group_by</span>(Dataset) <span class="sc">%&gt;%</span></span>
<span id="cb107-10"><a href="#cb107-10" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">slice</span>( <span class="fu">unique</span>(<span class="fu">round</span>(<span class="fu">seq</span>(<span class="dv">1</span>, dplyr<span class="sc">::</span><span class="fu">n</span>(), <span class="at">length.out =</span> <span class="fu">pmin</span>(<span class="dv">400</span>L, dplyr<span class="sc">::</span><span class="fu">n</span>())))) ) <span class="sc">%&gt;%</span></span>
<span id="cb107-11"><a href="#cb107-11" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">ungroup</span>()</span>
<span id="cb107-12"><a href="#cb107-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-13"><a href="#cb107-13" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(roc_df, <span class="fu">aes</span>(<span class="at">x =</span> FPR, <span class="at">y =</span> TPR, <span class="at">linetype =</span> Dataset)) <span class="sc">+</span></span>
<span id="cb107-14"><a href="#cb107-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb107-15"><a href="#cb107-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb107-16"><a href="#cb107-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_equal</span>() <span class="sc">+</span></span>
<span id="cb107-17"><a href="#cb107-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb107-18"><a href="#cb107-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"ROC curves    Logistic regression"</span>,</span>
<span id="cb107-19"><a href="#cb107-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="fu">sprintf</span>(<span class="st">"AUC Train = %.3f, AUC Test = %.3f"</span>,</span>
<span id="cb107-20"><a href="#cb107-20" aria-hidden="true" tabindex="-1"></a>                       <span class="fu">as.numeric</span>(pROC<span class="sc">::</span><span class="fu">auc</span>(roc_train)), <span class="fu">as.numeric</span>(pROC<span class="sc">::</span><span class="fu">auc</span>(roc_test))),</span>
<span id="cb107-21"><a href="#cb107-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"False Positive Rate"</span>, <span class="at">y =</span> <span class="st">"True Positive Rate"</span></span>
<span id="cb107-22"><a href="#cb107-22" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb107-23"><a href="#cb107-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/unnamed-chunk-44-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><br>
Optionally we can create a PR curve<br>
<br>
</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === Optional PR curves for glm ===============================================</span></span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="st">"PRROC"</span> <span class="sc">%in%</span> <span class="fu">.packages</span>()) {</span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>  fg_train <span class="ot">&lt;-</span> p_train[y_train <span class="sc">==</span> <span class="dv">1</span>]; bg_train <span class="ot">&lt;-</span> p_train[y_train <span class="sc">==</span> <span class="dv">0</span>]</span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>  fg_test  <span class="ot">&lt;-</span> p_test[y_test  <span class="sc">==</span> <span class="dv">1</span>];  bg_test  <span class="ot">&lt;-</span> p_test[y_test  <span class="sc">==</span> <span class="dv">0</span>]</span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a>  pr_train <span class="ot">&lt;-</span> PRROC<span class="sc">::</span><span class="fu">pr.curve</span>(<span class="at">scores.class0 =</span> fg_train, <span class="at">scores.class1 =</span> bg_train, <span class="at">curve =</span> <span class="cn">TRUE</span>)</span>
<span id="cb108-6"><a href="#cb108-6" aria-hidden="true" tabindex="-1"></a>  pr_test  <span class="ot">&lt;-</span> PRROC<span class="sc">::</span><span class="fu">pr.curve</span>(<span class="at">scores.class0 =</span> fg_test,  <span class="at">scores.class1 =</span> bg_test,  <span class="at">curve =</span> <span class="cn">TRUE</span>)</span>
<span id="cb108-7"><a href="#cb108-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-8"><a href="#cb108-8" aria-hidden="true" tabindex="-1"></a>  pr_df <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">bind_rows</span>(</span>
<span id="cb108-9"><a href="#cb108-9" aria-hidden="true" tabindex="-1"></a>    tibble<span class="sc">::</span><span class="fu">tibble</span>(<span class="at">recall =</span> pr_train<span class="sc">$</span>curve[,<span class="dv">1</span>], <span class="at">precision =</span> pr_train<span class="sc">$</span>curve[,<span class="dv">2</span>],</span>
<span id="cb108-10"><a href="#cb108-10" aria-hidden="true" tabindex="-1"></a>                   <span class="at">Dataset =</span> <span class="fu">paste0</span>(<span class="st">"Train (AUC-PR = "</span>, <span class="fu">sprintf</span>(<span class="st">"%.3f"</span>, pr_train<span class="sc">$</span>auc.integral), <span class="st">")"</span>)),</span>
<span id="cb108-11"><a href="#cb108-11" aria-hidden="true" tabindex="-1"></a>    tibble<span class="sc">::</span><span class="fu">tibble</span>(<span class="at">recall =</span> pr_test<span class="sc">$</span>curve[,<span class="dv">1</span>],  <span class="at">precision =</span> pr_test<span class="sc">$</span>curve[,<span class="dv">2</span>],</span>
<span id="cb108-12"><a href="#cb108-12" aria-hidden="true" tabindex="-1"></a>                   <span class="at">Dataset =</span> <span class="fu">paste0</span>(<span class="st">"Test (AUC-PR = "</span>,  <span class="fu">sprintf</span>(<span class="st">"%.3f"</span>, pr_test<span class="sc">$</span>auc.integral), <span class="st">")"</span>))</span>
<span id="cb108-13"><a href="#cb108-13" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb108-14"><a href="#cb108-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-15"><a href="#cb108-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(pr_df, <span class="fu">aes</span>(<span class="at">x =</span> recall, <span class="at">y =</span> precision, <span class="at">color =</span> Dataset)) <span class="sc">+</span></span>
<span id="cb108-16"><a href="#cb108-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb108-17"><a href="#cb108-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Precision–Recall curves    Logistic regression"</span>,</span>
<span id="cb108-18"><a href="#cb108-18" aria-hidden="true" tabindex="-1"></a>         <span class="at">x =</span> <span class="st">"Recall (Sensitivity)"</span>, <span class="at">y =</span> <span class="st">"Precision (PPV)"</span>) <span class="sc">+</span></span>
<span id="cb108-19"><a href="#cb108-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>()</span>
<span id="cb108-20"><a href="#cb108-20" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/unnamed-chunk-45-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><br>
and get the coefficients from the models</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === Coefficient table with Wald-style CIs (robust to confint() failures) =====</span></span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>coef_tbl_logit <span class="ot">&lt;-</span> broom<span class="sc">::</span><span class="fu">tidy</span>(mod_logit) <span class="sc">%&gt;%</span></span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">conf.low  =</span> estimate <span class="sc">-</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>) <span class="sc">*</span> std.error,</span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">conf.high =</span> estimate <span class="sc">+</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>) <span class="sc">*</span> std.error</span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb109-7"><a href="#cb109-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(estimate)</span>
<span id="cb109-8"><a href="#cb109-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-9"><a href="#cb109-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(coef_tbl_logit, <span class="at">n =</span> <span class="fu">min</span>(<span class="dv">25</span>, <span class="fu">nrow</span>(coef_tbl_logit)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 107 × 7
   term              estimate std.error statistic  p.value conf.low conf.high
   &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
 1 performance_score   -0.676    0.0767    -8.82  1.13e-18   -0.826  -0.526  
 2 gene_1379           -0.338    0.179     -1.89  5.89e- 2   -0.688   0.0126 
 3 gene_1733           -0.335    0.170     -1.97  4.87e- 2   -0.668  -0.00196
 4 gene_1598           -0.305    0.174     -1.75  7.93e- 2   -0.646   0.0357 
 5 gene_426            -0.283    0.174     -1.63  1.04e- 1   -0.625   0.0579 
 6 gene_1820           -0.280    0.175     -1.60  1.09e- 1   -0.622   0.0627 
 7 gene_1760           -0.257    0.180     -1.43  1.54e- 1   -0.610   0.0964 
 8 gene_719            -0.255    0.177     -1.45  1.48e- 1   -0.601   0.0906 
 9 gene_170            -0.246    0.174     -1.42  1.57e- 1   -0.587   0.0945 
10 gene_655            -0.237    0.177     -1.34  1.81e- 1   -0.584   0.110  
11 gene_934            -0.230    0.174     -1.32  1.87e- 1   -0.572   0.112  
12 gene_1909           -0.225    0.173     -1.30  1.94e- 1   -0.565   0.115  
13 gene_819            -0.225    0.175     -1.29  1.99e- 1   -0.568   0.118  
14 gene_1687           -0.208    0.177     -1.18  2.39e- 1   -0.555   0.138  
15 gene_1925           -0.206    0.174     -1.19  2.34e- 1   -0.547   0.134  
16 gene_1291           -0.199    0.174     -1.15  2.52e- 1   -0.540   0.142  
17 gene_289            -0.198    0.176     -1.13  2.60e- 1   -0.543   0.147  
18 gene_821            -0.183    0.175     -1.05  2.96e- 1   -0.526   0.160  
19 gene_1099           -0.182    0.173     -1.05  2.93e- 1   -0.522   0.157  
20 gene_577            -0.178    0.177     -1.00  3.16e- 1   -0.525   0.170  
21 gene_1940           -0.176    0.178     -0.988 3.23e- 1   -0.524   0.173  
22 gene_50             -0.172    0.178     -0.969 3.33e- 1   -0.521   0.176  
23 gene_1740           -0.157    0.174     -0.900 3.68e- 1   -0.497   0.184  
24 gene_41             -0.150    0.174     -0.862 3.89e- 1   -0.492   0.191  
25 gene_1946           -0.148    0.176     -0.842 4.00e- 1   -0.493   0.197  
# ℹ 82 more rows</code></pre>
</div>
</div>
</section>
<section id="understanding-log-odds-and-coefficient-interpretation-in-logistic-regression" class="level3" data-number="2.14.7">
<h3 data-number="2.14.7" class="anchored" data-anchor-id="understanding-log-odds-and-coefficient-interpretation-in-logistic-regression"><span class="header-section-number">2.14.7</span> Understanding Log-Odds and Coefficient Interpretation in Logistic Regression</h3>
<p>In linear regression, we predict a <em>continuous</em> outcome. In logistic regression, the outcome is <em>binary</em> (e.g., <code>high_response = 1</code> for “high responder” vs <code>0</code> for “low responder”). To keep predicted probabilities between 0 and 1, we model the <strong>logarithm of the odds</strong> (the <em>logit</em>) of being a responder.</p>
<section id="odds-and-logit" class="level4" data-number="2.14.7.1">
<h4 data-number="2.14.7.1" class="anchored" data-anchor-id="odds-and-logit"><span class="header-section-number">2.14.7.1</span> Odds and Logit</h4>
<p>The <strong>odds</strong> of success are: $[ = ] $If (p=0.75), then (=0.75/0.25=3) (three-to-one).</p>
<p>The <strong>logit</strong> (log-odds) is: <span class="math inline">\(\[ \text{logit}(p) = \log!\left(\frac{p}{1-p}\right) \]\)</span></p>
<p>Logistic regression is linear in the log-odds: <span class="math inline">\(\[ \log!\left(\frac{p}{1-p}\right)=w_0+w_1 x_1+\cdots+w_k x_k \]\)</span></p>
<p>Each coefficient ( $w_j $) is the change in <strong>log-odds</strong> for a one-unit increase in (x_j), holding other variables fixed.</p>
</section>
<section id="odds-ratios" class="level4" data-number="2.14.7.2">
<h4 data-number="2.14.7.2" class="anchored" data-anchor-id="odds-ratios"><span class="header-section-number">2.14.7.2</span> Odds Ratios</h4>
<p>Exponentiating a coefficient yields an <strong>odds ratio</strong> (OR): <span class="math inline">\(\[ \text{OR}\_j = e\^{w_j} \] - (\text{OR}\_j \&gt; 1)\)</span>: increasing (x_j) raises the odds of response<br>
- (<span class="math inline">\(\text{OR}\_j &lt; 1\)</span>): increasing (x_j) lowers the odds of response<br>
- (<span class="math inline">\(\text{OR}\_j = 1\)</span>): no change in odds</p>
<p>Example interpretations: - <span class="math inline">\(( \w=+0.80 \Rightarrow \text{OR}=e\^{0.80}\approx 2.22)\)</span>: odds a bit more than double per unit increase.<br>
- <span class="math inline">\(( w=-0.50 \Rightarrow \text{OR}\approx 0.61)\)</span>: odds drop by <span class="math inline">\(\~39%\)</span> per unit increase.</p>
</section>
<section id="from-log-odds-back-to-probability" class="level4" data-number="2.14.7.3">
<h4 data-number="2.14.7.3" class="anchored" data-anchor-id="from-log-odds-back-to-probability"><span class="header-section-number">2.14.7.3</span> From Log-Odds Back to Probability</h4>
<p><span class="math inline">\(\[ p=\frac{1}{1+e^{-(w_0+w_1 x_1+\cdots+w_k x_k)}} \]\)</span> If log-odds = (1.5), then (p). If log-odds = (-1.5), then (p).</p>
</section>
</section>
<section id="compute-odds-ratios-from-the-fitted-model" class="level3" data-number="2.14.8">
<h3 data-number="2.14.8" class="anchored" data-anchor-id="compute-odds-ratios-from-the-fitted-model"><span class="header-section-number">2.14.8</span> Compute Odds Ratios from the Fitted Model</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build odds–ratio table from the fitted model</span></span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a><span class="co"># (uses normal-approx CI; avoids profile-likelihood warnings/slowdowns)</span></span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb111-5"><a href="#cb111-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-6"><a href="#cb111-6" aria-hidden="true" tabindex="-1"></a>zcrit <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>)  <span class="co"># 1.96</span></span>
<span id="cb111-7"><a href="#cb111-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-8"><a href="#cb111-8" aria-hidden="true" tabindex="-1"></a>or_tbl <span class="ot">&lt;-</span> broom<span class="sc">::</span><span class="fu">tidy</span>(mod_logit) <span class="sc">%&gt;%</span></span>
<span id="cb111-9"><a href="#cb111-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(term <span class="sc">!=</span> <span class="st">"(Intercept)"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb111-10"><a href="#cb111-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb111-11"><a href="#cb111-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">OR      =</span> <span class="fu">exp</span>(estimate),</span>
<span id="cb111-12"><a href="#cb111-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">OR_low  =</span> <span class="fu">exp</span>(estimate <span class="sc">-</span> zcrit <span class="sc">*</span> std.error),</span>
<span id="cb111-13"><a href="#cb111-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">OR_high =</span> <span class="fu">exp</span>(estimate <span class="sc">+</span> zcrit <span class="sc">*</span> std.error)</span>
<span id="cb111-14"><a href="#cb111-14" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb111-15"><a href="#cb111-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(<span class="fu">abs</span>(estimate)))</span>
<span id="cb111-16"><a href="#cb111-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-17"><a href="#cb111-17" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Ways to *see* the OR columns clearly ---</span></span>
<span id="cb111-18"><a href="#cb111-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-19"><a href="#cb111-19" aria-hidden="true" tabindex="-1"></a><span class="co"># A) Select and print only the columns you care about</span></span>
<span id="cb111-20"><a href="#cb111-20" aria-hidden="true" tabindex="-1"></a>or_tbl <span class="sc">%&gt;%</span></span>
<span id="cb111-21"><a href="#cb111-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term, estimate, std.error, statistic, p.value, OR, OR_low, OR_high) <span class="sc">%&gt;%</span></span>
<span id="cb111-22"><a href="#cb111-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_head</span>(<span class="at">n =</span> <span class="dv">12</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 12 × 8
   term            estimate std.error statistic  p.value      OR  OR_low OR_high
   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
 1 treatmentchemo     6.78     0.658      10.3  6.35e-25 882.    243.    3.20e+3
 2 dose_intensity     3.74     0.595       6.29 3.14e-10  42.2    13.1   1.35e+2
 3 tumor_gradeG3      1.24     0.143       8.68 4.08e-18   3.47    2.62  4.59e+0
 4 performance_sc…   -0.676    0.0767     -8.82 1.13e-18   0.509   0.438 5.91e-1
 5 gene_1319          0.450    0.175       2.57 1.03e- 2   1.57    1.11  2.21e+0
 6 gene_1039          0.435    0.178       2.44 1.45e- 2   1.55    1.09  2.19e+0
 7 tumor_gradeG2      0.402    0.124       3.25 1.14e- 3   1.50    1.17  1.91e+0
 8 gene_1302          0.355    0.177       2.01 4.48e- 2   1.43    1.01  2.02e+0
 9 gene_1379         -0.338    0.179      -1.89 5.89e- 2   0.714   0.503 1.01e+0
10 gene_1733         -0.335    0.170      -1.97 4.87e- 2   0.715   0.513 9.98e-1
11 gene_1598         -0.305    0.174      -1.75 7.93e- 2   0.737   0.524 1.04e+0
12 gene_58            0.292    0.177       1.65 9.93e- 2   1.34    0.946 1.90e+0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="co"># B) Print all columns without truncation</span></span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(or_tbl, <span class="at">n =</span> <span class="dv">12</span>, <span class="at">width =</span> <span class="cn">Inf</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 106 × 8
   term              estimate std.error statistic  p.value      OR  OR_low
   &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
 1 treatmentchemo       6.78     0.658      10.3  6.35e-25 882.    243.   
 2 dose_intensity       3.74     0.595       6.29 3.14e-10  42.2    13.1  
 3 tumor_gradeG3        1.24     0.143       8.68 4.08e-18   3.47    2.62 
 4 performance_score   -0.676    0.0767     -8.82 1.13e-18   0.509   0.438
 5 gene_1319            0.450    0.175       2.57 1.03e- 2   1.57    1.11 
 6 gene_1039            0.435    0.178       2.44 1.45e- 2   1.55    1.09 
 7 tumor_gradeG2        0.402    0.124       3.25 1.14e- 3   1.50    1.17 
 8 gene_1302            0.355    0.177       2.01 4.48e- 2   1.43    1.01 
 9 gene_1379           -0.338    0.179      -1.89 5.89e- 2   0.714   0.503
10 gene_1733           -0.335    0.170      -1.97 4.87e- 2   0.715   0.513
11 gene_1598           -0.305    0.174      -1.75 7.93e- 2   0.737   0.524
12 gene_58              0.292    0.177       1.65 9.93e- 2   1.34    0.946
    OR_high
      &lt;dbl&gt;
 1 3202.   
 2  135.   
 3    4.59 
 4    0.591
 5    2.21 
 6    2.19 
 7    1.91 
 8    2.02 
 9    1.01 
10    0.998
11    1.04 
12    1.90 
# ℹ 94 more rows</code></pre>
</div>
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="co"># C) Nicely formatted table (if in a report)</span></span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a><span class="co"># knitr::kable(</span></span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a><span class="co">#   or_tbl %&gt;%</span></span>
<span id="cb115-4"><a href="#cb115-4" aria-hidden="true" tabindex="-1"></a><span class="co">#     transmute(</span></span>
<span id="cb115-5"><a href="#cb115-5" aria-hidden="true" tabindex="-1"></a><span class="co">#       term,</span></span>
<span id="cb115-6"><a href="#cb115-6" aria-hidden="true" tabindex="-1"></a><span class="co">#       `Estimate (β)` = estimate,</span></span>
<span id="cb115-7"><a href="#cb115-7" aria-hidden="true" tabindex="-1"></a><span class="co">#       `Std. Error`    = std.error,</span></span>
<span id="cb115-8"><a href="#cb115-8" aria-hidden="true" tabindex="-1"></a><span class="co">#       `z`             = statistic,</span></span>
<span id="cb115-9"><a href="#cb115-9" aria-hidden="true" tabindex="-1"></a><span class="co">#       `p`             = p.value,</span></span>
<span id="cb115-10"><a href="#cb115-10" aria-hidden="true" tabindex="-1"></a><span class="co">#       `OR = exp(β)`   = OR,</span></span>
<span id="cb115-11"><a href="#cb115-11" aria-hidden="true" tabindex="-1"></a><span class="co">#       `OR low`        = OR_low,</span></span>
<span id="cb115-12"><a href="#cb115-12" aria-hidden="true" tabindex="-1"></a><span class="co">#       `OR high`       = OR_high</span></span>
<span id="cb115-13"><a href="#cb115-13" aria-hidden="true" tabindex="-1"></a><span class="co">#     ) %&gt;%</span></span>
<span id="cb115-14"><a href="#cb115-14" aria-hidden="true" tabindex="-1"></a><span class="co">#     slice_head(n = 12),</span></span>
<span id="cb115-15"><a href="#cb115-15" aria-hidden="true" tabindex="-1"></a><span class="co">#   digits = 3, align = "lrrrrrrr",</span></span>
<span id="cb115-16"><a href="#cb115-16" aria-hidden="true" tabindex="-1"></a><span class="co">#   caption = "Top coefficients by |β| with odds ratios and 95% CI"</span></span>
<span id="cb115-17"><a href="#cb115-17" aria-hidden="true" tabindex="-1"></a><span class="co"># )</span></span>
<span id="cb115-18"><a href="#cb115-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-19"><a href="#cb115-19" aria-hidden="true" tabindex="-1"></a><span class="co"># D) If you want rounded values for readability</span></span>
<span id="cb115-20"><a href="#cb115-20" aria-hidden="true" tabindex="-1"></a>or_tbl_rounded <span class="ot">&lt;-</span> or_tbl <span class="sc">%&gt;%</span></span>
<span id="cb115-21"><a href="#cb115-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb115-22"><a href="#cb115-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">across</span>(<span class="fu">c</span>(estimate, std.error, statistic), <span class="sc">~</span><span class="fu">round</span>(.x, <span class="dv">3</span>)),</span>
<span id="cb115-23"><a href="#cb115-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">across</span>(<span class="fu">c</span>(p.value), <span class="sc">~</span><span class="fu">signif</span>(.x, <span class="dv">3</span>)),</span>
<span id="cb115-24"><a href="#cb115-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">across</span>(<span class="fu">c</span>(OR, OR_low, OR_high), <span class="sc">~</span><span class="fu">round</span>(.x, <span class="dv">2</span>))</span>
<span id="cb115-25"><a href="#cb115-25" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb115-26"><a href="#cb115-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-27"><a href="#cb115-27" aria-hidden="true" tabindex="-1"></a>or_tbl_rounded <span class="sc">%&gt;%</span></span>
<span id="cb115-28"><a href="#cb115-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term, estimate, std.error, statistic, p.value, OR, OR_low, OR_high) <span class="sc">%&gt;%</span></span>
<span id="cb115-29"><a href="#cb115-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_head</span>(<span class="at">n =</span> <span class="dv">12</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 12 × 8
   term              estimate std.error statistic  p.value     OR OR_low OR_high
   &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
 1 treatmentchemo       6.78      0.658     10.3  6.35e-25 882.   243.   3202.  
 2 dose_intensity       3.74      0.595      6.29 3.14e-10  42.2   13.2   135.  
 3 tumor_gradeG3        1.24      0.143      8.68 4.08e-18   3.47   2.62    4.59
 4 performance_score   -0.676     0.077     -8.82 1.13e-18   0.51   0.44    0.59
 5 gene_1319            0.45      0.175      2.57 1.03e- 2   1.57   1.11    2.21
 6 gene_1039            0.435     0.178      2.44 1.45e- 2   1.55   1.09    2.19
 7 tumor_gradeG2        0.402     0.124      3.25 1.14e- 3   1.5    1.17    1.91
 8 gene_1302            0.355     0.177      2.01 4.48e- 2   1.43   1.01    2.02
 9 gene_1379           -0.338     0.179     -1.89 5.89e- 2   0.71   0.5     1.01
10 gene_1733           -0.335     0.17      -1.97 4.87e- 2   0.72   0.51    1   
11 gene_1598           -0.305     0.174     -1.76 7.93e- 2   0.74   0.52    1.04
12 gene_58              0.292     0.177      1.65 9.93e- 2   1.34   0.95    1.9 </code></pre>
</div>
</div>
<p>The&nbsp;<strong>treatment variable (chemo vs.&nbsp;no_chemo)</strong>&nbsp;shows by far the strongest association, with an estimated coefficient of 6.78, corresponding to an odds ratio (OR) of approximately 885. This means that, holding other predictors constant, patients who received chemotherapy had odds of achieving a high tumor response nearly 900 times greater than those who did not receive it.</p>
<p>The&nbsp;<strong>dose_intensity</strong>&nbsp;variable also exerts a very large positive effect (w = 3.74; OR ≈ 42). Each one-unit increase in dose intensity multiplies the odds of response by roughly 42, indicating a steep dose–response relationship.</p>
<p>Tumor-related characteristics also influence response probability. A higher&nbsp;<strong>tumor_grade</strong>&nbsp;(e.g., G2 or G3 relative to the baseline category) is associated with an estimated b of 1.24 (OR ≈ 3.46), suggesting about a three-and-a-half-fold increase in the odds of response. A smaller positive contrast (w = 0.40; OR ≈ 1.49) indicates that other grade categories also contribute modestly to improved response rates.</p>
<p>In contrast,&nbsp;<strong>performance_score</strong>&nbsp;has a negative coefficient (w = −0.676; OR ≈ 0.51), meaning that each additional point on this score reflecting poorer clinical performance reduces the odds of a favorable response by about half.</p>
<p>Several genes show smaller but biologically interesting effects.&nbsp;<strong>gene_1598</strong>&nbsp;(w = +0.45; OR ≈ 1.57) and&nbsp;<strong>gene_1551</strong>&nbsp;(w = +0.44; OR ≈ 1.55) both display modest positive associations, where higher expression slightly increases the probability of response.&nbsp;<strong>gene_779</strong>&nbsp;(w = +0.36; OR ≈ 1.43) and&nbsp;<strong>gene_588</strong>&nbsp;(w = +0.29; OR ≈ 1.34) show similarly mild but consistent trends toward higher response odds.</p>
<p>Conversely,&nbsp;<strong>gene_565</strong>&nbsp;(w = −0.34; OR ≈ 0.71),&nbsp;<strong>gene_323</strong>&nbsp;(w = −0.34; OR ≈ 0.72), and&nbsp;<strong>gene_1183</strong>&nbsp;(w = −0.31; OR ≈ 0.74) are negatively associated with high response, suggesting that higher expression of these genes slightly decreases the odds of tumor reduction, possibly reflecting resistance pathways.</p>
</section>
<section id="benchmarking-logistic-regression-with-lasso-ridge-and-elastic-net-counterparts" class="level3" data-number="2.14.9">
<h3 data-number="2.14.9" class="anchored" data-anchor-id="benchmarking-logistic-regression-with-lasso-ridge-and-elastic-net-counterparts"><span class="header-section-number">2.14.9</span> Benchmarking Logistic regression with LASSO, RIDGE and ELASTIC NET counterparts</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === Penalized logistic: LASSO, Ridge, Elastic Net ============================</span></span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>({</span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(glmnet)</span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb117-5"><a href="#cb117-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-6"><a href="#cb117-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Freeze factor levels/dummies using the TRAIN design implied by f_logit</span></span>
<span id="cb117-7"><a href="#cb117-7" aria-hidden="true" tabindex="-1"></a>mf_train  <span class="ot">&lt;-</span> <span class="fu">model.frame</span>(f_logit, <span class="at">data =</span> train_df)</span>
<span id="cb117-8"><a href="#cb117-8" aria-hidden="true" tabindex="-1"></a>terms_log <span class="ot">&lt;-</span> <span class="fu">terms</span>(mf_train)</span>
<span id="cb117-9"><a href="#cb117-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-10"><a href="#cb117-10" aria-hidden="true" tabindex="-1"></a>X_train <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(terms_log, <span class="at">data =</span> train_df)[, <span class="sc">-</span><span class="dv">1</span>, drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span>
<span id="cb117-11"><a href="#cb117-11" aria-hidden="true" tabindex="-1"></a>X_test  <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(terms_log, <span class="at">data =</span> test_df)[,  <span class="sc">-</span><span class="dv">1</span>, drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span>
<span id="cb117-12"><a href="#cb117-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-13"><a href="#cb117-13" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> train_df<span class="sc">$</span>high_response</span>
<span id="cb117-14"><a href="#cb117-14" aria-hidden="true" tabindex="-1"></a>y_test  <span class="ot">&lt;-</span> test_df<span class="sc">$</span>high_response</span>
<span id="cb117-15"><a href="#cb117-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-16"><a href="#cb117-16" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb117-17"><a href="#cb117-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-18"><a href="#cb117-18" aria-hidden="true" tabindex="-1"></a><span class="co"># LASSO (alpha = 1)</span></span>
<span id="cb117-19"><a href="#cb117-19" aria-hidden="true" tabindex="-1"></a>cv_lasso  <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X_train, y_train, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">nfolds =</span> <span class="dv">10</span>)</span>
<span id="cb117-20"><a href="#cb117-20" aria-hidden="true" tabindex="-1"></a>mod_lasso <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X_train, y_train, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">lambda =</span> cv_lasso<span class="sc">$</span>lambda.min)</span>
<span id="cb117-21"><a href="#cb117-21" aria-hidden="true" tabindex="-1"></a>p_lasso_train <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(mod_lasso, <span class="at">newx =</span> X_train, <span class="at">type =</span> <span class="st">"response"</span>))</span>
<span id="cb117-22"><a href="#cb117-22" aria-hidden="true" tabindex="-1"></a>p_lasso_test  <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(mod_lasso, <span class="at">newx =</span> X_test,  <span class="at">type =</span> <span class="st">"response"</span>))</span>
<span id="cb117-23"><a href="#cb117-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-24"><a href="#cb117-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Ridge (alpha = 0)</span></span>
<span id="cb117-25"><a href="#cb117-25" aria-hidden="true" tabindex="-1"></a>cv_ridge  <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X_train, y_train, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">nfolds =</span> <span class="dv">10</span>)</span>
<span id="cb117-26"><a href="#cb117-26" aria-hidden="true" tabindex="-1"></a>mod_ridge <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X_train, y_train, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">lambda =</span> cv_ridge<span class="sc">$</span>lambda.min)</span>
<span id="cb117-27"><a href="#cb117-27" aria-hidden="true" tabindex="-1"></a>p_ridge_train <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(mod_ridge, <span class="at">newx =</span> X_train, <span class="at">type =</span> <span class="st">"response"</span>))</span>
<span id="cb117-28"><a href="#cb117-28" aria-hidden="true" tabindex="-1"></a>p_ridge_test  <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(mod_ridge, <span class="at">newx =</span> X_test,  <span class="at">type =</span> <span class="st">"response"</span>))</span>
<span id="cb117-29"><a href="#cb117-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-30"><a href="#cb117-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Elastic Net (alpha = 0.15 as an example)</span></span>
<span id="cb117-31"><a href="#cb117-31" aria-hidden="true" tabindex="-1"></a>alpha_en   <span class="ot">&lt;-</span> <span class="fl">0.15</span></span>
<span id="cb117-32"><a href="#cb117-32" aria-hidden="true" tabindex="-1"></a>cv_enet    <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X_train, y_train, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">alpha =</span> alpha_en, <span class="at">nfolds =</span> <span class="dv">10</span>)</span>
<span id="cb117-33"><a href="#cb117-33" aria-hidden="true" tabindex="-1"></a>mod_enet   <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X_train, y_train, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">alpha =</span> alpha_en, <span class="at">lambda =</span> cv_enet<span class="sc">$</span>lambda.min)</span>
<span id="cb117-34"><a href="#cb117-34" aria-hidden="true" tabindex="-1"></a>p_enet_train <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(mod_enet, <span class="at">newx =</span> X_train, <span class="at">type =</span> <span class="st">"response"</span>))</span>
<span id="cb117-35"><a href="#cb117-35" aria-hidden="true" tabindex="-1"></a>p_enet_test  <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(mod_enet, <span class="at">newx =</span> X_test,  <span class="at">type =</span> <span class="st">"response"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s now compare the models<br>
<br>
</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === Compare models on </span><span class="al">TEST</span><span class="co"> ====================================================</span></span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>compare_test <span class="ot">&lt;-</span> tibble<span class="sc">::</span><span class="fu">tibble</span>(</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">Model =</span> <span class="fu">c</span>(<span class="st">"Logistic (glm)"</span>, <span class="st">"LASSO-logit"</span>, <span class="st">"Ridge-logit"</span>, <span class="st">"ElasticNet-logit"</span>),</span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">Prob  =</span> <span class="fu">list</span>(p_test,        p_lasso_test,  p_ridge_test,  p_enet_test)</span>
<span id="cb118-5"><a href="#cb118-5" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb118-6"><a href="#cb118-6" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">rowwise</span>() <span class="sc">%&gt;%</span></span>
<span id="cb118-7"><a href="#cb118-7" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">mutate</span>(</span>
<span id="cb118-8"><a href="#cb118-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">yhat    =</span> <span class="fu">list</span>(<span class="fu">as.integer</span>(<span class="fu">unlist</span>(Prob) <span class="sc">&gt;=</span> <span class="fl">0.5</span>)),</span>
<span id="cb118-9"><a href="#cb118-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">Metrics =</span> <span class="fu">list</span>(<span class="fu">cm_metrics</span>(y_test, <span class="fu">unlist</span>(yhat))),</span>
<span id="cb118-10"><a href="#cb118-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">AUC_ROC =</span> <span class="fu">auc_roc</span>(y_test, <span class="fu">unlist</span>(Prob)),</span>
<span id="cb118-11"><a href="#cb118-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">AUC_PR  =</span> <span class="fu">auc_pr</span>(y_test,  <span class="fu">unlist</span>(Prob))</span>
<span id="cb118-12"><a href="#cb118-12" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb118-13"><a href="#cb118-13" aria-hidden="true" tabindex="-1"></a>  tidyr<span class="sc">::</span><span class="fu">unnest</span>(Metrics) </span>
<span id="cb118-14"><a href="#cb118-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-15"><a href="#cb118-15" aria-hidden="true" tabindex="-1"></a>compare_test</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 14
  Model     Prob  yhat     TP    TN    FP    FN Accuracy Sensitivity Specificity
  &lt;chr&gt;     &lt;lis&gt; &lt;lis&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
1 Logistic… &lt;dbl&gt; &lt;int&gt;  1005  1717   163   116    0.907       0.897       0.913
2 LASSO-lo… &lt;dbl&gt; &lt;int&gt;  1019  1716   164   102    0.911       0.909       0.913
3 Ridge-lo… &lt;dbl&gt; &lt;int&gt;  1034  1697   183    87    0.910       0.922       0.903
4 ElasticN… &lt;dbl&gt; &lt;int&gt;  1019  1712   168   102    0.910       0.909       0.911
# ℹ 4 more variables: Precision &lt;dbl&gt;, F1 &lt;dbl&gt;, AUC_ROC &lt;dbl&gt;, AUC_PR &lt;dbl&gt;</code></pre>
</div>
</div>
<p>and plot metrics of performance<br>
<br>
</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === Faceted ROC across models (</span><span class="al">TEST</span><span class="co">) =========================================</span></span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>roc_facets <span class="ot">&lt;-</span> <span class="cf">function</span>(models, labels,</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a>                       <span class="at">suptitle =</span> <span class="st">"ROC curves by model (TEST)"</span>,</span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a>                       <span class="at">xlaw =</span> <span class="st">"False positive rate (1 - specificity)"</span>,</span>
<span id="cb120-5"><a href="#cb120-5" aria-hidden="true" tabindex="-1"></a>                       <span class="at">ylaw =</span> <span class="st">"True positive rate (sensitivity)"</span>,</span>
<span id="cb120-6"><a href="#cb120-6" aria-hidden="true" tabindex="-1"></a>                       <span class="at">caption =</span> <span class="cn">NULL</span>) {</span>
<span id="cb120-7"><a href="#cb120-7" aria-hidden="true" tabindex="-1"></a>  df_list <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">"list"</span>, <span class="fu">length</span>(models))</span>
<span id="cb120-8"><a href="#cb120-8" aria-hidden="true" tabindex="-1"></a>  model_names <span class="ot">&lt;-</span> <span class="fu">names</span>(models)</span>
<span id="cb120-9"><a href="#cb120-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">is.null</span>(model_names)) model_names <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"Model "</span>, <span class="fu">seq_along</span>(models))</span>
<span id="cb120-10"><a href="#cb120-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_along</span>(models)) {</span>
<span id="cb120-11"><a href="#cb120-11" aria-hidden="true" tabindex="-1"></a>    roc_i <span class="ot">&lt;-</span> pROC<span class="sc">::</span><span class="fu">roc</span>(labels, models[[i]], <span class="at">quiet =</span> <span class="cn">TRUE</span>)</span>
<span id="cb120-12"><a href="#cb120-12" aria-hidden="true" tabindex="-1"></a>    auc_i <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(pROC<span class="sc">::</span><span class="fu">auc</span>(roc_i))</span>
<span id="cb120-13"><a href="#cb120-13" aria-hidden="true" tabindex="-1"></a>    pts   <span class="ot">&lt;-</span> tibble<span class="sc">::</span><span class="fu">tibble</span>(</span>
<span id="cb120-14"><a href="#cb120-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">fpr   =</span> <span class="dv">1</span> <span class="sc">-</span> roc_i<span class="sc">$</span>specificities,</span>
<span id="cb120-15"><a href="#cb120-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">tpr   =</span> roc_i<span class="sc">$</span>sensitivities,</span>
<span id="cb120-16"><a href="#cb120-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">model =</span> <span class="fu">sprintf</span>(<span class="st">"%s (AUC = %.3f)"</span>, model_names[i], auc_i)</span>
<span id="cb120-17"><a href="#cb120-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb120-18"><a href="#cb120-18" aria-hidden="true" tabindex="-1"></a>    df_list[[i]] <span class="ot">&lt;-</span> pts</span>
<span id="cb120-19"><a href="#cb120-19" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb120-20"><a href="#cb120-20" aria-hidden="true" tabindex="-1"></a>  roc_df <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">bind_rows</span>(df_list)</span>
<span id="cb120-21"><a href="#cb120-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-22"><a href="#cb120-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(roc_df, <span class="fu">aes</span>(<span class="at">x =</span> fpr, <span class="at">y =</span> tpr)) <span class="sc">+</span></span>
<span id="cb120-23"><a href="#cb120-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_path</span>(<span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb120-24"><a href="#cb120-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb120-25"><a href="#cb120-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">facet_wrap</span>(<span class="sc">~</span> model) <span class="sc">+</span></span>
<span id="cb120-26"><a href="#cb120-26" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> suptitle, <span class="at">x =</span> xlab, <span class="at">y =</span> ylab, <span class="at">caption =</span> caption) <span class="sc">+</span></span>
<span id="cb120-27"><a href="#cb120-27" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">12</span>)</span>
<span id="cb120-28"><a href="#cb120-28" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb120-29"><a href="#cb120-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-30"><a href="#cb120-30" aria-hidden="true" tabindex="-1"></a>models_scores <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb120-31"><a href="#cb120-31" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Logistic (glm)"</span> <span class="ot">=</span> p_test,</span>
<span id="cb120-32"><a href="#cb120-32" aria-hidden="true" tabindex="-1"></a>  <span class="st">"LASSO-logit"</span>    <span class="ot">=</span> p_lasso_test,</span>
<span id="cb120-33"><a href="#cb120-33" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Ridge-logit"</span>    <span class="ot">=</span> p_ridge_test,</span>
<span id="cb120-34"><a href="#cb120-34" aria-hidden="true" tabindex="-1"></a>  <span class="st">"ENet-logit"</span>     <span class="ot">=</span> p_enet_test</span>
<span id="cb120-35"><a href="#cb120-35" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb120-36"><a href="#cb120-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-37"><a href="#cb120-37" aria-hidden="true" tabindex="-1"></a><span class="fu">roc_facets</span>(models_scores, <span class="at">labels =</span> y_test,</span>
<span id="cb120-38"><a href="#cb120-38" aria-hidden="true" tabindex="-1"></a>           <span class="at">suptitle =</span> <span class="st">"ROC by model on TEST (ct_reduced)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/unnamed-chunk-51-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === Faceted PR across models (</span><span class="al">TEST</span><span class="co">, optional) ================================</span></span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="st">"PRROC"</span> <span class="sc">%in%</span> <span class="fu">.packages</span>()) {</span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>  pr_facets <span class="ot">&lt;-</span> <span class="cf">function</span>(models, labels,</span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>                        <span class="at">positive_class =</span> <span class="dv">1</span>,</span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a>                        <span class="at">suptitle =</span> <span class="st">"Precision–Recall curves by model (TEST)"</span>,</span>
<span id="cb121-6"><a href="#cb121-6" aria-hidden="true" tabindex="-1"></a>                        <span class="at">caption =</span> <span class="cn">NULL</span>) {</span>
<span id="cb121-7"><a href="#cb121-7" aria-hidden="true" tabindex="-1"></a>    df_list <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">"list"</span>, <span class="fu">length</span>(models))</span>
<span id="cb121-8"><a href="#cb121-8" aria-hidden="true" tabindex="-1"></a>    model_names <span class="ot">&lt;-</span> <span class="fu">names</span>(models)</span>
<span id="cb121-9"><a href="#cb121-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">is.null</span>(model_names)) model_names <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"Model "</span>, <span class="fu">seq_along</span>(models))</span>
<span id="cb121-10"><a href="#cb121-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_along</span>(models)) {</span>
<span id="cb121-11"><a href="#cb121-11" aria-hidden="true" tabindex="-1"></a>      s <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(models[[i]])</span>
<span id="cb121-12"><a href="#cb121-12" aria-hidden="true" tabindex="-1"></a>      y <span class="ot">&lt;-</span> <span class="fu">as.integer</span>(labels)</span>
<span id="cb121-13"><a href="#cb121-13" aria-hidden="true" tabindex="-1"></a>      s_pos <span class="ot">&lt;-</span> s[y <span class="sc">==</span> positive_class]</span>
<span id="cb121-14"><a href="#cb121-14" aria-hidden="true" tabindex="-1"></a>      s_neg <span class="ot">&lt;-</span> s[y <span class="sc">!=</span> positive_class]</span>
<span id="cb121-15"><a href="#cb121-15" aria-hidden="true" tabindex="-1"></a>      pr <span class="ot">&lt;-</span> PRROC<span class="sc">::</span><span class="fu">pr.curve</span>(<span class="at">scores.class0 =</span> s_pos, <span class="at">scores.class1 =</span> s_neg, <span class="at">curve =</span> <span class="cn">TRUE</span>)</span>
<span id="cb121-16"><a href="#cb121-16" aria-hidden="true" tabindex="-1"></a>      tmp <span class="ot">&lt;-</span> tibble<span class="sc">::</span><span class="fu">tibble</span>(</span>
<span id="cb121-17"><a href="#cb121-17" aria-hidden="true" tabindex="-1"></a>        <span class="at">recall    =</span> pr<span class="sc">$</span>curve[, <span class="dv">1</span>],</span>
<span id="cb121-18"><a href="#cb121-18" aria-hidden="true" tabindex="-1"></a>        <span class="at">precision =</span> pr<span class="sc">$</span>curve[, <span class="dv">2</span>],</span>
<span id="cb121-19"><a href="#cb121-19" aria-hidden="true" tabindex="-1"></a>        <span class="at">model     =</span> <span class="fu">sprintf</span>(<span class="st">"%s (AUC-PR = %.3f)"</span>, model_names[i], pr<span class="sc">$</span>auc.integral)</span>
<span id="cb121-20"><a href="#cb121-20" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb121-21"><a href="#cb121-21" aria-hidden="true" tabindex="-1"></a>      df_list[[i]] <span class="ot">&lt;-</span> tmp</span>
<span id="cb121-22"><a href="#cb121-22" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb121-23"><a href="#cb121-23" aria-hidden="true" tabindex="-1"></a>    pr_df <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">bind_rows</span>(df_list)</span>
<span id="cb121-24"><a href="#cb121-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-25"><a href="#cb121-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(pr_df, <span class="fu">aes</span>(recall, precision)) <span class="sc">+</span></span>
<span id="cb121-26"><a href="#cb121-26" aria-hidden="true" tabindex="-1"></a>      <span class="fu">geom_path</span>(<span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb121-27"><a href="#cb121-27" aria-hidden="true" tabindex="-1"></a>      <span class="fu">facet_wrap</span>(<span class="sc">~</span> model) <span class="sc">+</span></span>
<span id="cb121-28"><a href="#cb121-28" aria-hidden="true" tabindex="-1"></a>      <span class="fu">labs</span>(<span class="at">title =</span> suptitle, <span class="at">x =</span> <span class="st">"Recall (sensitivity)"</span>, <span class="at">y =</span> <span class="st">"Precision (PPV)"</span>, <span class="at">caption =</span> caption) <span class="sc">+</span></span>
<span id="cb121-29"><a href="#cb121-29" aria-hidden="true" tabindex="-1"></a>      <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">12</span>)</span>
<span id="cb121-30"><a href="#cb121-30" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb121-31"><a href="#cb121-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-32"><a href="#cb121-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pr_facets</span>(models_scores, <span class="at">labels =</span> y_test,</span>
<span id="cb121-33"><a href="#cb121-33" aria-hidden="true" tabindex="-1"></a>            <span class="at">suptitle =</span> <span class="st">"Precision–Recall by model on TEST (ct_reduced)"</span>)</span>
<span id="cb121-34"><a href="#cb121-34" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="supervised_regression_files/figure-html/unnamed-chunk-52-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-eisenhauer2009recist" class="csl-entry" role="listitem">
Eisenhauer, Elizabeth A., Patrick Therasse, Jan Bogaerts, Lawrence H. Schwartz, Daniel Sargent, Rebecca Ford, Janet Dancey, et al. 2009. <span>“New Response Evaluation Criteria in Solid Tumours: Revised RECIST Guideline (Version 1.1).”</span> <em>European Journal of Cancer</em> 45 (2): 228–47. <a href="https://doi.org/10.1016/j.ejca.2008.10.026">https://doi.org/10.1016/j.ejca.2008.10.026</a>.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/danilosarti\.github\.io\/att_ml_ai_book");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./introduction_AI.html" class="pagination-link" aria-label="Introduction to AI and Machine Learning">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to AI and Machine Learning</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./three_methods.html" class="pagination-link" aria-label="Supervised Learning: Tree Methods">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Supervised Learning: Tree Methods</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>